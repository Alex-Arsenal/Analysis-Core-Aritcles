{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据复制到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch('http://kouxun.lenovoresearch2019.cn:9200/')\n",
    "client = Elasticsearch('127.0.0.1:9200/')\n",
    "query = es.search(\n",
    "        index='ls_datas',\n",
    "        # index='lak_datas',\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        },\n",
    "        scroll='5m',\n",
    "        size=100\n",
    "    )\n",
    "results = query['hits']['hits']  # es查询出的结果第一页\n",
    "total = query['hits']['total']  # es查询出的结果总量\n",
    "scroll_id = query['_scroll_id']  # 游标用于输出es查询出的所有结果\n",
    "for i in range(0, int(total / 100) + 1):\n",
    "    # scroll参数必须指定否则会报错\n",
    "    query_scroll = es.scroll(scroll_id=scroll_id, scroll='5m')['hits']['hits']\n",
    "    results += query_scroll\n",
    "print(len(results))\n",
    "# print(results[0])\n",
    "for i in results:\n",
    "    datas_dict={}\n",
    "    id=i['_id']\n",
    "    print(id)\n",
    "    title_id=i['_source']['title_id']\n",
    "    yearnum=i['_source']['yearnum']\n",
    "    year_title=i['_source']['year_title']\n",
    "    ls_datas=i['_source']['ls_datas']\n",
    "    # lak_datas=i['_source']['lak_datas']\n",
    "\n",
    "    datas_dict['title_id']=title_id\n",
    "    datas_dict['yearnum']=yearnum\n",
    "    datas_dict['year_title']=year_title\n",
    "    datas_dict['ls_datas']=ls_datas\n",
    "    # datas_dict['lak_datas']=lak_datas\n",
    "    client.index(index=\"ls_datas\", doc_type=\"ls_datas_type\", id=id, body=datas_dict)\n",
    "    # client.index(index=\"lak_datas\", doc_type=\"lak_datas_type\", id=id, body=datas_dict)\n",
    "    print(\"插入数据成功\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T06:27:40.907844Z",
     "start_time": "2019-11-21T06:22:17.928180Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "2013\n",
      "插入数据成功\n",
      "2006\n",
      "插入数据成功\n",
      "2000\n",
      "插入数据成功\n",
      "1993\n",
      "插入数据成功\n",
      "1990\n",
      "插入数据成功\n",
      "2016\n",
      "插入数据成功\n",
      "2015\n",
      "插入数据成功\n",
      "2003\n",
      "插入数据成功\n",
      "2002\n",
      "插入数据成功\n",
      "1992\n",
      "插入数据成功\n",
      "1991\n",
      "插入数据成功\n",
      "2018\n",
      "插入数据成功\n",
      "2010\n",
      "插入数据成功\n",
      "2005\n",
      "插入数据成功\n",
      "2004\n",
      "插入数据成功\n",
      "1996\n",
      "插入数据成功\n",
      "2001\n",
      "插入数据成功\n",
      "2019\n",
      "插入数据成功\n",
      "2017\n",
      "插入数据成功\n",
      "2009\n",
      "插入数据成功\n",
      "2008\n",
      "插入数据成功\n",
      "2007\n",
      "插入数据成功\n",
      "1998\n",
      "插入数据成功\n",
      "1994\n",
      "插入数据成功\n",
      "2014\n",
      "插入数据成功\n",
      "2012\n",
      "插入数据成功\n",
      "2011\n",
      "插入数据成功\n",
      "1999\n",
      "插入数据成功\n",
      "1997\n",
      "插入数据成功\n",
      "1995\n",
      "插入数据成功\n",
      "1989\n",
      "插入数据成功\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch('http://kouxun.lenovoresearch2019.cn:9200/')\n",
    "client = Elasticsearch('127.0.0.1:9200/')\n",
    "query = es.search(\n",
    "        #index='cscw_datas',\n",
    "        #index='ubicomp_datas',\n",
    "        #index='group_datas',\n",
    "        #index='iui_datas',\n",
    "        #index='its_datas',\n",
    "        #index='uist_datas',\n",
    "        #index='mobilechi_datas',\n",
    "        #index='dis_datas',\n",
    "        #index='icmi_datas',\n",
    "        index='chi_datas',\n",
    "        #index='assets_datas',\n",
    "        #index='gi_datas',\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        },\n",
    "        scroll='5m',\n",
    "        size=100\n",
    "    )\n",
    "results = query['hits']['hits']  # es查询出的结果第一页\n",
    "total = query['hits']['total']  # es查询出的结果总量\n",
    "scroll_id = query['_scroll_id']  # 游标用于输出es查询出的所有结果\n",
    "for i in range(0, int(total / 100) + 1):\n",
    "    # scroll参数必须指定否则会报错\n",
    "    query_scroll = es.scroll(scroll_id=scroll_id, scroll='5m')['hits']['hits']\n",
    "    results += query_scroll\n",
    "print(len(results))\n",
    "# print(results[0])\n",
    "for i in results:\n",
    "    datas_dict={}\n",
    "    id=i['_id']\n",
    "    print(id)\n",
    "    url=i['_source']['url']\n",
    "    title=i['_source']['title']\n",
    "    head=i['_source']['head']\n",
    "    year_id=i['_source']['year_id']\n",
    "    all_category_datas=i['_source']['all_category_datas']\n",
    "\n",
    "    datas_dict['url']=url\n",
    "    datas_dict['title']=title\n",
    "    datas_dict['head']=head\n",
    "    datas_dict['year_id']=year_id\n",
    "    datas_dict['all_category_datas']=all_category_datas\n",
    "    #client.index(index=\"cscw_datas\", doc_type=\"cscw_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"ubicomp_datas\", doc_type=\"ubicomp_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"group_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"iui_datas\", doc_type=\"cscw_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"its_datas\", doc_type=\"ubicomp_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"uist_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"mobilechi_datas\", doc_type=\"ubicomp_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"dis_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"icmi_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    client.index(index=\"chi_datas\", doc_type=\"ubicomp_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"assets_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    #client.index(index=\"gi_datas\", doc_type=\"group_datas_type\", id=id, body=datas_dict)\n",
    "    print(\"插入数据成功\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从本地提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T06:47:49.243010Z",
     "start_time": "2019-11-19T06:47:49.088177Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "16\n",
      "19\n",
      "15\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#lak,ls\n",
    "import requests\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "client = Elasticsearch(hosts=[\"http://127.0.0.1:9200/\"])\n",
    "#client = Elasticsearch(hosts=[\"http://kouxun.lenovoresearch2019.cn:9200/\"])\n",
    "data = client.search(\n",
    "        #index='lak_datas',\n",
    "        index='ls_datas',\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        },\n",
    "        scroll='5m',\n",
    "        size=46\n",
    "    )\n",
    "data = data['hits']['hits']\n",
    "total_text = {}\n",
    "total_bibliometrics = {}\n",
    "total_index_term = {}\n",
    "total_reference = {}\n",
    "total_author = {}\n",
    "article_author = {}\n",
    "total_article = {}\n",
    "total_corpus ={}\n",
    "\n",
    "for x in data:\n",
    "    data_year = x['_source']\n",
    "    #print (data_year)\n",
    "\n",
    "    year = data_year['yearnum']\n",
    "    total_article[year] = {'title':[], 'abstract':[]}\n",
    "    #sigchi_datas = data_year['lak_datas']\n",
    "    sigchi_datas = data_year['ls_datas']\n",
    "    \n",
    "    print (year)    \n",
    "\n",
    "    for s in sigchi_datas:\n",
    "        #print (s)\n",
    "        #print ('\\n')\n",
    "        #author = s['auther_detaildata']\n",
    "        author = s['authors']\n",
    "        reference = s['references']\n",
    "        index_term = s['index_terms']\n",
    "        bibliometrics = s['bibliometrics']\n",
    "        title = s['title']\n",
    "        abstract = s['abstract']\n",
    "        #doi=s['doi']\n",
    "        \n",
    "        total_bibliometrics.setdefault(year,[]).append(bibliometrics)\n",
    "        total_reference.setdefault(year,[]).append(reference)\n",
    "        total_index_term.setdefault(year,[]).append(index_term)\n",
    "        total_article[year]['title'].append(title)\n",
    "        total_article[year]['abstract'].append(abstract)\n",
    "        article_author.setdefault(year,[]).append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T06:27:50.647641Z",
     "start_time": "2019-11-21T06:27:47.230529Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#dis, mobilechi,uist,its,iui,ubicomp,group,cscw,assets\n",
    "import requests\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "client = Elasticsearch(hosts=[\"http://127.0.0.1:9200/\"])\n",
    "data = client.search(\n",
    "        #index='dis_datas',\n",
    "        #index='mobilechi_datas',\n",
    "        #index='icmi_datas',\n",
    "        #index='uist_datas',\n",
    "        #index='its_datas',\n",
    "        #index='iui_datas',\n",
    "        #index='ubicomp_datas',\n",
    "        #index='group_datas',\n",
    "        #index='cscw_datas',\n",
    "        index='chi_datas',\n",
    "        #index='assets_datas',\n",
    "        #index='gi_datas',\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        },\n",
    "        scroll='5m',\n",
    "        size=46\n",
    "    )\n",
    "data = data['hits']['hits']\n",
    "total_text = {}\n",
    "total_bibliometrics = {}\n",
    "total_index_term = {}\n",
    "total_reference = {}\n",
    "total_author = {}\n",
    "article_author = {}\n",
    "total_article = {}\n",
    "total_corpus ={}\n",
    "\n",
    "for x in data:\n",
    "    data_year = x['_source']\n",
    "    #print (data_year)\n",
    "\n",
    "    year = data_year['year_id']\n",
    "    total_article[year] = {'title':[], 'abstract':[]}\n",
    "    datas = data_year['all_category_datas']\n",
    "    #print (year)\n",
    "    \n",
    "    for s in datas:\n",
    "        for i in s['category_datas']:\n",
    "            #print (i.keys())\n",
    "            if 'authors' in i.keys():\n",
    "                author = i['authors']\n",
    "            else:\n",
    "                author = i['auther_detaildata']\n",
    "            reference = i['references']\n",
    "            bibliometrics = i['bibliometrics']\n",
    "            title = i['title']\n",
    "            abstract = i['abstract']\n",
    "            \n",
    "            \n",
    "            total_bibliometrics.setdefault(year,[]).append(bibliometrics)\n",
    "            total_reference.setdefault(year,[]).append(reference)\n",
    "            total_article[year]['title'].append(title)\n",
    "            total_article[year]['abstract'].append(abstract)\n",
    "            article_author.setdefault(year,[]).append(author)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T06:09:41.122588Z",
     "start_time": "2019-11-21T06:09:39.822914Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "None\n",
      "Speech Studies\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "client = Elasticsearch(hosts=[\"http://127.0.0.1:9200/\"])\n",
    "data = client.search(\n",
    "        index='chi_datas',\n",
    "        #index='gi_datas',\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        },\n",
    "        scroll='5m',\n",
    "        size=46\n",
    "    )\n",
    "data = data['hits']['hits']\n",
    "total_text = {}\n",
    "total_bibliometrics = {}\n",
    "total_index_term = {}\n",
    "total_reference = {}\n",
    "total_author = {}\n",
    "article_author = {}\n",
    "total_article = {}\n",
    "total_corpus ={}\n",
    "\n",
    "for x in data:\n",
    "    data_year = x['_source']\n",
    "    #print (data_year)\n",
    "\n",
    "    year = data_year['year_id']\n",
    "    total_article[year] = {'title':[], 'abstract':[]}\n",
    "    datas = data_year['all_category_datas']\n",
    "    #print (year)\n",
    "    \n",
    "    for s in datas:\n",
    "        \n",
    "        for i in s['category_datas']:\n",
    "            if type(i) != dict:\n",
    "                print (year)\n",
    "                print (i)\n",
    "                print (s['category_title'])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心文章提取分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T06:51:56.590048Z",
     "start_time": "2019-11-19T06:51:56.566834Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, WordPunctTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "#设置stopwords，缩略词拆解\n",
    "\n",
    "stopwords = set (stopwords.words('english')+list(punctuation)+[').'])\n",
    "\n",
    "\n",
    "#分段成句和分句成词\n",
    "def splitSentence(paragraph):\n",
    "    sent = sent_tokenize(paragraph)\n",
    "    return sent\n",
    "\n",
    "\n",
    "def wordtokenizer(sentence):\n",
    "    word = []\n",
    "    words = WordPunctTokenizer().tokenize(sentence)\n",
    "    word = word + words\n",
    "    return word\n",
    "\n",
    "#文章预处理\n",
    "def standardization(word_sent):\n",
    "#转换为小写字母    \n",
    "    text = []\n",
    "    for s in word_sent:\n",
    "        text.append(s.lower())\n",
    "    \n",
    "    return text\n",
    "\n",
    "#词形还原\n",
    "def lemmatizer(word):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = []\n",
    "#对单词类型标注\n",
    "    text_tag = np.array(nltk.pos_tag(word))\n",
    "    #print (text_tag)\n",
    "    \n",
    "    for s in text_tag:\n",
    "        if s[1].startswith('N'):\n",
    "            if s[1] == 'NNS' or s[1] == 'NN':\n",
    "                text.append(wnl.lemmatize(s[0],'n'))\n",
    "            else:\n",
    "                text.append(s[0])\n",
    "        elif s[1].startswith('V'):\n",
    "            text.append(wnl.lemmatize(s[0], 'v'))\n",
    "        elif s[1].startswith('J'):\n",
    "            text.append(wnl.lemmatize(s[0], 'a'))\n",
    "        elif s[1].startswith('R'):\n",
    "            text.append(wnl.lemmatize(s[0], 'r'))\n",
    "        else:\n",
    "            text.append(s[0])\n",
    "            \n",
    "    #print (text)\n",
    "    new_text = [word for word in text if word not in stopwords and 3<len(word)]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T06:29:44.571423Z",
     "start_time": "2019-11-21T06:29:44.499399Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTFul: adaptive review technology for flipped learning\n",
      "2013\n",
      "111\n",
      "Extracting usability and user experience information from online user reviews\n",
      "2013\n",
      "229\n",
      "Using intelligent task routing and contribution review to help communities build artifacts of lasting value\n",
      "2006\n",
      "118\n",
      "Comparative design review: an exercise in parallel design\n",
      "1993\n",
      "71\n",
      "Human-computer interaction research at the University of Illinois (lab review)\n",
      "1990\n",
      "11\n",
      "NTT human interface laboratories (lab review)\n",
      "1990\n",
      "12\n",
      "User interface and quality planning department (lab review)\n",
      "1990\n",
      "13\n",
      "Human computer interaction group, University of York, U.K. (lab review)\n",
      "1990\n",
      "14\n",
      "Human-computer interface laboratory—Virginia Polytechnic Institute and State University (lab review)\n",
      "1990\n",
      "42\n",
      "CHI in the applied research divisions at Bellcore (lab review)\n",
      "1990\n",
      "43\n",
      "CHI systems, incorporated (lab review)\n",
      "1990\n",
      "44\n",
      "Interactive systems research group—Fraunhofer-Gesellschaft Institute for Industrial Engineering (lab review)\n",
      "1990\n",
      "45\n",
      "Research for human-computer interaction at the MRC Applied Psychology Unit (lab review)\n",
      "1990\n",
      "57\n",
      "Boeing Advanced Technology Center (lab review)\n",
      "1990\n",
      "58\n",
      "The U.S. West Intelligent Services Research Laboratory (lab review)\n",
      "1990\n",
      "59\n",
      "Interactive systems group—University of Oregon, department of computer and information science (lab review)\n",
      "1990\n",
      "60\n",
      "A visit to a very small database: lessons from managing the review of papers submitted for CHI'91\n",
      "1992\n",
      "73\n",
      "YAPO: yet another preview ODA\n",
      "1992\n",
      "91\n",
      "Understanding the impact of abstracted audio preview of SMS\n",
      "2010\n",
      "196\n",
      "API usability peer reviews: a method for evaluating the usability of application programming interfaces\n",
      "2010\n",
      "265\n",
      "Command strokes with and without preview: using pen gestures on keyboard for command selection\n",
      "2007\n",
      "129\n",
      "Distributed collaborative writing: a comparison of spoken and written modalities for reviewing and revising documents\n",
      "1994\n",
      "7\n",
      "A systematic review of quantitative studies on the enjoyment of digital entertainment games\n",
      "2014\n",
      "100\n",
      "ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging\n",
      "2014\n",
      "135\n",
      "Shape-changing interfaces: a review of the design space and open research questions\n",
      "2012\n",
      "83\n",
      "What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing\n",
      "2011\n",
      "56\n",
      "Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs\n",
      "2011\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "for s in total_article:\n",
    "    count = 0\n",
    "    for i in total_article[s]['title']:\n",
    "        text = wordtokenizer(i)\n",
    "        for j in text:\n",
    "            if 'review' in j:\n",
    "                print (i)\n",
    "                print (s)\n",
    "                print (count)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T06:53:36.691556Z",
     "start_time": "2019-11-21T06:53:36.663846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2013': [0, 2, 3, 5, 6, 10, 14, 16, 17, 19, 20, 23, 25, 26, 32, 33, 34, 36, 39, 40, 43, 49, 50, 55, 56, 58, 64, 65, 66, 67, 69, 70, 72, 73, 78, 82, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 106, 114, 116, 117, 118, 121, 122, 123, 125, 126, 128, 130, 132, 133, 135, 139, 140, 141, 145, 146, 152, 156, 161, 162, 163, 168, 172, 173, 177, 183, 184, 186, 188, 189, 190, 193, 194, 196, 198, 200, 201, 203, 204, 205, 207, 212, 214, 218, 220, 224, 225, 228, 229, 233, 235, 237, 245, 246, 249, 251, 254, 255, 256, 259, 262, 264, 265, 270, 274, 279, 282, 285, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 300, 303, 307, 308, 309, 310, 311, 312, 314, 315, 317, 321, 325, 338, 339, 340, 344, 347, 348, 352, 356, 359, 362, 364, 365, 366, 367, 368, 369, 370, 375, 377, 378, 381, 382, 383, 386, 387, 388, 389, 391], '2006': [0, 2, 4, 6, 8, 9, 14, 17, 18, 20, 23, 24, 25, 26, 29, 31, 33, 46, 47, 48, 49, 50, 51, 61, 63, 64, 66, 67, 69, 73, 75, 79, 80, 83, 85, 86, 87, 88, 89, 90, 95, 96, 99, 100, 104, 108, 109, 111, 114, 117, 118, 122, 127, 128, 129, 130, 132, 135, 136, 137, 142, 143, 144, 145, 147], '2000': [1, 2, 6, 9, 16, 18, 20, 21, 23, 25, 26, 30, 33, 35, 37, 41, 42, 43, 45, 46, 52, 54, 56, 57, 61, 62, 64, 65, 66, 69, 70, 71], '1993': [5, 16, 36, 49, 68, 84], '1990': [2, 27, 35, 37, 39, 48, 49], '2016': [1, 2, 4, 5, 7, 8, 12, 14, 20, 21, 22, 24, 25, 28, 29, 30, 32, 34, 36, 37, 39, 40, 46, 47, 54, 55, 57, 60, 64, 65, 66, 71, 73, 75, 76, 84, 86, 87, 88, 93, 95, 96, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 117, 124, 125, 126, 128, 132, 133, 134, 135, 137, 138, 141, 142, 144, 147, 151, 152, 153, 154, 156, 160, 163, 165, 166, 167, 172, 174, 175, 176, 177, 178, 179, 180, 189, 190, 191, 195, 196, 199, 200, 201, 202, 203, 204, 207, 208, 209, 211, 213, 220, 222, 224, 230, 232, 233, 234, 235, 236, 238, 239, 240, 248, 255, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 275, 278, 281, 282, 283, 284, 285, 288, 289, 291, 293, 304, 305, 306, 311, 313, 318, 320, 325, 329, 331, 332, 336, 338, 339, 340, 341, 342, 343, 344, 345, 347, 350, 351, 352, 355, 358, 359, 362, 363, 367, 369, 377, 378, 381, 382, 383, 384, 387, 388, 406, 407, 413, 416, 419, 421, 422, 425, 428, 430, 432, 433, 435, 437, 440, 441, 442, 445, 446, 447, 448, 449, 451, 457, 458, 459, 466, 467, 472, 474, 475, 476, 477, 478, 480, 481, 482, 484, 485, 488, 491, 494, 495, 497, 500, 504, 505, 510, 517, 518, 520, 525, 529, 530, 531, 532, 533, 536, 538, 540, 541], '2015': [0, 3, 13, 14, 15, 18, 20, 22, 26, 30, 32, 33, 38, 42, 43, 46, 47, 50, 51, 52, 57, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 79, 82, 84, 88, 90, 92, 95, 96, 98, 102, 104, 105, 108, 115, 116, 119, 122, 125, 126, 127, 128, 130, 131, 132, 135, 138, 140, 141, 142, 143, 144, 146, 149, 150, 152, 154, 156, 160, 161, 163, 166, 168, 169, 172, 173, 174, 177, 179, 182, 184, 185, 188, 189, 191, 196, 198, 202, 205, 206, 207, 208, 209, 210, 213, 215, 218, 219, 220, 221, 222, 225, 231, 232, 233, 235, 236, 238, 239, 240, 242, 243, 245, 247, 248, 250, 252, 257, 258, 259, 261, 267, 269, 270, 271, 272, 274, 276, 279, 280, 281, 282, 283, 284, 285, 286, 287, 291, 296, 298, 301, 302, 303, 304, 310, 311, 320, 321, 324, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 339, 340, 341, 343, 344, 348, 351, 354, 357, 359, 361, 362, 363, 364, 365, 366, 367, 368, 375, 376, 378, 380, 390, 392, 400, 401, 411, 412, 413, 415, 419, 424, 425, 429, 431, 432, 433, 435, 439, 441, 442, 443, 444, 452, 456, 457, 461, 463, 465, 468, 469, 475, 476, 477, 478, 481], '2003': [0, 1, 2, 6, 9, 11, 12, 13, 14, 15, 16, 17, 21, 22, 24, 27, 28, 29, 30, 32, 34, 39, 42, 43, 44, 50, 51, 55, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74], '2002': [0, 4, 7, 8, 9, 12, 14, 17, 18, 21, 22, 23, 25, 26, 29, 33, 34, 35, 37, 43, 45, 51, 53, 55, 56, 59, 60], '1992': [0, 3, 4, 5, 13, 17, 29, 32, 58, 61, 80, 82, 94, 96, 97, 103], '1991': [5, 11, 12, 14, 17, 22, 23, 25, 26, 27, 29, 32, 45], '2018': [2, 3, 5, 7, 14, 18, 30, 31, 32, 35, 37, 38, 39, 45, 46, 47, 48, 54, 55, 68, 70, 73, 80, 81, 85, 86, 88, 91, 93, 94, 102, 103, 114, 115, 119, 123, 124, 127, 129, 134, 140, 143, 151, 153, 157, 161, 170, 173, 179, 183, 191, 206, 208, 214, 227, 231, 237, 241, 242, 244, 252, 257, 258, 259, 264, 271, 276, 280, 282, 284, 287, 289, 293, 297, 298, 300, 305, 310, 312, 313, 315, 318, 326, 334, 337, 339, 340, 343, 344, 349, 358, 364, 370, 372, 373, 375, 381, 385, 387, 389, 390, 396, 400, 406, 418, 426, 428, 429, 430, 432, 433, 434, 436, 437, 438, 443, 446, 455, 456, 458, 459, 463, 465, 471, 473, 476, 479, 480, 481, 489, 509, 511, 512, 522, 528, 531, 533, 551, 552, 554, 565, 566, 568, 572, 574, 576, 579, 581, 626, 637, 641, 642, 644, 646, 651, 653, 662, 663, 664], '2010': [4, 6, 9, 14, 15, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 42, 43, 46, 47, 48, 50, 56, 61, 64, 65, 68, 70, 71, 72, 79, 80, 81, 82, 88, 90, 92, 95, 99, 100, 102, 103, 114, 117, 118, 120, 122, 124, 130, 131, 132, 133, 134, 136, 138, 140, 142, 143, 146, 147, 148, 153, 156, 158, 161, 164, 171, 172, 173, 176, 177, 178, 179, 180, 182, 184, 186, 194, 197, 203, 205, 206, 207, 208, 209, 210, 211, 215, 217, 219, 220, 224, 226, 227, 228, 229, 230, 233, 236, 237, 242, 244, 245, 247, 248, 249, 254, 255, 256, 258, 259, 260, 261, 268, 269, 270, 272, 273, 274, 275, 276, 279, 280, 281, 287, 288, 294, 295, 296, 297, 300, 301], '2005': [1, 3, 4, 6, 8, 10, 12, 13, 15, 18, 19, 20, 22, 28, 31, 32, 33, 34, 36, 37, 40, 42, 45, 46, 47, 49, 52, 53, 54, 59, 60, 63, 64, 68, 69, 71, 72, 74, 75, 76, 78, 80, 86, 87, 90, 91, 92], '2004': [4, 5, 11, 14, 16, 19, 21, 22, 26, 28, 30, 33, 34, 38, 40, 46, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 61, 65, 67, 68, 69, 71, 72, 73, 74, 75, 79, 81, 83, 84, 89, 92], '1996': [7, 12, 14, 15, 18, 26, 27, 28, 29, 35, 39], '2001': [1, 2, 3, 7, 8, 18, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 42, 46, 49, 50, 53, 58, 61, 62, 63, 65, 66], '2019': [2, 15, 39, 105, 146, 461, 472, 597], '2017': [0, 2, 4, 5, 9, 11, 12, 13, 14, 17, 23, 24, 36, 41, 43, 44, 46, 53, 55, 56, 58, 60, 61, 64, 66, 69, 71, 74, 79, 86, 88, 89, 97, 102, 103, 107, 108, 112, 113, 117, 125, 126, 127, 128, 134, 135, 139, 140, 141, 143, 146, 148, 149, 154, 158, 164, 165, 168, 170, 181, 184, 186, 187, 188, 190, 192, 196, 197, 198, 200, 205, 206, 210, 214, 216, 220, 222, 224, 225, 226, 227, 230, 231, 232, 234, 236, 237, 239, 245, 246, 247, 249, 253, 254, 266, 267, 268, 270, 273, 274, 276, 277, 280, 281, 283, 284, 286, 287, 288, 294, 295, 297, 299, 306, 311, 313, 315, 316, 319, 321, 322, 328, 331, 332, 335, 340, 341, 343, 344, 347, 351, 352, 353, 354, 355, 357, 360, 368, 369, 379, 381, 387, 390, 391, 395, 396, 397, 401, 409, 413, 414, 419, 421, 426, 429, 433, 438, 441, 442, 447, 453, 454, 455, 458, 459, 460, 463, 468, 474, 476, 477, 478, 484, 485, 486, 489, 490, 491, 492, 493, 494, 502, 506, 510, 512, 514, 519, 520, 529, 530, 531, 541, 542, 544, 548, 549, 550, 551, 557, 560, 562, 572, 575, 579, 580, 581, 582, 583, 584, 587, 590, 592, 596], '2009': [0, 2, 3, 5, 8, 11, 15, 16, 17, 18, 25, 26, 35, 36, 37, 38, 43, 45, 46, 47, 48, 49, 51, 54, 59, 61, 70, 73, 76, 78, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 95, 99, 100, 103, 104, 105, 107, 108, 109, 110, 111, 114, 118, 119, 120, 121, 123, 130, 131, 134, 135, 137, 138, 142, 145, 146, 147, 155, 156, 157, 158, 164, 166, 168, 170, 172, 174, 178, 180, 181, 183, 184, 185, 188, 190, 192, 193, 197, 199, 200, 203, 205, 206, 209, 210, 212, 213, 215, 218, 219, 222, 223, 224, 225, 229, 230, 232, 237, 238, 243, 244, 247, 253, 257, 260, 261, 265, 267, 270, 275], '2008': [0, 4, 7, 9, 11, 13, 14, 16, 18, 22, 25, 26, 28, 31, 35, 37, 38, 41, 42, 43, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 69, 76, 77, 78, 79, 83, 87, 91, 93, 95, 101, 104, 111, 112, 120, 121, 122, 126, 128, 131, 132, 137, 140, 141, 142, 143, 144, 146, 148, 149, 150, 152, 153, 154, 156, 158, 160, 161, 165, 168, 170, 172, 175, 177, 178, 183, 187, 188, 189, 192, 195, 197, 198, 201, 206, 210, 212, 215, 216], '2007': [0, 3, 6, 7, 8, 10, 12, 13, 15, 17, 22, 26, 30, 42, 43, 46, 47, 48, 49, 50, 52, 54, 55, 59, 60, 61, 62, 63, 64, 66, 70, 72, 73, 74, 75, 76, 78, 80, 81, 83, 84, 86, 90, 93, 95, 96, 98, 99, 100, 101, 102, 104, 106, 110, 113, 117, 118, 120, 123, 128, 129, 130, 131, 143, 149, 154, 156, 157, 158, 159, 160, 163, 165, 166, 167, 169, 170, 180, 181], '1998': [2, 3, 5, 6, 22, 29, 31, 32, 36, 38, 41, 44, 51, 56, 61, 63, 69, 72], '1994': [10, 16, 19, 22, 27, 38, 40, 41, 45, 46, 47, 54, 62, 67], '2014': [0, 1, 4, 5, 6, 9, 17, 18, 19, 21, 24, 31, 38, 47, 48, 49, 50, 52, 53, 54, 56, 58, 59, 65, 74, 78, 80, 84, 85, 87, 88, 89, 90, 91, 95, 97, 100, 104, 105, 109, 110, 119, 120, 123, 124, 126, 127, 129, 131, 133, 137, 139, 140, 146, 148, 149, 151, 153, 155, 157, 166, 167, 182, 185, 188, 191, 192, 193, 194, 200, 205, 212, 213, 217, 219, 220, 221, 222, 223, 225, 230, 241, 242, 243, 247, 248, 249, 255, 256, 257, 260, 261, 263, 265, 266, 267, 268, 270, 272, 274, 275, 279, 280, 283, 286, 288, 289, 290, 295, 298, 299, 301, 302, 304, 308, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 326, 328, 329, 334, 335, 339, 341, 342, 344, 345, 347, 348, 349, 350, 351, 353, 355, 356, 357, 362, 364, 371, 373, 377, 386, 390, 392, 394, 395, 396, 397, 398, 405, 406, 419, 423, 426, 427, 428, 429, 435, 436, 439, 442, 447, 452, 453, 456, 457, 460, 461, 463, 464], '2012': [0, 1, 2, 7, 9, 10, 11, 12, 13, 19, 21, 24, 25, 26, 28, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 48, 51, 52, 54, 57, 59, 61, 65, 67, 68, 74, 75, 76, 80, 83, 85, 86, 88, 90, 94, 98, 99, 107, 108, 109, 110, 111, 112, 113, 115, 117, 119, 120, 123, 125, 126, 127, 130, 131, 132, 133, 134, 135, 136, 137, 142, 143, 144, 147, 149, 150, 151, 152, 155, 157, 158, 161, 165, 170, 171, 172, 174, 175, 180, 186, 187, 188, 189, 193, 194, 200, 207, 208, 209, 210, 211, 214, 215, 217, 219, 223, 227, 228, 230, 234, 237, 244, 246, 247, 248, 251, 253, 263, 265, 266, 267, 268, 269, 270, 272, 274, 275, 277, 283, 287, 288, 295, 296, 299, 302, 303, 304, 306, 312, 313, 316, 317, 318, 320, 323, 328, 329, 330, 331, 334, 339, 342, 345, 346, 348, 351, 359, 366], '2011': [1, 5, 9, 11, 12, 14, 16, 17, 19, 20, 22, 24, 25, 26, 28, 29, 35, 36, 45, 46, 47, 53, 59, 63, 70, 77, 78, 79, 80, 81, 82, 83, 86, 87, 91, 92, 93, 94, 102, 106, 107, 113, 116, 118, 120, 121, 123, 124, 125, 127, 129, 140, 141, 142, 143, 144, 145, 146, 148, 149, 153, 154, 155, 157, 158, 161, 162, 163, 164, 171, 173, 178, 179, 180, 182, 192, 194, 195, 197, 201, 202, 203, 205, 212, 213, 214, 216, 217, 220, 226, 230, 233, 240, 241, 242, 243, 244, 248, 252, 255, 261, 262, 263, 264, 266, 272, 273, 275, 278, 283, 287, 289, 290, 295, 296, 297, 299, 304, 305, 306, 307, 309, 312, 316, 317, 319, 322, 323, 331, 332, 336, 344, 345, 349, 351, 352, 354, 355, 356, 358, 359, 360, 366, 367, 372, 378, 380, 381, 382, 383, 387, 391, 393, 395, 397, 400, 402, 406], '1999': [1, 2, 3, 5, 7, 9, 10, 15, 19, 20, 27, 28, 31, 34, 35, 36, 37, 38, 43, 44, 45, 47, 48, 49, 50, 55, 59, 63, 65, 66, 69, 72, 73, 75, 76], '1997': [0, 1, 4, 5, 6, 8, 9, 14, 23, 25, 29, 33, 37, 39, 41, 42, 43, 45, 46, 48, 50, 52, 58], '1995': [5, 6, 7, 12, 24, 25, 26, 29, 30, 33, 34, 35, 47, 51, 57]}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#用contemporary citation 筛选高引文章\n",
    "now = 2019\n",
    "index = 4\n",
    "high_cited = {}\n",
    "missing = {}\n",
    "for s in total_bibliometrics:\n",
    "    count = 0\n",
    "    year = float(s)\n",
    "    for i in total_bibliometrics[s]:\n",
    "        if type(i) != list:\n",
    "            #print(i)\n",
    "            if 'Citation_Count' in i.keys():\n",
    "                if i['Citation_Count'] == ' 1,333':\n",
    "                    citition = 1333.0\n",
    "                else:\n",
    "                    citition = float(i['Citation_Count'])\n",
    "            elif 'microsoft_citations' in i.keys():\n",
    "                citition = float(i['microsoft_citations'])\n",
    "            else:\n",
    "                missing.setdefault(s,[]).append(count)\n",
    "        else:\n",
    "            if 'Citations' in i[0].keys():\n",
    "                citition = float(i[0]['Citations'])\n",
    "            else:\n",
    "                missing.setdefault(s,[]).append(count)\n",
    "\n",
    "        new_cite = index / (now - year + 1) * citition\n",
    "\n",
    "        if new_cite > 10:\n",
    "            high_cited.setdefault(s,[]).append(count)\n",
    "\n",
    "        \n",
    "        count += 1\n",
    "print (high_cited)\n",
    "print (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:45:28.512272Z",
     "start_time": "2019-11-20T05:45:28.465214Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1\n",
      "Resolving References to Graphical Objects in Multimodal Queries by Constraint Satisfaction\n",
      "In natural language queries to an intelligent multimodal system, ambiguities related to referring expressions - \n",
      "\n",
      "\n",
      "2\n",
      "Human-Robot Interface Based on Speech Understanding Assisted by Vision\n",
      "Speech recognition provides a natural and familiar interface for human beings to pass on information. For this, it is likely to be used as the human interface in service robots. However, in order for the robot to move in accordance to what the user tells it, there is a need to look at information other than those obtained from speech input. First, we look at the widely discussed problem in natural language processing of abbreviated communication of common context between parties. In addition to this, another problem exists for a robot, and that is the lack of information linking symbols in a robot’s world to things in a real world. Here, we propose a method of using image processing to make up for the information lacking in language processing that makes it insufficient to carry out the action. And when image processing fails, the robot will ask the user directly and use his/her answer to help it in achieving its task. We confirm our theories by performing experiments on both simulation and real robot and test their reliability.\n",
      "\n",
      "\n",
      "3\n",
      "Designing Multi-sensory Models for Finding Patterns in Stock Market Data\n",
      "The rapid increase in available information has lead to many attempts to automatically locate patterns in large, abstract, multi-attributed information spaces. These techniques are often called ‘Data Mining’ and have met with varying degrees of success. An alternative approach to automatic pattern detection is to keep the user in the ‘exploration loop’. A domain expert is often better able to search data for relationships. Furthermore, it is now possible to construct user interfaces that provide multi-sensory interactions. For example, interfaces can be designed which utilise 3D visual spaces and also provide auditory and haptic feedback. These multi-sensory interfaces may assist in the interpretation of abstract information spaces by providing models that map different attributes of data to different senses. While this approach has the potential to assist in exploring these large information spaces what is unclear is how to choose the best models to define mappings between the abstract information and the human sensory channels. This paper describes some simple guidelines based on real world analogies for designing these models. These principles are applied to the problem of finding new patterns in stock market data.\n",
      "\n",
      "\n",
      "4\n",
      "Audio-visual Segmentation and “The Cocktail Party Effect”\n",
      "Audio-based interfaces usually suffer when noise or other acoustic sources are present in the environment. For robust audio recognition, a single source must first be isolated. Existing solutions to this problem generally require special microphone configurations, and often assume prior knowledge of the spurious sources. We have developed new algorithms for segmenting streams of audio-visual information into their constituent sources by exploiting the mutual information present between audio and visual tracks. Automatic face recognition and image motion analysis methods are used to generate visual features for a particular user; empirically these features have high mutual information with audio recorded from that user. We show how audio utterances from several speakers recorded with a single microphone can be separated into constituent streams; we also show how the method can help reduce the effect of noise in automatic speech recognition.\n",
      "\n",
      "\n",
      "5\n",
      "Visual Recognition of Emotional States\n",
      "Recognizing and interpreting a human’s facial expressions and thereby his mood are an important challenge for computer vision. In this paper, we will show that trajectories in eigenspace can be used to automate the recognition of facial expressions. Prerequisite is the exact knowledge of position and size of the face within a sequence of video images. Precision and stability are two properties deciding if a tracking algorithm is suitable for subsequent recognition tasks. We will describe in this paper a robust face tracking algorithm that can sufficiently normalize a video stream to a face allowing for facial expression recognition based on eigenspace techniques. The presented face tracking algorithm is mainly based on using probability maps generated from color histograms.\n",
      "\n",
      "\n",
      "8\n",
      "A Sound MagicBoard\n",
      "Vision and audio can be used in a complementary way to efficiently create augmented reality tools. This paper describes how sound detection can be used to enhance the efficiency of a computer vision augmented reality tool such as the MagicBoard. A MagicBoard is an ordinary white board with which a user can handle both real and virtual information, allowing, e.g., for a copy&paste operation on a physical drawing on the board. The electronic part of the MagicBoard consists of a video-projector and the concurrent use of several detectors such as a camera and microphones. In our system, sound is used to support a purely vision-based finger tracker, especially during the most critical phase, i.e., when trying to detect and localize a finger tap as a click on the board. The relative phase of a signal caused by a finger tap on the board, detected by several microphones is used to estimate the postition of the finger tap. In the probable case of several possible estimates, the estimates are eventually verified by the visual tracker. The resulting system is surprisingly precise and robust.\n",
      "\n",
      "\n",
      "9\n",
      "A Head Gesture Recognition Algorithm\n",
      "In this paper, we present a head gesture\n",
      "\n",
      "\n",
      "10\n",
      "Gesture Recognition for a Walking Person by Using a Sequence of Spatially Reduced Range Image\n",
      "In order to obtain flexibility of gesture recognition system, a sequence of range image has been used for both erasing background noise and distinguishing gestures of which categories are depending on depth features. The essential processing was to spatially divide the space in front of the person into, for example, 3 by 3 by 3 voxels and calculate the ratio of hand area in each voxels. This paper newly introduces a tracking method for a walking person who is also moving.\n",
      "\n",
      "\n",
      "12\n",
      "A Self-reliance Smoothness of the Vision-Based Recognition of Hand Gestures\n",
      "The hand gestures are a natural and intuitive mode for human-computer interaction. The vision-based recognition of hand gestures is a necessary method for future human-computer interaction. On the other hand, the edge detection in the course of the hand recognition is also a key technique. In this paper based on the classical self-reliance smoothness operator, we propose a new method of midpoint threshold (the averaged grads method). According to this method, the optimal threshold and edge image of hand gestures can be got by using the first or each information of grads of reference image.\n",
      "\n",
      "\n",
      "13\n",
      "Hand Shape Extraction and Understanding by Virtue of Multiple Cues Fusion Technology\n",
      "In order that information included in the hand shape can be extracted for gesture communication aiming to the new technology of Human Computer Interaction, hand shape should be reliably extracted based on image sequences. In this paper a hand shape extraction approach is proposed .By using multiple cues such as motion and color information, embedded in image sequences, a set of complicated hand shapes which compromise a small dictionary of hand postures, can be reliably extracted within a rather sophisticated environment, In this paper the proposed shape extraction strategy is addressed and preliminary results are indicated to prove its effectiveness\n",
      "\n",
      "\n",
      "15\n",
      "A General Framework for Face Detection\n",
      "In this paper a general framework for face detection is presented which taken into accounts both color and gray level images. For color images, skin color segmentation is used as the first stage to reduce search space into a few gray level regions possibly containing faces. And then in general for gray level images, techniques of template matching based on average face for searching face candidates and neural network classification for face verification are integrated for face detection. A qualitative 3D model of skin color in HSI space is used for skin color segmentation. Two types of templates: eyes-in-whole and face itself, are used one by one in template matching for searching face candidates. Two three-layer-perceptrons (MLPs) are used independently in the template matching procedure to verify each face candidate to produce two list of detected faces which are arbitrated to exclude most of the false alarms. Experiment results demonstrate the feasibility of this approach.\n",
      "\n",
      "\n",
      "17\n",
      "Real-Time Face Tracking under Partial Occlusion and Illumination Change\n",
      "In this paper, we present an approach which tracks human faces robustly in real-time applications by taking advantage of both region matching and active contour model. Region matching with motion prediction robustly locates the approximate position of the target , then active contour model detects the local variation of the target’s boundary which is insensitive to illumination changes, and results from active contour model guides updating the template for successive tracking. In this case, the system can tolerate changes in both pose and illumination. To reduce the influence of local error due to partial occlusion and weak edge strength, we use \n",
      "\n",
      "\n",
      "20\n",
      "Recognition of Human Faces Based on Fast Computation of Circular Harmonic Components\n",
      "This paper discusses facial recognition as applied to the classification of two-dimensional images and proposes a new architecture that allows a fast derivation of compact and invariant features from the Radon space. Our approach has been inspired by the review of feature-based non-connectionist and connectionist models of facial recognition. In the feature based non-connectionist model, a large part of the computational effort is focused on the extraction of facial features or the geometrical encoding of the face and the measurement of statistical parameters to describe their relationship. The connectionist model focuses on two-dimensional intensity values of the facial image allowing the geometrical encoding to be measured implicitly. The connectionist model is thus susceptible to variations in lighting conditions, spatial position and orientation of the images and can result in a poor detection of faces. An additional bottleneck of the connectionist model is the large feature vector size applied to its input that can cause non-convergence problems during training. The Radon transform is a generic transformation that is capable of representing shapes and it is used to compute harmonic components from which compact and invariant features can be derived. It is shown in this paper that these features when applied to a connectionist model result in a system that is capable of achieving high recognition rates and at high significance levels.\n",
      "\n",
      "\n",
      "21\n",
      "Multiple Faces Tracking and Zooming System\n",
      "We propose a multi-camera system that can track multiple human faces and hands as well as focus on them for face and hand-sign recognition. Our current system consists of four video cameras. Two cameras are fixed and used as a stereo camera to estimate position. The stereo camera detects faces and hands using a standard skin color method we proposed. The distances of targets are then estimated. To track multiple targets, we evaluated position and size of targets in consecutive frames. The other two cameras perform target tracking. Our system selects a target for recognition by using size and motion information sequentially. If size of the selected target is too small for recognition, tracking cameras acquire its zoomed image. Using our system, we experimented on multiple target tracking.\n",
      "\n",
      "\n",
      "22\n",
      "Face Warping Using a Single Image\n",
      "Given an image of a face and the co-ordinates of the eyeballs’ centre, we provide a method which creates the corresponding frontal face and gives a qualitative and quantitative measure of the horizontal tilt of the face, using the natural symmetry of the human head. By multiscale dynamic programming, we obtain the optical flow (2D warp) which transforms the input face into its mirror image, this mirror image being a good approximation of the same head that has undergone a 3D rotation. The frontal face is obtained by applying half of the magnitude of the optical flow, and any pose is obtained by applying a fraction of this optical flow. The nose axis, which gives a quantitative and qualitative tilt estimation, is obtained by the reverse optical flow applied on the symmetrical axis of the generated frontal face. Experimental results on 500 images and on the Surrey database confirm the performance of this system.\n",
      "\n",
      "\n",
      "23\n",
      "Hierarchical Framework for Facial Expression Recognition\n",
      "In recent years, much work on the recognition of facial expression, and the recognition of face and the methods are various. The algorithm for recognizing facial expression includes various preprocessing and core scheme for the detection of facial area, the detection of facial components and the recognition of facial expression. We propose a framework to implement the recognition facial expression through the algorithm which is composed of many steps. The framework allows a substitution and reuse of a step of the algorithm. A step of the algorithm is able to use and update individually. And we also propose an efficient method for each step. First of all, we propose multiresolution wavelet transform, 2d equilibrium state vector to search facial components at 3\n",
      "\n",
      "\n",
      "24\n",
      "Detecting Facial Features on Images with Multiple Faces\n",
      "This paper presents an approach to detect facial features of multiple faces on complex background and with variable poses, illumination conditions, expressions, ages, image sizes, etc. First, the skin parts of the input image are extracted by color segmentation. Then, the candidate face regions are estimated by grouping the skin parts. Within each candidate face region, an attempt is made to find the eye pair using both Hough Transform and the Principal Component Analysis (PCA) method. If the predicted eye pair is, under the measurement of correlation, close enough to its projection on the eigen eyes space, the corresponding region is confirmed to be a face region. Finally, other facial features, including mouth corners, nose tips and nose holes are detected based on the integral projection algorithm and the average anthropologic measurements of the valid faces.\n",
      "\n",
      "\n",
      "25\n",
      "The Synthesis of Realistic Human Face\n",
      "In this paper, we present new techniques for creating a realistic specific human face based on a general 3D face model and several photos of a human. The morphing technique allows interactive alignment of features of the general geometric face model with the features of the multi-direction images of the specific human face, which are pre-provided by the animator. To enhance the realism, we employ a multi-direction texture mapping technique, which gets illumination information from multi-direction images of the specific human face.\n",
      "\n",
      "\n",
      "27\n",
      "A Improved Facial Expression Recognition Method\n",
      "We proposed a novel facial expression recognition algorithm based on Independent Component Analysis (ICA) and Linear Discriminant Analysis (LDA). ICA produced a set of independent basis images of expression image, LDA selected features obtained from ICA. Experiments proved the excellent performance of our algorithm.\n",
      "\n",
      "\n",
      "29\n",
      "Face Recognition Based on Local Fisher Features\n",
      "To efficiently solve human face image recognition problem with an image database, many techniques have been proposed. A key step in these techniques is the extraction of features for indexing in the database and afterwards for fulfilling recognition tasks. Linear Discriminate Analysis(LDA) is a statistic method for classification. LDA filter is global in space and local in frequency. It squeezes all discriminant information into few basis vectors so that the interpretation of the extracted features becomes difficult. In this paper, we propose a new idea to enhance the performance of the LDA method for image recognition. We extract localized information of the human face images by virtue of wavelet transform. The simulation results suggest good classification ability of our proposed system.\n",
      "\n",
      "\n",
      "31\n",
      "Multimodal Integration Using Complex Feature Set\n",
      "Multimodal integration is an important problem of multimodal user interface research. After briefly surveying research on multimodal integration, this paper introduced a natural language processing method to resolve the problem of integration. It introduced the unification operation on complex feature set and extended this operation in order to represent the information from input modalities and implement multimodal integration.\n",
      "\n",
      "\n",
      "32\n",
      "Bilingual Dictionary Based Sentence Alignment for Chinese English Bitext\n",
      "Bitext is a rather “ hot ” issue among current natural language processing and automatic sentence alignment is the first step towards bitext processing.Following the shift form previous knowledge-poor approach (pure length-based)to current some-what knowledge-rich approach,this paper suggests a bilingual dictionary based sentence alignment method for Chinese English bitext and realizes it through dynamic programming.Experiment on HIT bitext shows that this method has achieved an accuracy as high as 95%, and therefore is worthy of further exploring.\n",
      "\n",
      "\n",
      "33\n",
      "A Task Oriented Natural Language Understanding Model\n",
      "A theoretical task oriented natural language understanding(NLU) model is provided in this paper, together with a practical application based on it. The model is based on sentence framework (regular language mode in specific areas), chunks, etc. And it consists of following modules: post-process, NLU, target searching, connection, action. Every module is discussed in detail taking the application as example. The NLU module is of great importance, and we place emphasis on it. The success of our application shows that the model provided in this paper is feasible in specific task areas. The sentence framework, together with chunks, is very important in expressing sentence meaning. Verbs are of great important in sentence analysis. And we can use this model and methods provided in this paper to build many applications in various areas. Further more, the model and methods are worth reference in processing other domains’ problems.\n",
      "\n",
      "\n",
      "34\n",
      "Variable Length Language Model for Chinese Character Recognition\n",
      "We present a new type of language model — variable length language model (VLLM)whose length is non-deterministic on the base of 5-gram combined model brought forward previously.Its main advantage lies in that it captures the function of 5-gram combined model and reflects the structural feature of every line in test text as well.Compared to previous language model, the VLLM makes use of current result to determine which kind of language model should be used next and realizes the automatic choice of language model that is always constant before. VLLM also resolves the problem when punctuation marks appear.Based on those improvements,we make experiments and get encouraging result.\n",
      "\n",
      "\n",
      "35\n",
      "Automatic Lexical Errors Detecting of Chinese Texts Based on the Orderly-Neighborship\n",
      "According to the statistic analysis of common errors found in those texts that are typed-in, OCR-recognized or phonetics-recognized but not be proofread and the characteristics of such texts,we propose a error-detecting principle and error-detecting algorithm based on the orderly-neighborship. Furthermore, Factors that affect performance index of error-detecting system such as recall ratio and accurate ratio are discussed.\n",
      "\n",
      "\n",
      "36\n",
      "Statistical Analysis of Chinese Language and Language Modeling Based on Huge Text Corpora\n",
      "This paper presents the statistical characteristics of Chinese language based on huge text corpora.From our investigation,we find that in writing Chinese it is more likely to use long words,while in other language styles the words are shorter.In large text corpora,the number of bigram and trigram can be estimated by the size of the corpus.In the recognition experiments,we find the correlation is weak between the perplexity to either the size of the training set or the recognition character error rate.However,in order to attain good performance,the large training set above tens of million words is necessary.\n",
      "\n",
      "\n",
      "37\n",
      "On Building a Simulating Translation Environment for Multilingual Conversation\n",
      "We present a distributed environment (Sim*) for collecting multilingual spoken dialogues through a Wizard of Oz scheme. These speech corpora are then used to build an automatic Speech Translation system. In the future Sim* should develop to offer full support for any combination of resources between human interpreters and automatic Speech Translation systems, in a multimodal and distributed context.\n",
      "\n",
      "\n",
      "38\n",
      "Approach to Recognition and Understanding of the Time Constituents in the Spoken Chinese Language Translation\n",
      "In the spoken Chinese language, the time constituents occur frequently, especially in the domain of appointment schedule, ticket booking and hotel reservation etc. However, in the current Chinese-to-English Machine Translation (MT) systems, it is still a problem to deal with the time constituents. According to our test results of some commercial Chinese-to- English MT systems, about 57.1% Chinese time constituents are wrongly translated, and 58.3% of the errors are caused by false recognition and misunderstanding of the time constituents. In the paper, we present a new approach to recognition and understanding of the time constituents in the Chinese language, which is integrated by a shallow level analyzer and a deep level analyzer. The shallow level analysis is realized by a Finite State Transition Network (\n",
      "\n",
      "\n",
      "39\n",
      "KD2000 Chinese Text-To-Speech System\n",
      "This paper presents the new progress we made in recent two years on Chinese text-to-speech towards higher naturalness. The results can be summarized as follows: 1). Aim at the different characteristics between philology and phonetics, a kind of hierarchy process model for Chinese TTS system has been proposed. Five layers are defined to label the sentence in the text analysis. 2). A prosodic generating model is built for selecting appropriate unit with higher accuracy. 3). Extracting prosodic parameter from the unit base and then normalizing them to form a prosodic parameter base. 4). Proposed an effective method for processing the special text, which integrates external descriptor rules and model matching. With these progresses a new Chinese text- to-speech system named KD2000 has been developed. The improved performance has been confirmed by evaluation test.\n",
      "\n",
      "\n",
      "40\n",
      "Multimodal Speaker Detection Using Input/Output Dynamic Bayesian Networks\n",
      "Inferring users’ actions and intentions forms an integral part of design and development of any human-computer interface. The presence of noisy and at times ambiguous sensory data makes this problem challenging. We formulate a framework for temporal fusion of multiple sensors using input-output dynamic Bayesian networks (IODBNs).We find that contextual information about the state of the computer interface, used as an input to the DBN, and sensor distributions learned from data are crucial for good detection performance. Nevertheless, classical DBN learning methods can cause such models to fail when the data exhibits complex behavior. To further improve the detection rate we formulate an \n",
      "\n",
      "\n",
      "41\n",
      "Research on Speech Recognition Based on Phase Space Reconstruction Theory\n",
      "Based on Takens theory, time delay method is used to reconstruct the phase space of speech signal in this paper. In hyper dimensional phase space, similar sequence repeatability (RPT) and the entropy information of speech are calculated, and they are applied to speech recognition. The result proves that speech signal shows some geometric property between the stochastic Gauss noise and deterministic Lorenz attractor. For speech phonemes, the RPT parameters of same kind show some similarity, and of different kind show some different characteristics as well. The method proposed in this paper provides a new way for the non-linear analysis of speech recognition.\n",
      "\n",
      "\n",
      "42\n",
      "Estimating the Pose of Phicons for Human Computer Interaction\n",
      "Physical icons (phicons) are ordinary objects that can serve as user interface in an intelligent environment. This article addresses the problem of recognizing the position and orientation of such objects. Such recognition enables free manipulation of phicons in 3D space.\n",
      "\n",
      "\n",
      "43\n",
      "An Approach to Robust and Fast Locating Lip Motion\n",
      "In this paper,we present a novel approach to robust and fast locating lip motion.Firstly, the fisher transform with constraints is presented to enhance the lip region in a face image. Secondly, two distribution characteristics of the lip in human face space are proposed to increase the accuracy and and real-time implementation performance of lip locating. Experiments with 2000 images show that this approach can satisfy requirements not only in real-time performance but also in reliability and accuracy.\n",
      "\n",
      "\n",
      "44\n",
      "Multi-level Human Tracking\n",
      "In this paper, we describe a system on automatically tracking people in indoor environment. Parametric Estimation methods are adopted in training images to obtain means and covariance of the background pixels. They are processed in pixel classification step to extract moving people and eliminate their shadows. Our tracking algorithm consists of two levels: region level and blob level. The region level tracks a whole human by utilizing the position information of the detected persons. The EM algorithm is adopted at the blob level to segment human image into different parts. When region level tracking fails, the system switches to blob-level tracking. Average Bhattacharyya distances between corresponding blobs of consecutive frames are calculated to get the correct match between different regions. Potential applications of the proposed algorithm include HCI and visual surveillance. Experimental results are given to demonstrate the robustness and efficiency of our algorithm.\n",
      "\n",
      "\n",
      "45\n",
      "Region-Based Tracking in Video Sequences Using Planar Perspective Models\n",
      "Object tracking can be used in many applications using motion information. This paper proposes a method of region-based tracking using planar perspective motion models. Planar perspective models can represent motion information of the plane rigid motion in the sequence properly. And in many cases the real object’s motion can be represented using planar perspective motion models approximately. The method estimates model parameters on three pyramid levels, and it is based on the reliable estimation of planar perspective models in the region to be tracked. The calculation on three pyramid levels can accelerate the speed of estimation. Gauss-Newton and Levenberg-Marquadet are combined to estimate the models’ parameters. During the tracking process there is some noise, so robust estimation is used in the parameters’ estimation of models. Some experimental results are shown at the end of paper. From the experiments’ result the tracking method is effective in those complicated situations.\n",
      "\n",
      "\n",
      "46\n",
      "A Novel Motion Estimation Algorithm Based on Dynamic Search Window and Spiral Search\n",
      "Motion estimation is a key technique in MPEG and H.263 encoder, due to its significant impact on the bit rate and the output quality of the encoded sequence. The full search algorithm (FS), which is considered to be the optimal, is computational intensive, and traditional fast algorithms still need to be improved in both computational complexity and matching accuracy. This paper proposes a novel algorithm, DSWSS, which is based on dynamic search window and spiral search. It performs as accurately as full search algorithm, but needs much less computation.\n",
      "\n",
      "\n",
      "47\n",
      "Determining Motion Components Using the Point Distribution Model\n",
      "The Point Distribution Model (PDM) has proven effective in modelling variations in shape in sets of images, including those in which motion is involved such as body and hand tracking. This paper proposes an extension to the PDM through a re-parameterisation of the model which uses factors such as the angular velocity and distance travelled for sets of points on a moving shape. This then enables non-linear quantities such as acceleration and the average velocity of the body to be expressed in a linear model by the PDM. Results are shown for objects with known acceleration and deceleration components, these being a simulated pendulum modelled using simple harmonic motion and video sequences of a real pendulum in motion.\n",
      "\n",
      "\n",
      "49\n",
      "A Novel Algorithm for Handwritten Chinese Character Recognition\n",
      "2-D HMM methods have recently been applied to handwritten Chinese character recognition(HCCR) with much practical prospect, however, the time consuming is a great obstacle for its widely using. To overcome this weakness a novel block-based ICM algorithm, which will decode image block by block other than pixel by pixel, is proposed. Experiments shows that it can work much better than the traditional one for HCCR with a little higher accuracy and much higher speed of recognition. It offers a great potential for HCCR when using truly-2D HMM.\n",
      "\n",
      "\n",
      "50\n",
      "An HMM Based Two-Pass Approach for Off-Line Cursive Handwriting Recognition\n",
      "The cursive handwriting recognition is a challenging task because the recognition system has to handle not only large shape variation of human handwriting, but also character segmentation. Usually the recognition performance depends crucially upon the segmentation process. Hidden Markov Models (HMMs) have the ability to model similarity and variation among samples of a class. In this paper we present an extended sliding window feature extraction method and an HMM based two-pass modeling approach. Whereas our feature extraction method makes the resulting system more robust with word baseline detection, the two-pass recognition approach exploits the segmentation ability of the Viterbi algorithm and creates another HMM set and carries out a second pass recognition. The total performance is enhanced by combination of the two pass results. Experiments of recognizing cursive handwritten words with 30000 words lexicon have been carried out and show that our novel approach can achieve better recognition performance and reduce the relative error rate significantly.\n",
      "\n",
      "\n",
      "51\n",
      "On-Line Recognition of Mathematical Expressions Using Automatic Rewriting Method\n",
      "This paper describes our system of on-line recognition of mathematical expressions. Users can input mathematical expressions by handwriting. As soon as a character is written, it is rewritten by neat strokes in an appropriate position and size automatically. This \n",
      "\n",
      "\n",
      "52\n",
      "On-Line Hand-Drawn Symbol Recognition Based on Primitives Separation and Fuzzy Inference\n",
      "In this paper, a universal recognition method for hand-drawn symbols is presented which based on primitives separation and fuzzy inference. This technique first separates input figure symbol into primitives using a single-band integral algorithm, then a fuzzy inference framework is used to combine these primitives into complicate symbols. The features used in the inference process are very simple, so the figure set can be easily extended. The method was tested under regular input circumstance with an average recognition rate of 90 percent reported.\n",
      "\n",
      "\n",
      "53\n",
      "Integration MBHMM and Neural Network for Totally Unconstrained Handwritten Numerals Recognition\n",
      "In this paper we present a method of Multi-branch two dimensional HMM (hidden markov model ) for handwritten numeral recognition and another method of Neural network for handwrittern numeral recognition and then integrated the two method into a totally unconstrained handwritten numeral recognition system. The system is composed of a horizontal super state multi-branch two dimensional HMM, a vertical super state multi-branch two dimensional HMM and a Neural network. The integrated recognition system recognition rate is higher than the three subsystem. The data base of handwriting digits used in this paper was collected at Beijing Postal Center, the digits was scanned from letters zip code, altogether 4000 hand writing digits, 2000 are used for training set, 2000 are used for testing set.The training set recognition rate is 99.85%, the testing set recognition rate is 98.05%. If we used more complex decision strategy the system performance will be better.\n",
      "\n",
      "\n",
      "55\n",
      "A Neural-Network Dimension Reduction Method for Large-Set Pattern Classification*\n",
      "High-dimensional data are often too complex to be classified. K-L transformation is an effective dimension reduction method. However its result is not satisfactory in large-set pattern classification. In this paper a novel nonlinear dimension reduction method is presented and analyzed. The transform is achieved through a multi-layer feed-forward neural network trained with K-L transformation result. Experimental results show that this method is more effective than K-L transformation being applied in large-set pattern classification such as Chinese character recognition.\n",
      "\n",
      "\n",
      "56\n",
      "Local Subspace Classifier in Reproducing Kernel Hilbert Space\n",
      "Local Subspace Classifier(LSC) is a new classification technique, which is closely related to the subspace classification methods, and a heir of prototype classification methods. And it is superior to both of them. In this paper, a method of improving the performance of Local Subspace Classifier is presented. It is to avoid the intersection of the local subspaces representing the respective categories by mapping the original feature space into RKHS(Reproducing Kernel Hilbert Space).\n",
      "\n",
      "\n",
      "58\n",
      "Deformation Transformation for Handwritten Chinese Character Shape Correction\n",
      "In this paper, a novel 1-D deformation transformation based on trigonometric function for handwritten Chinese character shape correction is proposed. With a suitable selection of deformation parameters, the 1-D deformation transformation could deform a given handwritten Chinese character into 24 different handwriting styles. A deforming parameter controls the deformation degree for each style. The proposed deformation transformation could be applied as a non-linear shape correction method for Chinese character recognition. Our preliminary experiment has showed the effectiveness of the proposed approach.\n",
      "\n",
      "\n",
      "59\n",
      "Offline Handwritten Chinese Character Recognition Using Optimal Sampling Features\n",
      "For offline handwritten Chinese character recognition,stroke variation is the most difficult problem to be solved.A new method of optimal sampling features is proposed to compensate for the stroke variations and decrease the within-class pattern variability.In this method,we propose the concept of sampling features based on directional features that are widely used in offline Chinese character recognition.Optimal sampling features are then developed from sampling features by displacing the sampling positions under an optimal criterion.The algorithm for extracting optimal sampling features is proposed.The effectiveness of this method is widely tested using the Tsinghua University database (THCHR).\n",
      "\n",
      "\n",
      "61\n",
      "Off-Line Handwritten Chinese Character Recognition with Nonlinear Pre-classification\n",
      "In this paper,we describe a new Chinese character recognition system, in which neural networks are employed as a nonlinear pre-classifier to pre-classify similar Chinese characters,and an algorithm of clustering called Association Class Grouping algorithm (ACG)is hired to cluster similar Chinese characters. In our system,feature of contour direction is extracted to form a Bayesian classifier. Experiments have been conducted to recognize 3,755 Chinese Characters. The recognition rate is about 92%.\n",
      "\n",
      "\n",
      "62\n",
      "Detection of the Indicated Area with an Indication Stick\n",
      "This paper describes a detection method of indication action and the corresponding indicated area with a stick. In human communication, there exists ambiguity of indication action, so we need some useful knowledge about indication action. We propose a detection method of the indicated area based on the knowledge which we clarify by means of observation of some lectures. We formulate a potential value of intentional indication action of an instant, and cast the value for printed area using a weighted vote method. An experimental result shows that 85 percents of indication actions are correctly detected.\n",
      "\n",
      "\n",
      "63\n",
      "Heuristic Walkthroughs Evaluation of Pen-Based Chinese Word Edit System (PCWES) Usability\n",
      "An evaluation experiment was conducted to compare four interface styles:Hanwang Fixed Window,Translucent Mobile Single Window,Translucent Mobile Double Window,and No Window.Subjects tested the four styles on a pen_based word edit system in free-form mode.The result shows that traditional interface style of the Hanwang Fix Window didn’t satisfy the requirement of the nature interaction of the end user.And the TMDW mode are very suitable for user to perform the word processing task,in terms of the task performing time and mean accuracy rate.And the NW is the most nature and promising style,in terms of the subjective preference and the error rate of the performing time and accuracy rate of the experimental data.The experiment also shows that the moving window would influent the accuracy rate of the recognition. This experiment confirmed that a proper employment of interface style could improve the interactive efficiency of word editing systems.Also we give out some useful interface hints to improve the performance of the interface. Our tests for the first time give statistical support to the view that free pen_based interface is meaningful in the nature pen and gesture input of the word edit system.\n",
      "\n",
      "\n",
      "64\n",
      "Design and Realization of 3D Space Coordinate Serial Input\n",
      "This paper is about design and realization of communication circuit, which connects three-dimension coordinate input device to computer. Communication protocol and the key technique of device driver are published in this paper. It is told how the applied software is developed on the basis of communication protocol and driver. One applied example is introduced. This paper provides essential technique condition for a broad application of the device.\n",
      "\n",
      "\n",
      "65\n",
      "User’s Vision Based Multi-resolution Rendering of 3D Models in Distributed Virtual Environment DVENET\n",
      "Funded by National High Technology 863 Project, the distributed virtual environment network DVENET has been focused at incorporating realistic 3D visual simulation into a joint exercise. Visual tracking allows visual simulation to measure visual field and visual angle relied on by multi-resolution rendering techniques including LOD (level of detail), morphing and LOL (level of light), which economize the computational cost. Based on vision perception of user, this paper describes our recent research in real-time multi-resolution rendering of 3D models in virtual environment. This method calculates the critical parameters, such as view-distance, imaging parameter, brightness parameter, and so on, which control the switches between neighbor multiple resolution models and are correlative to user’s visual field and visual angle. It might also be utilized for kinds of simulators responding to the presence of the multi-resolution target but based on the special visions of infrared equipment or radar.\n",
      "\n",
      "\n",
      "66\n",
      "Vision-Based Registration Using 3-D Fiducial for Augmented Reality\n",
      "One of the key issues in the realization of Augmented Reality is the registration problem. Synthetically, vision-based registration can offer superior solutions. In several existing registration methods, 2-D objects or pictures are used as positioning fiducials, and at least two cameras and/or separate tracking devices are needed.A new registration method is proposed which uses a solid fiducial and a single color CCD camera.The new method significantly simplifies the registration system and eliminates tracker-to-camera errors.\n",
      "\n",
      "\n",
      "67\n",
      "The Study on Stereoscopic Image Generating Algorithm Based on Image Transformation\n",
      "Nowadays, image-base modeling is one of hotspots in the study of Computer graphics. Along with the requirement of putting the VR technology into real-life environment being enhanced, the immersion of the scene becomes more and more important. Allow for the complexity of the scenes, we have employed the approaches based on Digital image Transformation to obtain stereoscopic image. In this paper, the stereoscopic image generation algorithm based on the Stereo Vision and Digital image Transformation is given. At same time, image and video processing examples are presented to discuss the algorithm’s feasibility and practicability.\n",
      "\n",
      "\n",
      "69\n",
      "Penbuilder: Platform for the Development of Pen-Based User Interface\n",
      "Pen-based user interfaces is widely used in mobile computing environment, which provides natural, efficient interaction. It has substantial differences from any previous interface and it is difficult to be implemented. A welldesigned platform will improve the development of pen-based user interface. In this paper, the architecture of Pen-Book-Page-Paper is presented, which is extended from the metaphor of Pen-Paper. Penbuilder is a development platform based on this architecture. Pen-based user interface can be constructed from three layers of Penbuilder: modal-primitive layer, task-primitive layer and task layer. Each layer provides different extent supports for flexibility and reusability. The components of the platform are discussed in detail and some properties of the platform are argued. Penbuilder is also compliant for the development of distributed user interface. In the section of discussion, we analyze the platform through task tree. The platform provides full supports for extensibility and new interactive devices can be easily added.\n",
      "\n",
      "\n",
      "71\n",
      "Usability of Browser-Based Pen-Touch/Speech User Interfaces for Form-Based Applications in Mobile Environment\n",
      "This paper describes a speech interface system for the information retrieval services on the WWW and the experimental result of a usability evaluation for the form-based information retrieval tasks. We have presented a general speech interface system which can be basically applied to many menu-based information retrieval services on the WWW. The system enables additional speech input capability for a general WWW browser. A usability evaluation experiment of the speechenabled system for several existing menu-based information retrieval services is conducted and the results are compared with the case of a conventional system with pen-touch input mode. We also investigated the difference in the effect of usability for di.erent operating conditions.\n",
      "\n",
      "\n",
      "72\n",
      "A Lock Opening and Closing System with the Image Base Using a Cellular Phone through the Internet\n",
      "Now a day, we use cellular phones to display color images, characters, and to connect to the Internet. As an Internet applications for future generations, we built a system in which electric equipment was connected to a web server and controlled by a cellular phone. More specifically we constructed a system to open and close a door using a cellular phone. One of the most important problems is that nobody knows the condition of a room, if somebody is not present in the room. In order to solve this problem, a pan-tilt camera is set in the room. The web server can control this camera, and the user can select various directions from which the image can be taken. An automatic lock system is built with human detection. Movement and color information is used in aiding human detection. By experimenting with this automatic lock system, the security of this system was confirmed.\n",
      "\n",
      "\n",
      "75\n",
      "A Parallel Multistream Model for Integration of Sign Language Recognition and Lip Motion\n",
      "The parallel multistream model is proposed for integration sign language recognition and lip motion. The different time scales existing in sign language and lip motion can be tackled well using this approach. Primary experimental results have shown that this approach is efficient for integration of sign language recognition and lip motion. The promising results indicated that parallel multistream model can be a good solution in the framework of multimodal data fusion. An approach to recognize sign language with scalability with the size of vocabulary and a fast approach to locate lip corners are also proposed in this paper.\n",
      "\n",
      "\n",
      "81\n",
      "Multimodal Interface Techniques in Content-Based Multimedia Retrieval\n",
      "Multimodal interfaces (MI) can well improve the interactivity between users and computers through cooperation of different interactive devices and methods to exchange information and understand their requirements or response. As a hotspot in information processing, content- based retrieval (CBR) of multimedia has intrinsic demand for multimodal interface techniques to suit for input / output of multiple media types. In this paper, different MI techniques in CBR of multimedia are introduced, which are classified into three classes, namely traditional CUI/GUI, multimedia UI and intelligent multimodal UI. The analysis and comparison of these MI techniques with corresponded media retrieval ways are also given. It is hoped that the investigation in this paper can much promote the work both in MI and CBR of multimedia for efficient and effective information interaction between human and machines.\n",
      "\n",
      "\n",
      "82\n",
      "Design of Retrieval Method of Map Targets in the Multimodal Interface\n",
      "Multimodal interface is a part of computer technologies and plays an important role in many fields. The multimodal interface, which is efficient, flexible, and convenient, supports the system of CBIR strongly. In this paper, the method, by which map targets are retrieved in multimodal interface, has been studied. According to the characteristic that the different users do not have the same interest in the map targets, a concept model, which is called multi-user conceptual implication(MUCI), has been established to reflect the difference of map targets. The MUCI not only corresponds to hierarchies of categories of map targets, but also implicates the degree of user’s interest of categories. Once the map targets that users are interested in have been searched in MUCI, the targets of actual map can be quickly and accurately retrieved according to their color and shape and retrieval algorithms. The targets that are not important or less important can be ignored. The established method of this model, processes of reasoning and retrieval have been described in paper. In addition, the design and manipulation of data structure of map in multimodal interface have been illustrated. This multimodal interface has been used successfully in resource information system of a large oil field and the results are satisfying.\n",
      "\n",
      "\n",
      "84\n",
      "A Pragmatic Semantic Reliable Multicast Architecture for Distance Learning\n",
      "Although IP multicast has been rapidly evolving in the last few years, the current Internet is not fully multicast-enabled because of the lack of robust inter-domain routing and controlling protocols. In this paper, we present an alternative architecture for data distribution on Internet called PSRM that realizes semantic reliable, loose synchronized, multicast data delivery. PSRM is not based on global IP multicast, instead it uses a hybrid way to combine unicast delivery with multicast delivery. In PSRM, IP multicast is used only in local area, or multicast domain, to enhance the performance, and these multicast domains are organized into a spanning tree by TCP connections. As PSRM is based upon ALF protocol architecture, we use application-defined semantics to adapt content in a heterogeneous environment. PSRM have been implemented and demonstrated by a prototype distance learning application.\n",
      "\n",
      "\n",
      "85\n",
      "A Framework for Supporting Multimodal Conversational Characters in a Multi-agent System\n",
      "This paper discusses the computational framework for enabling multimodal conversational interface agents embodied in lifelike characters within a multi-agent environment. It is generally argued that one of the problems with such interface characters today is their inability to respond believably or adequately to the context of an interaction and the surrounding environment. Affective behaviour is used to better express responses to interaction context and provide more believable visual expressive responses. We describe an operational approach to enabling the computational perception required for the automated generation of affective behaviour through inter-agent communication in multi-agent real-time environments. The research is investigating the potential of extending current agent communication languages so as they not only convey the semantic content of knowledge exchange but also they can communicate affective attitudes about the shared knowledge. Providing a necessary component of the framework required for autonomous agent development with which we may bridge the gap between current research in psychological theory and practical implementation of social multi-agent systems.\n",
      "\n",
      "\n",
      "2002\n",
      "0\n",
      "Layered representations for human activity recognition\n",
      "We present the use of layered probabilistic representations using hidden Markov models for performing sensing, learning, and inference at multiple levels of temporal granularity We describe the use of representation in a system that diagnoses states of a user's activity based on real-time streams of evidence from video, acoustic, and computer interactions. We review the representation, present an implementation, and report on experiments with the layered representation in an office-awareness application.\n",
      "\n",
      "\n",
      "1\n",
      "Evaluating integrated speech- and image understanding\n",
      "The capability to coordinate and interrelate speech and vision is a virtual prerequisite for adaptive, cooperative, and flexible interaction among people. It is therefore fair to assume that human-machine interaction, too, would benefit from intelligent interfaces for integrated speech and image processing. We first sketch an interactive system that integrates automatic speech processing with image understanding. Then, we concentrate on performance assessment which we believe is an emerging key issue in multimodal interaction. We explain the benefit of time scale analysis and usability studies and evaluate our system accordingly.\n",
      "\n",
      "\n",
      "2\n",
      "Techniques for interactive audience participation\n",
      "At SIGGRAPH in 1991, Loren and Rachel Carpenter unveiled an interactive entertainment system that allowed members of a large audience to control an onscreen game using red and green reflective paddles. In the spirit of this approach, we present a new set of techniques that enable members of an audience to participate, either cooperatively or competitively, in shared entertainment experiences. Our techniques allow audiences with hundreds of people to control onscreen activity by (1) leaning left and right in their seats, (2) batting a beach ball while its shadow is used as a pointing device, and (3) pointing laser pointers at the screen. All of these techniques can be implemented with inexpensive, off the shelf hardware. Me have tested these techniques with a variety of audiences; in this paper we describe both the computer vision based implementation and the lessons we learned about designing effective content for interactive audience participation.\n",
      "\n",
      "\n",
      "3\n",
      "Perceptual collaboration in Neem\n",
      "The Neem Platform is a research test bed for Project Neem, concerned with the development of socially and culturally aware collaborative systems in a wide range of domains. In this paper we discuss a novel use of perceptual interfaces, applied to group collaboration support. In Neem, the multimodal content of human to human interaction is analyzed and reasoned upon. Applications react to this implicit communication by dynamically adapting their behavior according to the perceived group context. In contrast, perceptual interfaces have been traditionally, employed to handle explicit (multimodal) commands from users, and are as a rule not concerned with the communication that takes place among humans. The Neem Platform is a generic (application neutral) component-based evolvable framework that provides functionality that facilitates building such perceptual collaborative applications.\n",
      "\n",
      "\n",
      "4\n",
      "A tracking framework for collaborative human computer interaction\n",
      "The ability to track many people and their body parts (i.e., face and hands) in a complex environment is crucial for designing collaborative natural human computer interaction (HCI). A challenging issue in tracking body parts is the data association uncertainty while assigning measurements to the proper tracks in the case of occlusion and close interaction of body parts of different people. This paper describes a framework for tracking body parts of people in 2D/3D using a multiple hypothesis tracking (MHT) algorithm. A path coherence function has been incorporated along with MHT to reduce the negative effects of closely spaced measurements that produce unconvincing tracks and unnecessary computations. The performance of the framework has been validated using experiments on a real sequence of images.\n",
      "\n",
      "\n",
      "5\n",
      "A structural approach to distance rendering in personal auditory displays\n",
      "A virtual resonating environment aiming at enhancing our perception of distance is proposed. This environment reproduces the acoustics inside a tube, thus conveying peculiar distance cues to the listener. The corresponding resonator has been prototyped using a wave-based numerical scheme called waveguide mesh, that gave the necessary versatility to the model during the design and parameterization of the listening environment. Psychophysical tests show that this virtual environment conveys robust distance cues.\n",
      "\n",
      "\n",
      "6\n",
      "A multimodal electronic travel aid device\n",
      "This paper describes an electronic travel aid device, that may enable blind individuals to \"see the world with their ears\". A wearable prototype will be assembled using low-cost hardware: earphones, sunglasses fitted with two micro cameras, and a palmtop computer. The system, which currently runs on a desktop computer, is able to detect the light spot produced by a laser pointer, compute its angular position and depth, and generate a corresponding sound providing auditory cues for perception of the position and distance of the pointed surface patch. It permits different sonification modes that can be chosen by drawing, with the laser pointer, a predefined stroke which will be recognized by a hidden Markov model. In this way a blind person can use a common pointer as a replacement for the cane and will interact with the device using a flexible and natural sketch based interface.\n",
      "\n",
      "\n",
      "7\n",
      "Lecture and presentation tracking in an intelligent meeting room\n",
      "Archiving, indexing, and later browsing through stored presentations and lectures is increasingly being used. We have investigated the special problems and advantages of lectures and propose the design and adaptation of a speech recognizer to a lecture such that the recognition accuracy can be significantly improved by prior analysis of the presented documents using a special class-based language model. We define a tracking accuracy measure which measures how well a system can automatically align recognized words with parts of a presentation and show that by prior exploitation of the presented documents, the tracking accuracy can be improved. The system described in this paper is part of an intelligent meeting room developed in the European Union-sponsored project FAME (Facilitating Agent for Multicultural Exchange).\n",
      "\n",
      "\n",
      "8\n",
      "Parallel computing-based architecture for mixed-initiative spoken dialogue\n",
      "This paper describes a new method of implementing mixed-initiative spoken dialogue systems based on parallel computing architecture. In a mixed-initiative dialogue, the user as well as the system needs to be capable of controlling the dialogue sequence. In our implementation, various language models corresponding to different dialogue contents, such as requests for information or replies to the system, are built and multiple recognizers using these language models are driven under a parallel computing architecture. The dialogue content of the user is automatically detected based on likelihood scores given by the recognizers, and the content is used to build the dialogue. A transitional probability from one dialogue state uttering a kind of content to another state uttering a different content is incorporated into the likelihood score. A flexible dialogue structure that gives users the initiative to control the dialogue is implemented by this architecture. Real-time dialogue systems for retrieving information about restaurants and food stores are built and evaluated in terms of dialogue content identification rate and keyword accuracy. The proposed architecture has the advantage that the dialogue system can be easily modified without remaking the whole language model.\n",
      "\n",
      "\n",
      "9\n",
      "3D N-best search for simultaneous recognition of distant-talking speech of multiple talkers\n",
      "A microphone array is a promising solution for realizing hands-free speech recognition in real environments. Accurate talker localization is very important for speech recognition using the microphone array. However, localization of a moving talker is difficult in noisy reverberant environments. Talker localization errors degrade the performance of speech recognition. To solve the problem, we proposed a new speech recognition algorithm which considers multiple talker direction hypotheses simultaneously. The proposed algorithm performs Viterbi search in 3-dimensional trellis space composed of talker directions, input frames, and HMM states. In this paper we describe a new simultaneous recognition algorithm for distant-talking speech of multiple talkers using the extended 3D N-best search algorithm. The algorithm exploits path distance-based clustering and a likelihood normalization technique appeared to be necessary in order to build an efficient system for our purpose. We evaluated the proposed method using reverberated data, which are those simulated by the image method and recorded in a real room. The image method was used to find the accuracy-reverberation time relationship, and real data was used to evaluate the real performance of our algorithm. The Top 3 result of simultaneous word accuracy was 73.02% under 162 ms reverberation time using the image method.\n",
      "\n",
      "\n",
      "10\n",
      "Integration of tone related feature for Chinese speech recognition\n",
      "Chinese is a tonal language that uses fundamental frequency, in addition to phones for word differentiation. Commonly used front-end features, such as mel-frequency cepstral coefficients (MFCC), however, are optimized for non-tonal languages such as English and are not mainly focused on pitch information that is important for tone identification. In this paper, we examine the integration of tone-related acoustic features for Chinese recognition. We propose the use of the cepstrum method (CEP), which uses the same configurations as in MFCC extraction for the extraction of pitch-related features. The pitch periods extracted from the CEP algorithm can be used directly for speech recognition and do not require any special treatment for unvoiced frames. In addition, we explore a number of feature transformations and find that the addition of a properly normalized and transformed set of pitch related-features can reduce the recognition error rate from 34.61% to 29.45% on the Chinese 1998 National Performance Assessment (Project 863) corpus.\n",
      "\n",
      "\n",
      "11\n",
      "Talking heads: which matching between faces and synthetic voices?\n",
      "The integration of synthetic faces and text-to-speech voice synthesis (what we call \"talking heads\") allows new applications in the area of man-machine interfaces. In the near future, talking heads might be useful communicative interface agents. But before making an extensive use of talking heads, several issues have to be checked according to their acceptability by users. An important issue is to make sure that the used synthetic voices match their faces. The scope of this paper is to study the coherence that might exist between synthetic voices and faces. Twenty-four subjects rated the coherence of all the combinations between ten faces and six voices. The main results of this paper show that not all associations between faces and voices are relevant and that some associations are better rated than others according to qualitative criteria.\n",
      "\n",
      "\n",
      "12\n",
      "Robust noisy speech recognition with adaptive frequency bank selection\n",
      "With the development of automatic speech recognition technology, the robustness problem of speech recognition systems is becoming more and more important. This paper addresses the problem of speech recognition in an additive background noise environment. Since the frequency energy of different types of noise focuses on different frequency banks, the effects of additive noise on each frequency bank are different. The seriously obscured frequency banks have little word signal information left, and are harmful for subsequence speech processing. Wu and Lin (2000) applied the frequency bank selection theory to robust word boundary detection in a noisy environment, and obtained good detection results. In this paper, this theory is extended to noisy speech recognition. Unlike the standard MFCC which uses all frequency banks for cepstral coefficients, we only use the frequency banks that are slightly corrupted and discard the seriously obscured ones. Cepstral coefficients are calculated only on the selected frequency banks. Moreover, an acoustic model is also adapted to match the modification of the acoustic feature. Experiments on continuous digital speech recognition show that the proposed algorithm leads to better performance than spectral subtraction and cepstral mean normalization at low SNRs.\n",
      "\n",
      "\n",
      "13\n",
      "Covariance-tied clustering method in speaker identification\n",
      "Gaussian mixture models (GMMs) have been successfully applied to the classifier for speaker modeling in speaker identification. However, there are still problems to solve, such as the clustering methods. The conditional k-means algorithm utilizes Euclidean distance taking all data distribution as sphericity, which is not the distribution of the actual data. In this paper we present a new method making use of covariance information to direct the clustering of GMMs, namely covariance-tied clustering. This method consists of two parts: obtaining covariance matrices using the data sharing technique based on a binary tree, and making use of covariance matrices to direct clustering. The experimental results prove that this method leads to worthwhile reductions of error rates in speaker identification. Much remains to be done to explore fully the covariance information.\n",
      "\n",
      "\n",
      "14\n",
      "Context-based multimodal input understanding in conversational systems\n",
      "In a multimodal human-machine conversation, user inputs are often abbreviated or imprecise. Sometimes, merely fusing multimodal inputs together cannot derive a complete understanding. To address these inadequacies, we are building a semantics-based multimodal interpretation framework called MIND (Multimodal Interpretation for Natural Dialog). The unique feature of MIND is the use of a variety of contexts (e.g., domain context and conversation context) to enhance multimodal fusion. In this paper we present a semantically rich modeling scheme and a context-based approach that enable MIND to gain a full understanding of user inputs, including ambiguous and incomplete ones.\n",
      "\n",
      "\n",
      "15\n",
      "Context-sensitive help for multimodal dialogue\n",
      "Multimodal interfaces offer users unprecedented flexibility in choosing a style of interaction. However, users are frequently unaware of or forget shorter or more effective multimodal or pen-based commands. This paper describes a working help system that leverages the capabilities of a multimodal interface in order to provide targeted, unobtrusive, context-sensitive help. This multimodal help system guides the user to the most effective way to specify a request, providing transferable knowledge that can be used in future requests without repeatedly invoking the help system.\n",
      "\n",
      "\n",
      "16\n",
      "Referring to objects with spoken and haptic modalities\n",
      "The gesture input modality considered in multimodal dialogue systems is mainly reduced to pointing or manipulating actions. With an approach based on spontaneous character of the communication, the treatment of such actions involves many processes. Without constraints, the user may use gesture in association with speech, and may exploit visual context peculiarities, guiding her/his articulation of gesture trajectories and her/his choice of words. Semantic interpretation of multimodal utterances also becomes a complex problem, taking into account varieties of referring expressions, varieties of gestural trajectories, structural parameters from the visual context, and also directives from a specific task. Following the spontaneous approach, we propose to give maximal understanding capabilities to dialogue systems, to ensure that various interaction modes must be taken into account. Considering the development of haptic sense devices (such as PHANToM) which increase the capabilities of sensations, particularly tactile and kinesthetic, we propose to explore a new domain of research concerning the integration of haptic gesture into multimodal dialogue systems, in terms of its possible associations with speech for object reference and manipulation. We focus on the compatibility between haptic gesture and multimodal reference models, and on the consequences of processing this new modality on intelligent system architectures, which has been sufficiently studied from a semantic point of view.\n",
      "\n",
      "\n",
      "17\n",
      "Towards visually-grounded spoken language acquisition\n",
      "A characteristic shared by most approaches to natural language understanding and generation is the use of symbolic representations of word and sentence meanings. Frames and semantic nets are examples of symbolic representations. Symbolic methods are inappropriate for applications which require natural language semantics to be linked to perception, as is the case in tasks such as scene description or human-robot interaction. This paper presents two implemented systems, one that learns to generate, and one that learns to understand visually-grounded spoken language. These implementations are part of our on-going effort to develop a comprehensive model of perceptually-grounded semantics.\n",
      "\n",
      "\n",
      "18\n",
      "Modeling output in the EMBASSI multimodal dialog system\n",
      "In this paper we present the concept for abstract modeling of output render components. We illustrate how this categorization serves to seamlessly integrate previously unknown output multimodalities coherently into multimodal presentations of the EMBASSI dialog system. We present a case study and conclude with an overview of related work.\n",
      "\n",
      "\n",
      "19\n",
      "Multimodal dialogue systems for interactive TV applications\n",
      "Many studies have shown the advantages of building multimodal systems, but not in the interactive TV application context. This paper reports on a qualitative study of a multimodal program guide for interactive TV. The system was designed by adding speech interaction to an existing TV program guide. Results indicate that spoken natural language input combined with visual output is preferable for TV applications. Furthermore, user feedback requires a clear distinction between the dialogue system's domain result and system status in the visual output. Consequently, we propose an interaction model that consists of three entities: user, domain results, and system feedback.\n",
      "\n",
      "\n",
      "20\n",
      "Human-robot interaction: engagement between humans and robots for hosting activities\n",
      "To participate in conversations with people, robots must not only see and talk to people, but must also make use of the conventions of conversation and connection to their human counterparts. This paper reports on research on engagement in human-human interaction and applications to (non-autonomous) robots interacting with humans in hosting activities.\n",
      "\n",
      "\n",
      "21\n",
      "Viewing and analyzing multimodal human-computer tutorial dialogue: a database approach\n",
      "It is easier to record logs of multimodal human-computer tutorial dialogue than to make sense of them. In the 2000-2001 school year, we logged the interactions of approximately 400 students who used Project LISTEN's Reading Tutor and who read aloud over 2.4 million words. We discuss some difficulties we encountered converting the logs into a more easily understandable database. It is faster to write SQL queries to answer research questions than to analyze complex log files each time. The database also permits us to construct a viewer to examine individual Reading Tutor-student interactions. This combination of queries and viewable data has turned out to be very powerful, and we discuss how we have combined them to answer research questions.\n",
      "\n",
      "\n",
      "22\n",
      "Adaptive dialog based upon multimodal language acquisition\n",
      "Communicating by voice with speech-enabled computer applications based on preprogrammed rule grammars suffers from constrained vocabulary and sentence structures. Deviations from the allowed language result in an unrecognized utterance that will not be understood and processed by the system. One way to alleviate this restriction consists in allowing the user to expand the computer's recognized and understood language by teaching the computer system new language knowledge. We present an adaptive dialog system capable of learning from users new words, phrases and sentences, and their corresponding meanings. User input incorporates multiple modalities, including speaking, typing, pointing, drawing and image capturing. The allowed language can thus be expanded in real time by users according to their preferences. By acquiring new language knowledge the system becomes more capable in specific tasks, although its language is still constrained.\n",
      "\n",
      "\n",
      "23\n",
      "Integrating emotional cues into a framework for dialogue management\n",
      "Emotions are very important in human-human communication but are usually ignored in human-computer interaction. Recent work focuses on recognition and generation of emotions as well as emotion driven behavior. Our work focuses on the use of emotions in dialogue systems that can be used with speech input or as well in multi-modal environments. We describe a framework for using emotional cues in a dialogue system and their informational characterization. We describe emotion models that can be integrated into the dialogue system and can be used in different domains and tasks. Our application of the dialogue system is planned to model multi-modal human-computer-interaction with a humanoid robotic system.\n",
      "\n",
      "\n",
      "24\n",
      "Data driven design of an ANN/HMM system for on-line unconstrained handwritten character recognition\n",
      "This paper is dedicated to a data driven design method for a hybrid ANN/HMM based handwriting recognition system. On one hand, a data driven designed neural modelling of handwriting primitives is proposed. ANNs are firstly used as state models in a HMM primitive divider that associates each signal frame with an ANN by minimizing the accumulated prediction error. Then, the neural modelling is realized by training each network on its own frame set. Organizing these two steps in an EM algorithm, precise primitive models are obtained. On the other hand, a data driven systematic method is proposed for the HMM topology inference task. All possible prototypes of a pattern class are firstly merged into several clusters by a tabu search aided clustering algorithm. Then a multiple parallel-path HMM is constructed for the pattern class. Experiments prove an 8% recognition improvement with a saving of 50% of system resources, compared to an intuitively designed referential ANN/HMM system.\n",
      "\n",
      "\n",
      "25\n",
      "Gesture patterns during speech repairs\n",
      "Speech and gesture are two primary modes used in natural human communication; hence, they are important inputs for a multimodal interface to process. One of the challenges for multimodal interfaces is to accurately recognize the words in spontaneous speech. This is partly due to the presence of speech repairs, which seriously degrade the accuracy of current speech recognition systems. Based on the assumption that speech and gesture arise from the same thought process, we would expect to find patterns of gesture that co-occur with speech repairs that can be exploited by a multimodal processing system to more effectively process spontaneous speech. To evaluate this hypothesis, we have conducted a measurement study of gesture and speech repair data extracted from videotapes of natural dialogs. Although we have found that gestures do not always co-occur with speech repairs, we observed that modification gesture patterns have a high correlation with content replacement speech repairs, but rarely occur with content repetitions. These results suggest that gesture patterns can help us to classify different types of speech repairs in order to correct them more accurately.\n",
      "\n",
      "\n",
      "26\n",
      "Prosody based co-analysis for continuous recognition of coverbal gestures\n",
      "Although recognition of natural speech and gestures have been studied extensively, previous attempts at combining them in a unified framework to boost classification were mostly semantically motivated, e.g., keyword-gesture co-occurrence. Such formulations inherit the complexity of natural language processing. This paper presents a Bayesian formulation that uses a phenomenon of gesture and speech articulation for improving accuracy of automatic recognition of continuous coverbal gestures. The prosodic features from the speech signal were co-analyzed with the visual signal to learn the prior probability of co-occurrence of the prominent spoken segments with the particular kinematical phases of gestures. It was found that the above co-analysis helps in detecting and disambiguating small hand movements, which subsequently improves the rate of continuous gesture recognition. The efficacy of the proposed approach was demonstrated on a large database collected front the weather channel broadcast. This formulation opens new avenues for bottom-up frameworks of multimodal integration.\n",
      "\n",
      "\n",
      "27\n",
      "Purdue RVL-SLLL ASL database for automatic recognition of American Sign Language\n",
      "This article reports on an extensive database of American Sign Language (ASL) motions, handshapes, words and sentences. Research on automatic recognition of ASL requires a suitable database for the training and the testing of algorithms. The databases that are currently available do not allow for algorithmic development that requires a step-by-step approach to ASL recognition-from the recognition of individual handshapes, to the recognition of motion primitives, and finally, to the recognition of full sentences. We have sought to remove these deficiencies in a new database-the Purdue RVL-SLLL ASL database.\n",
      "\n",
      "\n",
      "28\n",
      "The role of gesture in multimodal referring actions\n",
      "When deictic gestures are produced on a touch screen, they can take forms which can lead to several sorts of ambiguities. Considering that the resolution of a multimodal reference requires the identification of the referents and of the context (\"reference domain\") from which these referents are extracted, we focus on the linguistic, gestural, and visual clues that a dialogue system may exploit to comprehend the referring intention. We explore the links between words, gestures and perceptual groups, doing so in terms of the clues that delimit the reference domain. We also show the importance of taking the domain into account for dialogue management, particularly for the comprehension of further utterances, when they seem to implicitly use a pre-existing restriction to a subset of objects. We propose a strategy of multimodal reference resolution based on this notion of reference domain, and we illustrate its efficiency with prototypic examples built from a study of significant referring situations extracted from a corpus. We also present the future directions of our works, concerning some linguistic and task aspects that are not integrated here.\n",
      "\n",
      "\n",
      "29\n",
      "Hand gesture symmetric behavior detection and analysis in natural conversation\n",
      "We present an experimental investigation into the phenomenon of gestural symmetry for two-handed gestures accompanying speech. We describe an approach to compute hand motion symmetries based on the correlation computations. Local symmetries are detected using a windowing operation. We demonstrate that the selection of a smaller window size results in better sensitivity to local symmetries at the expense of noise in the form of spurious symmetries and 'symmetry dropoffs'. Our algorithm applies a 'hole filling' post process to address these detection problems. We examine the role of the detected motion symmetries of two-handed gestures in the structuring of speech. We compared discourse segments corresponding to extracted symmetries in two natural conversations against a discourse analysis by expert psycholinguistic coders. These comparisons illustrate the effectiveness of the symmetry feature for the understanding of underlying discourse structure. We believe that this basic characteristic of two-handed gestures accompanying speech must be incorporated in any multimodal interaction system involving two-handed gestures and speech.\n",
      "\n",
      "\n",
      "30\n",
      "A multi-class pattern recognition system for practical finger spelling translation\n",
      "The paper presents a portable system and method for recognizing the 26 hand shapes of the American Sign Language alphabet, using a novel glove-like device. Two additional signs, 'space', and 'enter' are added to the alphabet to allow the user to form words or phrases and send them to a speech synthesizer. Since the hand shape for a letter varies from one signer to another, this is a 28-class pattern recognition system. A three-level hierarchical classifier divides the problem into \"dispatchers\" and \"recognizers.\" After reducing pattern dimension from ten to three, the projection of class distributions onto horizontal planes makes it possible to apply simple linear discrimination in 2D, and Bayes' Rule in those cases where classes had features with overlapped distributions. Twenty-one out of 26 letters were recognized with 100% accuracy; the worst case, letter U, achieved 78%.\n",
      "\n",
      "\n",
      "31\n",
      "A map-based system using speech and 3D gestures for pervasive computing\n",
      "We describe an augmentation of Quickset, a multimodal voice/pen system that allows users to create and control map-based, collaborative, interactive simulations. In this paper, we report on our extension of the graphical pen input mode front stylus/mouse to 3D hand movements. To do this, the map is projected onto a virtual plane in space, specified by the operator before the start of the interactive session. We then use our geometric model to compute the intersection of hand movements with the virtual plane, translating these into map coordinates on the appropriate system. The goal of this research is the creation of a body-centered, multimodal architecture employing both speech and 3D hand gestures, which seamlessly, and unobtrusively supports distributed interaction. The augmented system, built on top of an existing architecture, also provides an improved visualization, management and awareness of a shared understanding. Potential applications of this work include telemedicine, battlefield management and any kind of collaborative decision-making during which users may wish to be mobile.\n",
      "\n",
      "\n",
      "32\n",
      "Hand tracking using spatial gesture modeling and visual feedback for a virtual DJ system\n",
      "The ability to accurately track hand movement provides new opportunities for human computer interaction (HCI). Many of today's commercial hand tracking devices based on gloves can be cumbersome and expensive. An approach that avoids these problems is to use computer vision to capture hand motion. We present a complete real-time hand tracking and 3-D modeling system based on a single camera. In our system, we extract feature points from a video stream of a hand to control a virtual hand model with 2-D global motion and 3-D local motion. The on screen model gives the user instant feedback on the estimated position of the hand. This visual feedback allows a user to compensate for the errors in tracking. The system is used for three example applications. The first application uses hand tracking and gestures to take on the role of the mouse. The second interacts with a 3D virtual environment using the 3D hand model. The last application is a virtual DJ system that is controlled by hand motion tracking and gestures.\n",
      "\n",
      "\n",
      "33\n",
      "State sharing in a hybrid neuro-Markovian on-line handwriting recognition system through a simple hierarchical clustering algorithm\n",
      "HMM has been largely applied in many fields with great success. To achieve a better performance, an easy way is using more states or more free parameters for a better signal modelling. Thus, state sharing and state clipping methods have been proposed to reduce parameter redundancy and to limit the explosive consummation of system resources. We focus on a simple state sharing method for a hybrid neuro-Markovian on-line handwriting recognition system. At first, a likelihood-based distance is proposed for measuring the similarity between two HMM state models. Afterwards, a minimum quantification error aimed hierarchical clustering algorithm is also proposed to select the most representative models. Here, models are shared to the most under the constraint of the minimum system performance loss. As the result, we maintain about 98% of the system performance while about 60% of the parameters are reduced.\n",
      "\n",
      "\n",
      "34\n",
      "An automatic speech translation system on PDAs for travel conversation\n",
      "We present an automatic speech-to-speech translation system for personal digital assistants (PDAs) that helps oral communication between Japanese and English speakers in various situations while traveling. Our original compact large vocabulary continuous speech recognition engine, compact translation engine based on a lexicalized grammar, and compact Japanese speech synthesis engine lead to the development of a Japanese/English bi-directional speech translation system that works with limited computational resources.\n",
      "\n",
      "\n",
      "35\n",
      "A PDA-based sign translator\n",
      "We propose an effective approach for a PDA-based sign system and present the sign translator. Its main functions include three parts: detection, recognition and translation. Automatic detection and recognition of text in natural scenes is a prerequisite for the automatic sign translator. In order to make the system robust for text detection in various natural scenes, the detection approach efficiently embeds multi-resolution, adaptive search in a hierarchical framework with different emphases at each layer. We also introduce an intensity-based OCR method to recognize characters in various fonts and lighting conditions, where we employ the Gabor transform to obtain local features, and LDA for selection and classification of features. The recognition rate is 92.4% for the testing set obtained from the natural sign. A sign is different from the normal used sentence. It is brief with a lot of abbreviations and place nouns. We only briefly introduce a rule-based place name translation. We have integrated all these functions in a PDA, which can capture sign images, auto segment and recognize the Chinese sign, and translate it into English.\n",
      "\n",
      "\n",
      "36\n",
      "The NESPOLE! multimodal interface for cross-lingual communication $experience and lessons learned\n",
      "We describe the design, evolution, and development of the user interface components of the NESPOLE! speech-to-speech translation system. The NESPOLE! system was designed for users with medium-to-low levels of computer literacy and Web expertise. The user interface was designed to effectively combine Web browsing, real-time sharing of graphical information and multi-modal annotations using a shared whiteboard, and real-time multilingual speech communication, all within an e-commerce scenario. Data collected in sessions with naive users in several stages in the process of system development formed the basis for improving the effectiveness and usability of the system. We describe this development process, the resulting interface components and the lessons learned.\n",
      "\n",
      "\n",
      "37\n",
      "Research of machine learning method for specific information recognition on the Internet\n",
      "With the available resources on the Internet becoming plentiful, a large amount of harmful information is permeating in and has been seriously affecting people's normal work and living. Therefore, harmful data streams must be recognized and filtered out effectively. After analyzing some harmful contents in Internet information streams, we present a new method, which recognizes specific information by machine learning (ML). We extracted key information from a number of corpuses through the ML method to obtain the part of speech (POS) transfer-form for key information by learning from corpuses, which is based on the same pronunciation matching of key information. Furthermore, the testing value of key information will be obtained in a real corpus to examine the likelihood between matching rules from information streams and those learnt from corpuses through the average value of POS transfer probability of key information. Therefore, the testing value for the whole real data stream will be obtained The experiment proved that the method was efficient for recognizing certain Internet harmful information.\n",
      "\n",
      "\n",
      "38\n",
      "The added value of multimodality in the NESPOLE! speech-to-speech translation system: an experimental study\n",
      "Multimodal interfaces, which combine two or more input modes (speech, pen, touch...), are expected to be more efficient, natural and usable than single-input interfaces. However, the advantage of multimodal input has only been ascertained in highly controlled experimental conditions (S.L. Oviatt, 1997; 1999); in particular, we lack data about what happens with \"real\" human-human, multilingual communication systems. We discuss the results of an experiment aiming to evaluate the added value of multimodality in a \"true\" speech-to-speech translation system, the NESPOLE! system, which provides for multilingual and multimodal communication in the tourism domain, allowing users to interact through the Internet sharing maps, Web-pages and pen-based gestures. We compared two experimental conditions differing as to whether multimodal resources were available: a speech-only condition (SO), and a multimodal condition (MM). Most of the data show tendencies for MM to be better than SO.\n",
      "\n",
      "\n",
      "39\n",
      "Multi-modal translation system and its evaluation\n",
      "Speech-to-speech translation has been studied to realize natural human communication beyond language barriers. Toward further multi-modal natural communication, visual information such as face and lip movements will be necessary. We introduce a multi-modal English-to-Japanese and Japanese-to-English translation system that also translates the speaker's speech motion while synchronizing it to the translated speech. To retain the speaker's facial expression, we substitute only the speech organ's image with the synthesized one, which is made by a three-dimensional wire-frame model that is adaptable to any speaker. Our approach enables image synthesis and translation with an extremely small database. We conduct subjective evaluation tests using the connected digit discrimination test using data with and without audio-visual lip-synchronization. The results confirm the significant quality of the proposed audio-visual translation system and the importance of lip-synchronization.\n",
      "\n",
      "\n",
      "40\n",
      "Towards universal speech recognition\n",
      "The increasing interest in multilingual applications like speech-to-speech translation systems is accompanied by the need for speech recognition front-ends in many languages that can also handle multiple input languages at the same time. We describe a universal speech recognition system that fulfills such needs. It is trained by sharing speech and text data across languages and thus reduces the number of parameters and overhead significantly at the cost of only slight accuracy loss. The final recognizer eases the burden of maintaining several monolingual engines, makes dedicated language identification obsolete and allows for code-switching within an utterance. To achieve these goals we developed new methods for constructing multilingual acoustic models and multilingual n-gram language models.\n",
      "\n",
      "\n",
      "41\n",
      "Improved named entity translation and bilingual named entity extraction\n",
      "Translation of named entities (NE), including proper names, temporal and numerical expressions, is very important in multilingual natural language processing, like crosslingual information retrieval and statistical machine translation. We present an integrated approach to extract a named entity translation dictionary from a bilingual corpus while at the same time improving the named entity annotation quality. Starting from a bilingual corpus where the named entities are extracted independently for each language, a statistical alignment model is used to align the named entities. An iterative process is applied to extract named entity pairs with higher alignment probability. This leads to a smaller but cleaner named entity translation dictionary and also to a significant improvement of the monolingual named entity annotation quality for both languages. Experimental result shows that the dictionary size is reduced by 51.8% and the annotation quality is improved from 70.03 to 78.15 for Chinese and 73.38 to 81.46 in terms of F-score.\n",
      "\n",
      "\n",
      "42\n",
      "Active gaze tracking for human-robot interaction\n",
      "In our effort to make human-robot interfaces more user-friendly, we built an active gaze tracking system that can measure a person's gaze direction in real-time. Gaze normally tells which object in his/her surrounding a person is interested in. Therefore, it can be used as a medium for human-robot interaction like instructing a robot arm to pick a certain object a user is looking at. We discuss how we developed and put together algorithms for zoom camera calibration, low-level control of active head, face and gaze tracking to create an active gaze tracking system.\n",
      "\n",
      "\n",
      "43\n",
      "3-D articulated pose tracking for untethered diectic reference\n",
      "Arm and body pose are useful cues for diectic reference - users naturally extend their arms to objects of interest in a dialog. We present recent progress on untethered sensing of articulated arm and body configuration using robust stereo vision techniques. These techniques allow robust, accurate, real-time tracking of 3D position and orientation. We demonstrate users' performance with our system on object selection tasks and describe our initial efforts to integrate this system into a multimodal conversational dialog framework.\n",
      "\n",
      "\n",
      "44\n",
      "Tracking focus of attention in meetings\n",
      "The author presents an overview of his work on tracking focus of attention in meeting situations. He has developed a system capable of estimating participants' focus of attention from multiple cues. In the system he employs an omni-directional camera to simultaneously track the faces of participants sitting around a meeting table and uses neural networks to estimate their head poses. In addition, he uses microphones to detect who is speaking. The system predicts participants' focus of attention from acoustic and visual information separately, and then combines the output of the audio- and video-based focus of attention predictors. In addition he reports recent experimental results: In order to determine how well we can predict a subject's focus of attention solely on the basis of his or her head orientation, he has conducted an experiment in which he recorded head and eye orientations of participants in a meeting using special tracking equipment. The results demonstrate that head orientation was a sufficient indicator of the subjects' focus target in 89% of the time. Furthermore he discusses how the neural networks used to estimate head orientation can be adapted to work in new locations and under new illumination conditions.\n",
      "\n",
      "\n",
      "45\n",
      "A probabilistic dynamic contour model for accurate and robust lip tracking\n",
      "In this paper a new condensation style contour tracking method called probabilistic dynamic contour (PDC) is proposed for lip tracking: a novel mixture dynamic model is designed to represent shape more compactly and to tolerate larger motions between frames, a measurement model is designed to include multiple visual cues. The proposed PDC tracker has the advantage that it is conceptually general but effectively suitable for lip tracking with the designed dynamic and measurement model. The new tracker improves the traditional condensation style tracker in three aspects: Firstly, the dynamic model is partially derived from the image sequence, so the tracker does not need to learn the dynamics in advance. Secondly, the measurement model is easy to be updated during tracking, which avoids modeling the foreground object in prior. Thirdly, to improve the tracker's speed, a compact representation of shape and a noise model are proposed to reduce the samples required to represent the posterior distribution. An experiment on lip contour tracking shows that the proposed method tracks contours robustly as well as accurately compared to the existing tracking method.\n",
      "\n",
      "\n",
      "46\n",
      "Attentional object spotting by integrating multimodal input\n",
      "An intelligent human-computer interface is expected to allow computers to work with users in a cooperative manner. To achieve this goal, computers need to be aware of user attention and provide assistance without explicit user requests. Cognitive studies of eye movements suggest that in accomplishing well-learned tasks, the performer's focus of attention is locked onto ongoing work and more than 90% of eye movements are closely related to the objects being manipulated in the tasks. In light of this, we have developed an attentional object spotting system that integrates multimodal data consisting of eye position, head position and video from the \"first-person\" perspective. To detect the user's focus of attention, we modeled eye gaze and head movements using a hidden Markov model (HMM) representation. For each attentional point in time, the object of user interest is automatically extracted and recognized. We report the results of experiments on finding attentional objects in the natural task of \"making a peanut-butter sandwich\".\n",
      "\n",
      "\n",
      "47\n",
      "Lip tracking for MPEG-4 facial animation\n",
      "It is very important to accurately track the mouth of a talking person for many applications, such as face recognition and human computer interaction. This is in general a difficult problem due to the complexity of shapes, colors, textures, and changing lighting conditions. We develop techniques for outer and inner lip tracking. From the tracking results FAPs are extracted which are used to drive an MPEG-4 decoder. A novel method consisting of a Gradient Vector Flow (GVF) snake with a parabolic template as an additional external force is proposed. Based on the results of the outer lip tracking, the inner lip is tracked using a similarity function and a temporal smoothness constraint. Numerical results are presented using the Bernstein database.\n",
      "\n",
      "\n",
      "48\n",
      "Achieving real-time lip-synch via SVM-based phoneme classification and lip shape refinement\n",
      "In this paper, we develop a real time lip-synch system that activates a 2D avatar's lip motion in synch with incoming speech utterance. To realize \"real time\" operation of the system, we contain the processing time by invoking a merge and split procedure performing coarse-to-fine phoneme classification. At each stage of phoneme classification, we apply a support vector machine (SVM) to constrain the computational load while attaining desirable accuracy. Coarse-to-fine phoneme classification is accomplished via 2 stages of feature extraction, where each speech frame is acoustically analyzed first for 3 classes of lip opening using MFCC as the feature and then a further refined classification for detailed lip shape using formant information. We implemented the system with 2D lip animation that shows the effectiveness of the proposed 2-stage procedure accomplishing the real-time lip-synch task.\n",
      "\n",
      "\n",
      "49\n",
      "Multi-modal temporal asynchronicity modeling by product HMMs for robust audio-visual speech recognition\n",
      "The demand for audio-visual speech recognition (AVSR) has increased in order to make speech recognition systems robust to acoustic noise. There are two kinds of research issue in audio-visual speech recognition, such as integration modeling considering asynchronicity between modalities and adaptive information weighting according information reliability. This paper proposes a method to effectively integrate audio and visual information. Such integration, inevitably, necessitates modeling the synchronization and asynchronization of audio and visual information. To address the time lag and correlation problems in individual features between speech and lip movements, we introduce a type of integrated HMM modeling of audio-visual information based on a family of a product HMM. The proposed model can represent state synchronicity not only within a phoneme, but also between phonemes. Furthermore, we also propose a rapid stream weight optimization based on the GPD algorithm for noisy, bimodal speech recognition. Evaluation experiments show that the proposed method improves the recognition accuracy for noisy speech. When SNR=0 dB our proposed method attained 16% higher performance compared to a product HMM without synchronicity re-estimation.\n",
      "\n",
      "\n",
      "50\n",
      "A multi-modal interface for an interactive simulated vascular reconstruction system\n",
      "This paper is devoted to multi-modal interface design and implementation of a simulated vascular reconstruction system. It provides multi-modal interaction methods such as speech recognition, hand gestures, direct manipulation of virtual 3D objects and measurement tools. The main challenge is that no general interface scenario in existence today can satisfy all the users of the system (radiologists, vascular surgeons, medical students, etc.). The potential users of the system can vary by their skills, expertise level, habits and psycho-motional characteristics. To make a multimodal interface user-friendly is a crucial issue. In this paper we introduce an approach to develop such an efficient, user-friendly multi-modal interaction system. We focus on adaptive interaction as a possible solution to address the variety of end-users. Based on a user model, the adaptive user interface identifies each individual by means of a set of criteria and generates a customized exploration environment.\n",
      "\n",
      "\n",
      "51\n",
      "Universal interfaces to multimedia documents\n",
      "Electronic documents theoretically have great advantages for people with print disabilities, although currently this potential is not being realized. This paper reports research to develop multimedia documents with universal interfaces which can be configured to the needs of people with a variety of print disabilities. The implications of enriching multimedia documents with additional and alternative single media objects is discussed and an implementation using HTML + TIME has been undertaken.\n",
      "\n",
      "\n",
      "52\n",
      "A video based interface to textual information for the visually impaired\n",
      "We describe the development of an interface to textual information for the visually impaired that uses video, image processing, optical-character-recognition (OCR) and text-to-speech (TTS). The video provides a sequence of low resolution images in which text must be detected, rectified and converted into high resolution rectangular blocks that are capable of being analyzed via off-the-shelf OCR. To achieve this, various problems related to feature detection, mosaicing, auto-focus, zoom, and systems integration were solved in the development of the system.\n",
      "\n",
      "\n",
      "53\n",
      "Modular approach of multimodal integration in a virtual environment\n",
      "We present a novel modular approach to integrating multiple input/output (I/O) modes in a virtual environment that imitate natural, intuitive and effective human interaction behavior. The I/O modes used in this research are spatial tracking of both hands, finger gesture recognition, head/body spatial tracking, voice recognition (discrete recognition for simple commands, and continuous recognition for natural language input), immersive stereo display and synthesized speech output. Intuitive natural interaction is achieved through several stages: identifying all the tasks that need to be performed, grouping similar tasks and assigning them to a particular mode such that it imitates the physical world. This modular approach allows inclusion and removal of additional input and output modes as well as additional users. We described this multimodal interaction paradigm by applying it to a real world application: visualizing, modeling and fitting protein molecular structures in an immersive virtual environment.\n",
      "\n",
      "\n",
      "54\n",
      "Mobile multi-modal data services for GPRS phones and beyond\n",
      "The paper discusses means to build multi-modal data services in existing GPRS infrastructures, and puts the proposed simple solutions into the perspective of technological possibilities that will become available in public mobile communications networks over the next few years along the progression path from 2G/GSM systems, through GPRS, to 3G systems like UMTS, or equivalently to 802.11 networks. Three demonstrators are presented, which were developed by the authors in an application-oriented research project co-financed by telecommunications companies. The first two, push-to-talk address entry for a route-finder, and an open-microphone map-content navigator simulate a UMTS or WLAN scenario. The third demonstrator implements a multi-modal map finder in a live public GPRS network using WAP-Push. Indications of usability are given. The paper argues for the importance of open, standards-based architectures that will spur attractive multi-modal services in the short term, as current economic difficulties in the telecommunications industry put support for long term research into more advanced forms of multi-modality in question.\n",
      "\n",
      "\n",
      "55\n",
      "Flexi-modal and multi-machine user interfaces\n",
      "We describe our system which facilitates collaboration using multiple modalities, including speech, handwriting, gestures, gaze tracking, direct manipulation, large projected touch-sensitive displays, laser pointer tracking, regular monitors with a mouse and keyboard, and wireless networked handhelds. Our system allows multiple, geographically dispersed participants to simultaneously and flexibly mix different modalities using the right interface at the right time on one or more machines. We discuss each of the modalities provided, how they were integrated in the system architecture, and how the user interface enabled one or more people to flexibly use one or more devices.\n",
      "\n",
      "\n",
      "56\n",
      "A real-time framework for natural multimodal interaction with large screen displays\n",
      "This paper presents a framework for designing a natural multimodal human computer interaction (HCI) system. The core of the proposed framework is a principled method for combining information derived from audio and visual cues. To achieve natural interaction, both audio and visual modalities are fused along with feedback through a large screen display. Careful design along with due considerations of possible aspects of a systems interaction cycle and integration has resulted in a successful system. The performance of the proposed framework has been validated through the development of several prototype systems as well as commercial applications for the retail and entertainment industry. To assess the impact of these multimodal systems (MMS), informal studies have been conducted. It was found that the system performed according to its specifications in 95% of the cases and that users showed ad-hoc proficiency, indicating natural acceptance of such systems.\n",
      "\n",
      "\n",
      "57\n",
      "Embarking on multimodal interface design\n",
      "Designers are increasingly faced with the challenge of targeting multimodal applications, those that span heterogeneous devices and use multimodal input, but do not have tools to support them. We studied the early stage work practices of professional multimodal interaction designers. We noted the variety of different artifacts produced, such as design sketches and paper prototypes. Additionally, we observed Wizard of Oz techniques that are sometimes used to simulate an interactive application from these sketches. These studies have led to our development of a technique for interface designers to consider as they embark on creating multimodal applications.\n",
      "\n",
      "\n",
      "58\n",
      "Multi modal user interaction in an automatic pool trainer\n",
      "This paper presents the human-computer interaction in an automatic pool trainer currently being developed at the Center for PersonKommunikation, Aalborg University. The aim of the system is to automate (parts of) the learning process, in this case of the game of pool. The automated pool trainer (APT) utilises multi modal, agent driven user-system communication, to facilitate the user interaction. To allow the user the necessary freedom of movement when addressing the task, system output is presented on a wall-mounted screen and is augmented by a laser drawing lines and points directly on the pool table surface. User interaction is either carried out via a spoken dialogue with an animated interface agent, or by using a touch screen panel. The paper describes the philosophy on which the system is designed, as well as the system architecture and individual modules. The user interaction is described and the paper concludes with a presentation of some test results and a discussion of the suitability of the presented and similar systems.\n",
      "\n",
      "\n",
      "59\n",
      "Multimodal contextual car-driver interface\n",
      "This paper focuses on the design and implementation of a companion contextual car driver interface that proactively assists the driver in managing information and communication. The prototype combines a smart car environment and driver state monitoring, incorporating a wide range of input-output modalities and a display hierarchy. Intelligent agents link information from many contexts, such as location and schedule, and transparently learn from the driver, interacting with the driver only when it is necessary.\n",
      "\n",
      "\n",
      "60\n",
      "Requirements for automatically generating multi-modal interfaces for complex appliances\n",
      "Several industrial and academic research groups are working to simplify the control of appliances and services by creating a truly universal remote control. Unlike the preprogrammed remote controls available today, these new controllers download a specification from the appliance or service and use it to automatically generate a remote control interface. This promises to be a useful approach because the specification can be made detailed enough to generate both speech and graphical interfaces. Unfortunately, generating good user interfaces can be difficult. Based on user studies and prototype implementations, this paper presents a set of requirements that we have found are needed for automatic interface generation systems to create high-quality user interfaces.\n",
      "\n",
      "\n",
      "61\n",
      "Articulated model based people tracking using motion models\n",
      "This paper focuses on acquisition of human motion data such as joint angles and velocity for applications of virtual reality, using both an articulated body model and a motion model in the CONDENSATION framework. Firstly, we learn a motion model represented by Gaussian distributions, and explore motion constraints by considering the dependency of motion parameters and represent them as conditional distributions. Both are integrated into the dynamic model to concentrate factored sampling in the areas of state-space with most posterior information. To measure the observing density with accuracy and robustness, a PEF (pose evaluation function) modeled with a radial term is proposed. We also address the issue of automatic acquisition of initial model posture and recovery from severe failures. A large number of experiments on several persons demonstrate that our approach works well.\n",
      "\n",
      "\n",
      "62\n",
      "Audiovisual arrays for untethered spoken interfaces\n",
      "When faced with a distant speaker at a known location in a noisy environment, a microphone array can provide a significantly improved audio signal for speech recognition. Estimating the location of a speaker in a reverberant environment from audio information alone can be quite difficult, so we use an array of video cameras to aid localization. Stereo processing techniques are used on pairs of cameras, and foreground 3-D points are grouped to estimate the trajectory of people as they move in an environment. These trajectories are used to guide a microphone array beamformer. Initial results using this system for speech recognition demonstrate increased recognition rates compared to non-array processing techniques.\n",
      "\n",
      "\n",
      "63\n",
      "Fingerprint classification by directional fields\n",
      "Fingerprint classification provides an important fingerprint index and can reduce fingerprint matching time in a large database. A good classification algorithm can give an accurate index that is able to search a fingerprint database more effectively. We present a fingerprint classification algorithm that is based on directional fields. We compute directional fields of fingerprint images and detect singular points (cores). Then, we extract features that we define from fingerprint images. We also use k-means classifier and 3-nearest neighbor to classify features and distinguish which fingerprint is Arch, Left Loop, Right Loop, or Whorl. Experimental results show a significant improvement in fingerprint classification performance. Moreover, the time required for the classification algorithm is reduced.\n",
      "\n",
      "\n",
      "64\n",
      "Towards vision-based 3-D people tracking in a smart room\n",
      "This paper presents our work on building a real time distributed system to track 3D locations of people in an indoor environment, such as a smart room, using multiple calibrated cameras. In our system, each camera is connected to a dedicated computer on which foreground regions in the camera image are detected. This is done using an adaptive background model. These detected foreground regions are broadcasted to a tracking agent, which computes believed 3D locations of persons based on the detected image regions. We have implemented both a best-hypothesis heuristic tracking approach as well as a probabilistic multi-hypothesis tracker to find the object tracks from these 3D locations. The two tracking approaches are evaluated on a sequence of two people walking in a conference room recorded with three cameras. The results suggest that the probabilistic tracker shows comparable performance to the heuristic tracker.\n",
      "\n",
      "\n",
      "65\n",
      "Using TouchPad pressure to detect negative affect\n",
      "Humans naturally use behavioral cues in their interactions with other humans. The Media Equation proposes that these same cues are directed towards media, including computers. It is probable that detection of these cues by a computer during run-time could improve usability design and analysis. A preliminary experiment testing one of these cues, Synaptics TouchPad pressure, shows that behavioral cues can be used as a critical incident indicator by detecting negative affect.\n",
      "\n",
      "\n",
      "66\n",
      "Designing transition networks for multimodal VR-interactions using a markup language\n",
      "This article presents one core component for enabling multimodal-speech and gesture-driven interaction in and for virtual environments. A so-called temporal Augmented Transition Network (tATN) is introduced. It allows to integrate and evaluate information from speech, gesture, and a given application context using a combined syntactic/semantic parse approach. This tATN represents the target structure for a multimodal integration markup language (MIML). MIML centers around the specification of multimodal interactions by letting an application designer declare temporal and semantic relations between given input utterance percepts and certain application states in a declarative and portable manner. A subsequent parse pass translates MIML into corresponding tATNs which are directly loaded and executed by a simulation engines scripting facility.\n",
      "\n",
      "\n",
      "67\n",
      "Musically expressive doll in face-to-face communication\n",
      "We propose an application that uses music as a multimodal expression to activate and support communication that runs parallel with traditional conversation. We examine a personified doll-shaped interface designed for musical expression. To direct such gestures toward communication, we have adopted an augmented stuffed toy with tactile interaction as a musically expressive device. We constructed the doll with various sensors for user context recognition. This configuration enables translation of the interaction into melodic statements. We demonstrate the effect of the doll on face-to-face conversation by comparing the experimental results of different input interfaces and output sounds. Consequently, we have found that conversation with the doll was positively affected by the musical output, the doll interface, and their combination.\n",
      "\n",
      "\n",
      "68\n",
      "Towards monitoring human activities using an omnidirectional camera\n",
      "We propose an approach for monitoring human activities in an indoor environment using an omnidirectional camera. Robustly tracking people is prerequisite for modeling and recognizing human activities. An omnidirectional camera mounted on the ceiling is less prone to problems of occlusion. We use the Markov Random Field (MRF) to present both background and foreground, and adapt models effectively against environment changes. We employ a deformable model to adapt the foreground models to optimally match objects in different position within a pattern of view of the omnidirectional camera. In order to monitor human activity, we represent positions of people as spatial points and analyze moving trajectories within a time-spatial window. The method provides an efficient way to monitoring high-level human activities without exploring identities.\n",
      "\n",
      "\n",
      "69\n",
      "Smart Platform - a software infrastructure for Smart Space (SISS)\n",
      "A software infrastructure is fundamental to a Smart Space. Previously proposed software infrastructures for Smart Space (SISS) did not sufficiently address the issue of performance and usability. A new solution, Smart Platform, which is focused on improving these aspects of a SISS, is presented in this paper. To optimize its intermodule communication performance, the stream-oriented communication is distinguished from the message-oriented ones, and a corresponding hybrid communication scheme is proposed. To improve the usability, a featured loose coupling structure, a straightforward Publish-and-Subscribe coordination model as well as a set of user-friendly deployment and development tools are developed. Besides, Smart Platform is intended as an open and generic SISS available for other research groups. To this end, XML-based message syntax and the open wire-protocol based architecture are adopted to make sharing research efforts more easily.\n",
      "\n",
      "\n",
      "70\n",
      "Do multimodal signals need to come from the same place? Crossmodal attentional links between proximal and distal surfaces\n",
      "Previous research has shown that the use of multimodal signals can lead to faster and more accurate responses compared to purely unimodal displays. However, in most cases response facilitation only occurs when the signals are presented in roughly the same spatial location. This would suggest a severe restriction on interface designers: to use multimodal displays effectively all signals must be presented from the same location on the display. We previously reported evidence that the use of haptic cues may provide a solution to this problem as haptic cues presented to a user's back can be used to redirect visual attention to locations on a screen in front of the user (Tan et al., 2001). In the present experiment we used a visual change detection task to investigate whether (i) this type of visual-haptic interaction is robust at low cue validity rates and (ii) similar effects occur for auditory cues. Valid haptic cues resulted in significantly faster change detection times even when they accurately indicated the location of the change on only 20% of the trials. Auditory cues had a much smaller effect on detection times at the high validity rate (80%) than haptic cues and did not significantly improve performance at the 20% validity rate. These results suggest that the use haptic attentional cues may be particularly effective in environments in which information cannot be presented in the same spatial location.\n",
      "\n",
      "\n",
      "71\n",
      "CATCH-2004 multi-modal browser: overview description with usability analysis\n",
      "This paper takes a closer look at the user interface issues in our research multi-modal browser architecture. The browser framework, also briefly introduced in this paper, reuses single-modal browser technologies available for VoiceXML, WML, and HTML browsing. User interface actions on a particular browser are captured, converted to events, and distributed to the other browsers participating (possibly on different hosts) in the multi-modal framework. We have defined a synchronization protocol, which distributes such events with the help of the central component called the Virtual Proxy. The choice of the architecture and the synchronization primitives have profound consequences on handling certain interesting UI use cases. We particularly address those specified by the W3C MultiModal Requirements, which are related to the design of possible strategies of dealing with simultaneous input, solving input inconsistencies, and defining synchronization points. The proposed approaches are illustrated by examples.\n",
      "\n",
      "\n",
      "72\n",
      "Multimodal interaction during multiparty dialogues: initial results\n",
      "Groups of people involved in collaboration on a task often incorporate the objects in their mutual environment into their discussion. With this comes physical reference to these 3-D objects, including: gesture, gaze, haptics, and possibly other modalities, over and above the speech we commonly associate with human-human communication. From a technological perspective, this human style of communication not only poses the challenge for researchers to create multimodal systems capable of integrating input from various modalities, but also to do it well enough that it supports, but does not interfere with the primary goal of the collaborators, which is their own human-human interaction. This paper offers a first step towards building such multimodal systems for supporting face-to-face collaborative work by providing both qualitative and quantitative analyses of multiparty multimodal dialogues in a field setting.\n",
      "\n",
      "\n",
      "73\n",
      "Multi-modal embodied agents scripting\n",
      "Embodied agents present ongoing challenging agenda for research in multi-modal user interfaces and human-computer-interaction. Such agent metaphors will only be widely applicable to online applications when there is a standardised way to map underlying engines with the visual presentation of the agents. This paper delineates the functions and specifications of a mark-up language for scripting the animation of virtual characters. The language is called: Character Mark-up Language (CML) and is an XML-based character attribute definition and animation scripting language designed to aid in the rapid incorporation of lifelike characters/agents into online applications or virtual reality worlds. This multi-modal scripting language is designed to be easily understandable by human animators and easily generated by a software process such as software agents. CML is constructed based jointly on motion and multi-modal capabilities of virtual life-like figures. The paper further illustrates the constructs of the language and describes a real-time execution architecture that demonstrates the use of such a language as a 4G language to easily utilise and integrate MPEG-4 media objects in online interfaces and virtual environments.\n",
      "\n",
      "\n",
      "74\n",
      "A methodology for evaluating multimodality in a home entertainment system\n",
      "Multimodality is likely to play a key role in household technology interfaces of the future offering as it can, enhanced efficiency, improved flexibility and increased user preference. These benefits are unlikely to be realized however unless such interfaces are well designed specifically with regard to modality allocation and configuration. We report on a methodology aimed at evaluating modality usage, which involves a combination of two sets of heuristics, one derived from a description of modality properties, the other concerned with issues of usability. We describe how modality properties can be reformulated into a procedural style checklist and then describe the implementation of this methodology and the issues we were able to highlight in the context of the EMBASSI 'Home' system, a multimodal system which aims to provide a natural and intuitive interface to a potentially open-ended array of appliances within the home.\n",
      "\n",
      "\n",
      "75\n",
      "Body-based interfaces\n",
      "This research explores different ways to use features of one's own body for interacting with computers. In the future, such \"body-based\" interfaces may be put into good use for wearable computing or virtual reality systems as part of a 3D multi-modal interface, freeing the user from holding interaction devices. We have identified four types of body-based interfaces: the Body-inspired-metaphor uses various parts of the body metaphorically for interaction; the Body-as-interaction-surface simply uses parts of the body as points of interaction; Mixed-mode mixes the former two; Object-mapping spatially maps the interaction object to the human body. These four body-based interfaces were applied to three different applications (and associated tasks) and were tested for their performance and utility. It was generally found that, while the body-inspired-metaphor produced the lowest error rate, it required a longer task completion time and caused more fatigue due to the longer hand moving distance. On the other hand, the body-as-interaction-surface was the fastest, but produced many more errors.\n",
      "\n",
      "\n",
      "76\n",
      "Evaluation of the Command and Control Cube\n",
      "Application control in virtual environments (VE) is still an open field of research. The Command and Control Cube (C/sup 3/) developed by Grosjean et al. (2001) is a quick access menu for the VE configuration called workbench (a large screen displaying stereoscopic images). The C/sup 3/ presents two modes, one with the graphical display of the cubic structure associated to the C/sup 3/ and a blind mode for expert users, with no feedback. We conduct formal tests of the C/sup 3/ under four different conditions: the visual mode with the graphical display, the blind mode with no feedback and two additional conditions enhancing the expert blind mode: a tactile mode with the tactile feedback, of a Cyberglove/spl trade/ and a sound mode with a standard audio device. Results show that the addition of sound and tactile feedback is more disturbing to the users than the blind mode. The visual mode performs the best although the blind mode achieves some promising results.\n",
      "\n",
      "\n",
      "77\n",
      "Interruptions as multimodal outputs: which are the less disruptive?\n",
      "This paper describes exploratory studies of interruption modalities and disruptiveness. Five interruption modalities were compared: heat, smell, sound, vibration, and light. Much more notable than the differences between modalities was the differences between people. We found that subjects' sensitiveness depended on their previous life exposure to the modalities. Individual differences greatly control the effect of interrupting stimuli. We show that is possible to build a multimodal adaptive interruption interface, such interfaces would dynamically select the output interruption modality to use based on its effectiveness on a particular user.\n",
      "\n",
      "\n",
      "78\n",
      "Experimentally augmenting an intelligent tutoring system with human-supplied capabilities: adding human-provided emotional scaffolding to an automated reading tutor that listens\n",
      "We present the first statistically reliable empirical evidence from a controlled study for the effect of human-provided emotional scaffolding on student persistence in an intelligent tutoring system. We describe an experiment that added human-provided emotional scaffolding to an automated Reading Tutor that listens, and discuss the methodology we developed to conduct this experiment. Each student participated in one (experimental) session with emotional scaffolding, and in one (control) session without emotional scaffolding, counterbalanced by order of session. Each session was divided into several portions. After each portion of the session was completed, the Reading Tutor gave the student a choice: continue, or quit. We measured persistence as the number of portions the student completed. Human-provided emotional scaffolding added to the automated Reading Tutor resulted in increased student persistence, compared to the Reading Tutor alone. Increased persistence means increased time on task, which ought lead to improved learning. If these results for reading turn out to hold for other domains too, the implication for intelligent tutoring systems is that they should respond with not just cognitive support-but emotional scaffolding as well. Furthermore, the general technique of adding human-supplied capabilities to an existing intelligent tutoring system should prove useful for studying other ITSs too.\n",
      "\n",
      "\n",
      "79\n",
      "Individual differences in facial expression: stability over time, relation to self-reported emotion, and ability to inform person identification\n",
      "The face can communicate varied personal information including subjective emotion, communicative intent, and cognitive appraisal. Accurate interpretation by observer or computer interface depends on attention to dynamic properties of the expression, context, and knowledge of what is normative for a given individual. In two separate studies, we investigated individual differences in the base rate of positive facial expression and in specific facial action units over intervals from 4 to 12 months. Facial expression was measured using convergent measures, including facial EMG, automatic feature-point tracking, and manual FACS coding. Individual differences in facial expression were stable over time, comparable in magnitude to stability of self-reported emotion, and sufficiently strong that individuals were recognized on the basis of their facial behavior alone at rates comparable to that for a commercial face recognition system (Facelt from Identix). Facial action units convey unique information about person identity that can inform interpretation of psychological states, person recognition, and design of individuated avatars.\n",
      "\n",
      "\n",
      "80\n",
      "Training a talking head\n",
      "A Cyberware laser scan of DWM was made, Baldi's generic morphology was mapped into the form of DWM, this head was trained on real data recorded with Optotrak LED markers, and the quality of its speech was evaluated. Participants were asked to recognize auditory sentences presented alone in noise, aligned with the newly trained synthetic textured mapped target face, or the original natural face. There was a significant advantage when the noisy auditory sentence was paired with either head, with the synthetic textured mapped target face giving as much of an improvement as the original recordings of the natural face.\n",
      "\n",
      "\n",
      "81\n",
      "Labial coarticulation modeling for realistic facial animation\n",
      "A modified version of the coarticulation model proposed by Cohen and Massaro (1993) is described. A semi-automatic minimization technique, working on real cinematic data, acquired by the ELITE opto-electronic system, was used to train the dynamic characteristics of the model. Finally, the model was applied with success to GRETA, an Italian talking head, and examples are illustrated to show the naturalness of the resulting animation technique.\n",
      "\n",
      "\n",
      "82\n",
      "Improved information maximization based face and facial feature detection from real-time video and application in a multi-modal person identification system\n",
      "In this paper an improved face detection method based on our previous information-based maximum discrimination approach is presented that maximizes the discrimination between face and non-face examples in a training set without using color or motion information. A short review of our previous method is given together with a description of a recent improvement of its detection speed. A person identification system has been developed that performs multi-modal person identification in real-time video based on this newly improved face detection method together with speaker identification.\n",
      "\n",
      "\n",
      "83\n",
      "Animating arbitrary topology 3D facial model using the MPEG-4 FaceDefTables\n",
      "In this paper we put forward a method to animate an arbitrary topology facial model (ATFM) based on the MPEG-4 standard. This paper deals mainly with the problem of building the FaceDefTables, which play a very important role in the MPEG-4 based facial animation system. The FaceDefTables for our predefined standard facial model (SFM) are built using the interpolation method. Since the FaceDefTables depend on facial models, the FaceDefTables for the SFM can be applied only to those facial models having the same topology as the SFM. For those facial models that have different topology, we have to build the FaceDefTables accordingly. To acquire the FaceDefTables for ATFM, we first select feature points on ATFM, then transform the SFM according to those feature points. Finally, we project each vertex on the ATFM to the transformed SFM and build the FaceDefTables for the ATFM according to the projection position. With the FaceDefTables we built, realistic animation results have been acquired.\n",
      "\n",
      "\n",
      "84\n",
      "An improved active shape model for face alignment\n",
      "In this paper, we present several improvements on conventional active shape models (ASM) for face alignment. Despite the accuracy and robustness of ASMs in image alignment, its performance depends heavily on the initial parameters of the shape model, as well as the local texture model for each landmark and the corresponding local matching strategy. In this work, to improve ASMs for face alignment, several measures are taken. First, salient facial features, such as the eyes and the mouth, are localized based on a face detector. These salient features are then utilized to initialize the shape model and provide region constraints on the subsequent iterative shape searching. Secondly, we exploit edge information to construct better local texture models for landmarks on the face contour. The edge intensity at the contour landmark is used as a self-adaptive weight when calculating the Mahalanobis distance between the candidate and reference profile. Thirdly, to avoid unreasonable shift from pre-localized salient features, landmarks around the salient features are adjusted before applying global subspace constraints. Experiments on a database containing 300 labeled face images show that the proposed method performs significantly better than traditional ASMs.\n",
      "\n",
      "\n",
      "85\n",
      "Head-pose invariant facial expression recognition using convolutional neural networks\n",
      "Automatic face analysis has to cope with pose and lighting variations. Pose variations are particularly difficult to tackle and many face analysis methods require the use of sophisticated normalization and initialization procedures. We propose a data-driven face analysis approach that is not only capable of extracting features relevant to a given face analysis task, but is also more robust with regard to face location changes and scale variations when compared to classical methods such as MLPs. Our approach is based on convolutional neural networks that use multi-scale feature extractors, which allow for improved facial expression recognition results with faces subject to in-plane pose variations.\n",
      "\n",
      "\n",
      "86\n",
      "An improved algorithm for hairstyle dynamics\n",
      "This paper introduces an efficient and flexible hair modeling method to develop intricate hairstyle dynamics. A prominent contribution of the present work is that it proposes an evaluation approach for the spring coefficient, i.e., spring coefficient can be obtained through a combination of the large deflection deformation model and spring hinge model. This is based on the fact that there is a directly proportional relationship between the spring coefficient and stiffness coefficient, a variable determined by hair shape. What is more, the damping coefficient is no longer regarded as a constant, but a function of hair density, and this treatment has turned out to be successful in solving the problem of hair-hair collision. As a result, a dynamic model, which fits a great variety of hairstyles, is proposed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#审查missing的文章\n",
    "for s in missing:\n",
    "    print (s)\n",
    "    for i in missing[s]:\n",
    "        #print (i)\n",
    "        title = total_article[s]['title'][i]\n",
    "        abstract = total_article[s]['abstract'][i]\n",
    "        \n",
    "        print (i)\n",
    "        print (title)\n",
    "        print (abstract)\n",
    "        print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:31:19.957371Z",
     "start_time": "2019-11-20T06:31:19.248851Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "12\n",
      "A Self-reliance Smoothness of the Vision-Based Recognition of Hand Gestures\n",
      "The hand gestures are a natural and intuitive mode for human-computer interaction. The vision-based recognition of hand gestures is a necessary method for future human-computer interaction. On the other hand, the edge detection in the course of the hand recognition is also a key technique. In this paper based on the classical self-reliance smoothness operator, we propose a new method of midpoint threshold (the averaged grads method). According to this method, the optimal threshold and edge image of hand gestures can be got by using the first or each information of grads of reference image.\n",
      "40\n",
      "Multimodal Speaker Detection Using Input/Output Dynamic Bayesian Networks\n",
      "Inferring users’ actions and intentions forms an integral part of design and development of any human-computer interface. The presence of noisy and at times ambiguous sensory data makes this problem challenging. We formulate a framework for temporal fusion of multiple sensors using input-output dynamic Bayesian networks (IODBNs).We find that contextual information about the state of the computer interface, used as an input to the DBN, and sensor distributions learned from data are crucial for good detection performance. Nevertheless, classical DBN learning methods can cause such models to fail when the data exhibits complex behavior. To further improve the detection rate we formulate an \n",
      "84\n",
      "A Pragmatic Semantic Reliable Multicast Architecture for Distance Learning\n",
      "Although IP multicast has been rapidly evolving in the last few years, the current Internet is not fully multicast-enabled because of the lack of robust inter-domain routing and controlling protocols. In this paper, we present an alternative architecture for data distribution on Internet called PSRM that realizes semantic reliable, loose synchronized, multicast data delivery. PSRM is not based on global IP multicast, instead it uses a hybrid way to combine unicast delivery with multicast delivery. In PSRM, IP multicast is used only in local area, or multicast domain, to enhance the performance, and these multicast domains are organized into a spanning tree by TCP connections. As PSRM is based upon ALF protocol architecture, we use application-defined semantics to adapt content in a heterogeneous environment. PSRM have been implemented and demonstrated by a prototype distance learning application.\n",
      "2002\n",
      "2\n",
      "Techniques for interactive audience participation\n",
      "At SIGGRAPH in 1991, Loren and Rachel Carpenter unveiled an interactive entertainment system that allowed members of a large audience to control an onscreen game using red and green reflective paddles. In the spirit of this approach, we present a new set of techniques that enable members of an audience to participate, either cooperatively or competitively, in shared entertainment experiences. Our techniques allow audiences with hundreds of people to control onscreen activity by (1) leaning left and right in their seats, (2) batting a beach ball while its shadow is used as a pointing device, and (3) pointing laser pointers at the screen. All of these techniques can be implemented with inexpensive, off the shelf hardware. Me have tested these techniques with a variety of audiences; in this paper we describe both the computer vision based implementation and the lessons we learned about designing effective content for interactive audience participation.\n",
      "17\n",
      "Towards visually-grounded spoken language acquisition\n",
      "A characteristic shared by most approaches to natural language understanding and generation is the use of symbolic representations of word and sentence meanings. Frames and semantic nets are examples of symbolic representations. Symbolic methods are inappropriate for applications which require natural language semantics to be linked to perception, as is the case in tasks such as scene description or human-robot interaction. This paper presents two implemented systems, one that learns to generate, and one that learns to understand visually-grounded spoken language. These implementations are part of our on-going effort to develop a comprehensive model of perceptually-grounded semantics.\n",
      "21\n",
      "Viewing and analyzing multimodal human-computer tutorial dialogue: a database approach\n",
      "It is easier to record logs of multimodal human-computer tutorial dialogue than to make sense of them. In the 2000-2001 school year, we logged the interactions of approximately 400 students who used Project LISTEN's Reading Tutor and who read aloud over 2.4 million words. We discuss some difficulties we encountered converting the logs into a more easily understandable database. It is faster to write SQL queries to answer research questions than to analyze complex log files each time. The database also permits us to construct a viewer to examine individual Reading Tutor-student interactions. This combination of queries and viewable data has turned out to be very powerful, and we discuss how we have combined them to answer research questions.\n",
      "22\n",
      "Adaptive dialog based upon multimodal language acquisition\n",
      "Communicating by voice with speech-enabled computer applications based on preprogrammed rule grammars suffers from constrained vocabulary and sentence structures. Deviations from the allowed language result in an unrecognized utterance that will not be understood and processed by the system. One way to alleviate this restriction consists in allowing the user to expand the computer's recognized and understood language by teaching the computer system new language knowledge. We present an adaptive dialog system capable of learning from users new words, phrases and sentences, and their corresponding meanings. User input incorporates multiple modalities, including speaking, typing, pointing, drawing and image capturing. The allowed language can thus be expanded in real time by users according to their preferences. By acquiring new language knowledge the system becomes more capable in specific tasks, although its language is still constrained.\n",
      "26\n",
      "Prosody based co-analysis for continuous recognition of coverbal gestures\n",
      "Although recognition of natural speech and gestures have been studied extensively, previous attempts at combining them in a unified framework to boost classification were mostly semantically motivated, e.g., keyword-gesture co-occurrence. Such formulations inherit the complexity of natural language processing. This paper presents a Bayesian formulation that uses a phenomenon of gesture and speech articulation for improving accuracy of automatic recognition of continuous coverbal gestures. The prosodic features from the speech signal were co-analyzed with the visual signal to learn the prior probability of co-occurrence of the prominent spoken segments with the particular kinematical phases of gestures. It was found that the above co-analysis helps in detecting and disambiguating small hand movements, which subsequently improves the rate of continuous gesture recognition. The efficacy of the proposed approach was demonstrated on a large database collected front the weather channel broadcast. This formulation opens new avenues for bottom-up frameworks of multimodal integration.\n",
      "36\n",
      "The NESPOLE! multimodal interface for cross-lingual communication $experience and lessons learned\n",
      "We describe the design, evolution, and development of the user interface components of the NESPOLE! speech-to-speech translation system. The NESPOLE! system was designed for users with medium-to-low levels of computer literacy and Web expertise. The user interface was designed to effectively combine Web browsing, real-time sharing of graphical information and multi-modal annotations using a shared whiteboard, and real-time multilingual speech communication, all within an e-commerce scenario. Data collected in sessions with naive users in several stages in the process of system development formed the basis for improving the effectiveness and usability of the system. We describe this development process, the resulting interface components and the lessons learned.\n",
      "37\n",
      "Research of machine learning method for specific information recognition on the Internet\n",
      "With the available resources on the Internet becoming plentiful, a large amount of harmful information is permeating in and has been seriously affecting people's normal work and living. Therefore, harmful data streams must be recognized and filtered out effectively. After analyzing some harmful contents in Internet information streams, we present a new method, which recognizes specific information by machine learning (ML). We extracted key information from a number of corpuses through the ML method to obtain the part of speech (POS) transfer-form for key information by learning from corpuses, which is based on the same pronunciation matching of key information. Furthermore, the testing value of key information will be obtained in a real corpus to examine the likelihood between matching rules from information streams and those learnt from corpuses through the average value of POS transfer probability of key information. Therefore, the testing value for the whole real data stream will be obtained The experiment proved that the method was efficient for recognizing certain Internet harmful information.\n",
      "45\n",
      "A probabilistic dynamic contour model for accurate and robust lip tracking\n",
      "In this paper a new condensation style contour tracking method called probabilistic dynamic contour (PDC) is proposed for lip tracking: a novel mixture dynamic model is designed to represent shape more compactly and to tolerate larger motions between frames, a measurement model is designed to include multiple visual cues. The proposed PDC tracker has the advantage that it is conceptually general but effectively suitable for lip tracking with the designed dynamic and measurement model. The new tracker improves the traditional condensation style tracker in three aspects: Firstly, the dynamic model is partially derived from the image sequence, so the tracker does not need to learn the dynamics in advance. Secondly, the measurement model is easy to be updated during tracking, which avoids modeling the foreground object in prior. Thirdly, to improve the tracker's speed, a compact representation of shape and a noise model are proposed to reduce the samples required to represent the posterior distribution. An experiment on lip contour tracking shows that the proposed method tracks contours robustly as well as accurately compared to the existing tracking method.\n",
      "46\n",
      "Attentional object spotting by integrating multimodal input\n",
      "An intelligent human-computer interface is expected to allow computers to work with users in a cooperative manner. To achieve this goal, computers need to be aware of user attention and provide assistance without explicit user requests. Cognitive studies of eye movements suggest that in accomplishing well-learned tasks, the performer's focus of attention is locked onto ongoing work and more than 90% of eye movements are closely related to the objects being manipulated in the tasks. In light of this, we have developed an attentional object spotting system that integrates multimodal data consisting of eye position, head position and video from the \"first-person\" perspective. To detect the user's focus of attention, we modeled eye gaze and head movements using a hidden Markov model (HMM) representation. For each attentional point in time, the object of user interest is automatically extracted and recognized. We report the results of experiments on finding attentional objects in the natural task of \"making a peanut-butter sandwich\".\n",
      "50\n",
      "A multi-modal interface for an interactive simulated vascular reconstruction system\n",
      "This paper is devoted to multi-modal interface design and implementation of a simulated vascular reconstruction system. It provides multi-modal interaction methods such as speech recognition, hand gestures, direct manipulation of virtual 3D objects and measurement tools. The main challenge is that no general interface scenario in existence today can satisfy all the users of the system (radiologists, vascular surgeons, medical students, etc.). The potential users of the system can vary by their skills, expertise level, habits and psycho-motional characteristics. To make a multimodal interface user-friendly is a crucial issue. In this paper we introduce an approach to develop such an efficient, user-friendly multi-modal interaction system. We focus on adaptive interaction as a possible solution to address the variety of end-users. Based on a user model, the adaptive user interface identifies each individual by means of a set of criteria and generates a customized exploration environment.\n",
      "59\n",
      "Multimodal contextual car-driver interface\n",
      "This paper focuses on the design and implementation of a companion contextual car driver interface that proactively assists the driver in managing information and communication. The prototype combines a smart car environment and driver state monitoring, incorporating a wide range of input-output modalities and a display hierarchy. Intelligent agents link information from many contexts, such as location and schedule, and transparently learn from the driver, interacting with the driver only when it is necessary.\n",
      "61\n",
      "Articulated model based people tracking using motion models\n",
      "This paper focuses on acquisition of human motion data such as joint angles and velocity for applications of virtual reality, using both an articulated body model and a motion model in the CONDENSATION framework. Firstly, we learn a motion model represented by Gaussian distributions, and explore motion constraints by considering the dependency of motion parameters and represent them as conditional distributions. Both are integrated into the dynamic model to concentrate factored sampling in the areas of state-space with most posterior information. To measure the observing density with accuracy and robustness, a PEF (pose evaluation function) modeled with a radial term is proposed. We also address the issue of automatic acquisition of initial model posture and recovery from severe failures. A large number of experiments on several persons demonstrate that our approach works well.\n",
      "78\n",
      "Experimentally augmenting an intelligent tutoring system with human-supplied capabilities: adding human-provided emotional scaffolding to an automated reading tutor that listens\n",
      "We present the first statistically reliable empirical evidence from a controlled study for the effect of human-provided emotional scaffolding on student persistence in an intelligent tutoring system. We describe an experiment that added human-provided emotional scaffolding to an automated Reading Tutor that listens, and discuss the methodology we developed to conduct this experiment. Each student participated in one (experimental) session with emotional scaffolding, and in one (control) session without emotional scaffolding, counterbalanced by order of session. Each session was divided into several portions. After each portion of the session was completed, the Reading Tutor gave the student a choice: continue, or quit. We measured persistence as the number of portions the student completed. Human-provided emotional scaffolding added to the automated Reading Tutor resulted in increased student persistence, compared to the Reading Tutor alone. Increased persistence means increased time on task, which ought lead to improved learning. If these results for reading turn out to hold for other domains too, the implication for intelligent tutoring systems is that they should respond with not just cognitive support-but emotional scaffolding as well. Furthermore, the general technique of adding human-supplied capabilities to an existing intelligent tutoring system should prove useful for studying other ITSs too.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "education_keywords = ['education','learn','teach','educate','e-learning','exam','student','curriculum','course','mooc']\n",
    "for s in missing:\n",
    "    print (s)\n",
    "    for i in missing[s]:\n",
    "        #print (i)\n",
    "        title = total_article[s]['title'][i]\n",
    "        abstract = total_article[s]['abstract'][i]\n",
    "        \n",
    "        if abstract == 'null' or abstract == 'An abstract is not available.' or type(abstract) == list:\n",
    "            print (title)\n",
    "            print (abstract)\n",
    "        else:\n",
    "            text = title + \" \" + abstract\n",
    "            sent = splitSentence(text) \n",
    "            word_list = []\n",
    "            for m in sent:\n",
    "                word = wordtokenizer(m)                  \n",
    "                word_list = word_list + word\n",
    "            word_standard = standardization(word_list)\n",
    "            word_ori = lemmatizer(word_standard)\n",
    "            for j in word_ori:\n",
    "                if j in education_keywords:\n",
    "                    print (i)\n",
    "                    print (title)\n",
    "                    print (abstract)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T01:53:14.210604Z",
     "start_time": "2019-11-26T01:53:14.206495Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_core = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T02:27:02.624614Z",
     "start_time": "2019-11-25T02:26:49.810593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2\n",
      "Quantifying the invisible audience in social networks\n",
      "When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals --- friend count, likes, and comments --- vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.\n",
      "10\n",
      "Optimizing challenge in an educational game using large-scale design experiments\n",
      "Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the \\'1cInverted-U Hypothesis\\'1d, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge.\n",
      "25\n",
      "A pilot study of using crowds in the classroom\n",
      "Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.\n",
      "78\n",
      "Control your game-self: effects of controller type on enjoyment, motivation, and personality in game\n",
      "Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.\n",
      "87\n",
      "The effect of virtual achievements on student engagement\n",
      "Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts. Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains. With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation. In this paper, we report on a large-scale (n > 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool. We discover a highly significant positive effect on the quantity of students' contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.\n",
      "88\n",
      "A trace-based framework for analyzing and synthesizing educational progressions\n",
      "A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.\n",
      "104\n",
      "From codes to patterns: designing interactive decoration for tableware\n",
      "We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.\n",
      "122\n",
      "Memorability of pre-designed and user-defined gesture sets\n",
      "We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.\n",
      "123\n",
      "Learning and performance with gesture guides\n",
      "Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial learning of gesture sets. Many methods for learning gestures have been proposed, but they are often evaluated with short-term recall tests that measure user performance, rather than learning. We evaluated four types of gesture guides using a retention and transfer paradigm common in motor learning experiments and found results different from those typically reported with recall tests. The results indicate that many guide systems with higher levels of guidance exhibit high performance benefits while the guide is being used, but are ultimately detrimental to user learning. We propose an adaptive guide that does not suffer from these drawbacks, and that enables a smooth transition from novice to expert. The results contrasting learning and performance can be explained by the guidance hypothesis. They have important implications for the design and evaluation of future gesture learning systems.\n",
      "126\n",
      "NoteVideo: facilitating navigation of blackboard-style lecture videos\n",
      "Khan Academy's pre-recorded blackboard-style lecture videos attract millions of online users every month. However, current video navigation tools do not adequately support the kinds of goals that students typically have, like quickly finding a particular concept in a blackboard-style lecture video. This paper reports on the development and evaluation of the new NoteVideo and its improved version, NoteVideo+, systems for identifying the conceptual 'objects' of a blackboard-based video - and then creating a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame where that object first appeared instead of navigating it linearly through time. The research consisted of iteratively implementing the system and then having users perform four different navigation tasks using three different interfaces: Scrubbing, Transcript, and NoteVideo. Results of the study show that participants perform significantly better on all four tasks while using the NoteVideo and its improved version - NoteVideo+ - as compared to others.\n",
      "163\n",
      "NailDisplay: bringing an always available visual display to fingertips\n",
      "This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger by allowing for always-available visual feedback owing to its fast accessibility and binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface, helping users to learn an imaginary interface (e.g., on the users' arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users' feedbacks gathered from an explorative user study.\n",
      "172\n",
      "Designing for the living room: long-term user involvement in a living lab\n",
      "Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants' motivation, establishment of a trust relationship, and the coordination of collaboration.\n",
      "183\n",
      "Designing with traces\n",
      "This paper draws on new materialist perspectives to introduce the analytic category of \"material traces\" to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "Community enhanced tutorials: improving tutorials with multiple demonstrations\n",
      "Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.\n",
      "198\n",
      "Graduate student use of a multi-slate reading system\n",
      "In laboratory studies, multi-surface slate-based reading systems have shown great promise as platforms for active reading. However, the true utility of such a system can only be ascertained through the rigors of real world use. We conducted month-long deployments of a multi-slate reading system to support the active reading activities of graduate students in the humanities. During these deployments we documented how the added display area and increased micro-mobility of multiple devices enhanced navigation and reading comfort. We also noted the essential role of writing and annotation. Finally, we observed how electronic affordances like synchronization across devices helped provide functionality that would not have been possible with paper documents. This paper contributes new information about how electronic reading solutions fit into real world reading workflows.\n",
      "214\n",
      "Design research at CHI and its applicability to design practice\n",
      "This note describes our analysis of 35 papers from CHI 2011 that aim to improve or support interaction design practice. In our analysis, we characterize how these CHI authors conceptualize design practice and the types of contributions they propose. This work is motivated by the recognition that design methods proposed by HCI researchers often do not fit the needs and constraints of professional design practice. As a complement to the analysis of the CHI papers we also interviewed 13 practitioners about their attitudes towards learning new methods and approaches. We conclude the note by offering some critical reflections about how HCI research can better support actual design practice.\n",
      "225\n",
      "Predicting users' first impressions of website aesthetics with a quantification of perceived visual complexity and colorfulness\n",
      "Users make lasting judgments about a website's appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site's usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website's colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user's education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.\n",
      "265\n",
      "Back-of-device authentication on smartphones\n",
      "This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.\n",
      "282\n",
      "Gesture output: eyes-free output using a force feedback touch surface\n",
      "We propose using spatial gestures not only for input but also for output. Analogous to gesture input, the proposed gesture output moves the user's finger in a gesture, which the user then recognizes. We use our concept in a mobile scenario where a motion path forming a \"5\" informs users about new emails, or a heart-shaped path serves as a mes- sage from a friend. We built two prototypes: (1) The long- RangeOuija is a stationary prototype that offers a motion range of up to 4cm; (2) The pocketOuija is self-contained mobile device based on an iPhone with up to 1cm motion range. Both devices actuate the user's fingers by means of an actuated transparent foil overlaid onto a touchscreen. We conducted three studies with the longRangeOuija in which participants recognized 2cm marks with 97% accu- racy, Graffiti digits with 98.8%, pairs of Graffiti digits with 90.5%, and Graffiti letters with 93.4%. Participants previ- ously unfamiliar with Graffiti identified 96.2% of digits and 76.4% of letters, suggesting that properly designed gesture output is guessable. After the experiment, the same participants were able to enter 100% of Graffiti digits by heart and 92.2% of letters. This suggests that participants learned gesture input as a side effect of using gesture output on our prototypes.\n",
      "295\n",
      "Why do people seek anonymity on the internet?: informing policy and design\n",
      "In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees' past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.\n",
      "303\n",
      "Beyond being green: simple living families and ICT\n",
      "Motivated by a need in sustainable HCI for studies of everyday practices, and a belief that a holistic view on sustainability is crucial to deeper understanding of how to design ICT to support sustainability, we here present a qualitative study of 11 simple living families in the US. Simple living refers to a lifestyle which is voluntarily simple out of concern for both the environment and quality of life. Our goal was to learn about a holistic view on sustainability and the role of ICT in helping and hindering families to live simply. The study contributes new insights about how holistic sustainability could be a valuable lens for HCI, revealing that sustainability is important to a wider range of areas in HCI than previously discussed. We conclude with implications for HCI for how to support sustainable practices beyond being \"about\" being green.\n",
      "312\n",
      "Job opportunities through entertainment: virally spread speech-based services for low-literate users\n",
      "We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users' activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.\n",
      "315\n",
      "VideoKheti: making video content accessible to low-literate and novice users\n",
      "Designing ICT systems for rural users in the developing world is difficult for a variety of reasons ranging from problems with infrastructure to wide differences in user contexts and capabilities. Developing regions may include huge variability in spoken languages, and users are often low- or non-literate, with very little experience interacting with digital technologies. Researchers have explored the use of text-free graphical interfaces as well as speech-based applications to overcome some of the issues related to language and literacy. While there are benefits and drawbacks to each of these approaches, they can be complementary when used together. In this work, we present VideoKheti, a mobile system using speech, graphics, and touch interaction for low-literate farmers in rural India. VideoKheti helps farmers to find and watch agricultural extension videos in their own language and dialect. In this paper, we detail the design and development of VideoKheti and report on a field study with 20 farmers in rural India who were asked to find videos based on a scenario. The results show that farmers could use VideoKheti, but their success still greatly depended on their education level. While participants were enthusiastic about using the system, the multimodal interface did not overcome many obstacles for low-literate users.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "64\n",
      "Mobile phones and paper documents: evaluating a new approach for capturing microfinance data in rural India\n",
      "CAM is a user interface toolkit that allows a camera-equipped mobile phone to interact with paper documents. It is designed to automate inefficient, paper-intensive information processes in the developing world. In this paper we present a usability evaluation of an application built using CAM for collecting data from microfinance groups in rural India. This application serves an important and immediate need in the microfinance industry. Our quantitative results show that the user interface is efficient, accurate and can quickly be learned by rural users. The results were competitive with an equivalent PC-based UI. Qualitatively, the interface was found easy to use by almost all users. This shows that, with a properly designed user interface, mobile phones can be a preferred platform for many rural computing applications. Voice feedback and numeric data entry were particularly well-received by users. We are conducting a pilot of this application with 400 microfinance groups in India.\n",
      "87\n",
      "Tabletop sharing of digital photographs for the elderly\n",
      "We have recently begun to see hardware support for the tabletop user interface, offering a number of new ways for humans to interact with computers. Tabletops offer great potential for face-to-face social interaction; advances in touch technology and computer graphics provide natural ways to directly manipulate virtual objects, which we can display on the tabletop surface. Such an interface has the potential to benefit a wide range of the population and it is important that we design for usability and learnability with diverse groups of people.This paper describes the design of SharePic -- a multiuser, multi-touch, gestural, collaborative digital photograph sharing application for a tabletop -- and our evaluation with both young adult and elderly user groups. We describe the guidelines we have developed for the design of tabletop interfaces for a range of adult users, including elders, and the user interface we have built based on them. Novel aspects of the interface include a design strongly influenced by the metaphor of physical photographs placed on the table with interaction techniques designed to be easy to learn and easy to remember. In our evaluation, we gave users the final task of creating a digital postcard from a collage of photographs and performed a realistic think-aloud with pairs of novice participants learning together, from a tutorial script.\n",
      "104\n",
      "Investigating health management practices of individuals with diabetes\n",
      "Chronic diseases, endemic in the rapidly aging population, are stretching the capacity of healthcare resources. Increasingly, individuals need to adopt proactive health attitudes and contribute to the management of their own health. We investigate existing diabetes self-management practices and ways in which reflection on prior actions impacts future lifestyle choices. The findings suggest that individuals generate and evaluate hypotheses regarding health implications of their actions. Thus, health-monitoring applications can assist individuals in making educated choices by facilitating discovery of correlations between their past actions and health states. Deployment of an early prototype of a health-monitoring application demonstrated the need for careful presentation techniques to promote more robust understanding and to avoid reinforcement of biases.\n",
      "2000\n",
      "16\n",
      ": designing a new class of computational toys\n",
      "We introduce an educational toy, called curlybot, as the basis for a new class of toys aimed at children in their early stages of development — ages four and up. curlybot is an autonomous two-wheeled vehicle with embedded electronics that can record how it has been moved on any flat surface and then play back that motion accurately and repeatedly. Children can use curlybot to develop intuitions for advanced mathematical and computational concepts, like differential geometry, through play away from a traditional computer.In our preliminary studies, we found that children learn to use curlybot quickly. They readily establish an affective and body syntonic connection with curlybot, because of its ability to remember all of the intricacies of their original gesture; every pause, acceleration, and even the shaking in their hand is recorded. Programming by example in this context makes the educational ideas implicit in the design of curlybot accessible to young children.\n",
      "30\n",
      "Tradeoffs in displaying peripheral information\n",
      "Peripheral information is information that is not central to a person's current task, but provides the person the opportunity to learn more, to do a better job, or to keep track of less important tasks. Though peripheral information displays are ubiquitous, they have been rarely studied. For computer users, a common peripheral display is a scrolling text display that provides announcements, sports scores, stock prices, or other news. In this paper, we investigate how to design peripheral displays so that they provide the most information while having the least impact on the user's performance on the main task. We report a series of experiments on scrolling displays aimed at examining tradeoffs between distraction of scrolling motion and memorability of information displayed. Overall, we found that continuously scrolling displays are more distracting than displays that start and stop, but information in both is remembered equally well. These results are summarized in a set of design recommendations.\n",
      "42\n",
      "A toolkit for strategic usability: results from workshops, panels, and surveys\n",
      "This paper describes the organizational approaches and usability methodologies considered by HCI professionals to increase the strategic impact of usability research within companies. We collected the data from 134 HCI professionals at three conferences: CHI 98, CHI 99, and the Usability Professionals' Association 1999 conference. The results are the first steps towards a toolkit for the usability community that can help HCI practitioners learn from the experiences of others in similar situations.\n",
      "45\n",
      "Visual similarity of pen gestures\n",
      "Pen-based user interfaces are becoming ever more popular. Gestures (i.e., marks made with a pen to invoke a command) are a valuable aspect of pen-based UIs, but they also have drawbacks. The challenge in designing good gestures is to make them easy for people to learn and remember. With the goal of better gesture design, we performed a pair of experiments to determine why users find gestures similar. From these experiments, we have derived a computational model for predicting perceived gesture similarity that correlates 0.56 with observation. We will incorporate the results of these experiments into a gesture design tool, which will aid the pen-based UI designer in creating gesture sets that are easier to learn and more memorable.\n",
      "61\n",
      "Alice: lessons learned from building a 3D system for novices\n",
      "We present lessons learned from developing Alice, a 3D graphics programming environment designed for undergraduates with no 3D graphics or programming experience. Alice is a Windows 95/NT tool for describing the time-based and interactive behavior of 3D objects, not a CAD tool for creating object geometry. Our observations and conclusions come from formal and informal observations of hundreds of users. Primary results include the use of LOGO-style egocentric coordinate systems, the use of arbitrary objects as lightweight coordinate systems, the launching of implicit threads of execution, extensive function overloading for a small set of commands, the careful choice of command names, and the ubiquitous use of animation and undo.\n",
      "1993\n",
      "Touch-typing with a stylus\n",
      "An abstract is not available.\n",
      "16\n",
      "1990\n",
      "35\n",
      "Testing a walkthrough methodology for theory-based design of walk-up-and-use interfaces\n",
      "The value of theoretical analyses in user interface design has been hotly debated. All sides agree that it is difficult to apply current theoretical models within the constraints of real-world development projects. We attack this problem in the context of bringing the theoretical ideas within a model of exploratory learning [19] to bear on the evaluation of alternative interfaces for walk-up-and-use systems. We derived a “cognitive walkthrough” procedure for systematically evaluating features of an interface in the context of the theory. Four people independently applied this procedure to four alternative interfaces for which we have empirical usability data. Consideration of the walkthrough sheds light on the consistency with which such a procedure can be applied as well as the accuracy of the results.\n",
      "2016\n",
      "4\n",
      "IJQwerty: What Difference Does One Key Change Make? Gesture Typing Keyboard Optimization Bounded by One Key Position Change from Qwerty\n",
      "Despite of a significant body of research in optimizing the virtual keyboard layout, none of them has gained large adoption, primarily due to the steep learning curve. To address this learning problem, we introduced three types of Qwerty constraints, Qwerty1, QwertyH1, and One-Swap bounds in layout optimization, and investigated their effects on layout learnability and performance. This bounded optimization process leads to IJQwerty, which has only one pair of keys different from Qwerty. Our theoretical analysis and user study show that IJQwerty improves the accuracy and input speed of gesture typing over Qwerty once a user reaches the expert mode. IJQwerty is also extremely easy to learn. The initial upon-use text entry speed is the same with Qwerty. Given the high performance and learnability, such a layout will more likely gain large adoption than any of previously obtained layouts. Our research also shows the disparity from Qwerty substantially affects layout learning. To minimize the learning effort, a new layout needs to hold a strong resemblance to Qwerty.\n",
      "5\n",
      "DualKey: Miniature Screen Text Entry via Finger Identification\n",
      "Fast and accurate access to keys for text entry remains an open question for miniature screens. Existing works typically use a cumbersome two-step selection process, first to zero-in on a particular zone and second to make the key selection. We introduce DualKey, a miniature screen text entry technique with a single selection step that relies on finger identification. We report on the results of a 10 day longitudinal study with 10 participants that evaluated speed, accuracy, and learning. DualKey outperformed the existing techniques on long-term performance with a speed of 19.6 WPM. We then optimized the keyboard layout for reducing finger switching time based on the study data. A second 10 day study with eight participants showed that the new sweqty layout improved upon DualKey even further to 21.59 WPM for long-term speed, was comparable to existing techniques on novice speed and outperformed existing techniques on novice accuracy rate.\n",
      "30\n",
      "A Real-Time IVR Platform for Community Radio\n",
      "Interactive Voice Response (IVR) platforms have been widely deployed in resource-limited settings. These systems tend to afford asynchronous push interactions, and within the context of health, provide medication reminders, descriptions of symptoms and tips on self-management. Here, we present the development of an IVR system for resource-limited settings that enables real-time, synchronous interaction. Inspired by community radio, and calls for health systems that are truly local, we developed \"Sehat ki Vaani\". Sehat ki Vaani is a real-time IVR platform that enables hosting and participation in radio chat shows on community-led topics. We deployed Sehat ki Vaani with two communities in North India on topics related to the management of Type 2 diabetes and maternal health. Our deployments highlight the potential for synchronous IVR systems to offer community connection and localised sharing of experience, while also highlighting the complexity of producing, hosting and participating in radio shows in real time through IVR. We discuss the relative strengths and weaknesses of synchronous IVR systems, and highlight lessons learnt for interaction design in this area.\n",
      "40\n",
      "Framing Feedback: Choosing Review Environment Features that Support High Quality Peer Assessment\n",
      "Peer assessment is rapidly growing in online learning, as it presents a method to address scalability challenges. However, research suggests that the benefits of peer review are obtained inconsistently. This paper explores why, introducing three ways that framing task goals significantly changes reviews. Three experiments manipulated features in the review environment. First, adding a numeric scale to open text reviews was found to elicit more explanatory, but lower quality reviews. Second, structuring a review task into short, chunked stages elicited more diverse feedback. Finally, showing reviewers a draft along with finished work elicited reviews that focused more on the work's goals than aesthetic details. These findings demonstrate the importance of carefully structuring online learning environments to ensure high quality peer reviews.\n",
      "64\n",
      "Not For Me: Older Adults Choosing Not to Participate in a Social Isolation Intervention\n",
      "This paper considers what we can learn from the experiences of people who choose not to participate in technology-based social interventions. We conducted ethnographically-informed field studies with socially isolated older adults, who used and evaluated a new iPad application designed to help build new social connections. In this paper we reflect on how the values and assumptions guiding the technological intervention were not always shared by those participating in the evaluation. Drawing on our field notes and interviews with the older adults who chose to discontinue participation, we use personas to illustrate the complexities and tensions involved in individual decisions to not participate. This analysis contributes to HCI research calling for a more critical perspective on technological interventions. We provide detailed examples highlighting the complex circumstances of our non-participants' lives, present a framework that outlines the socio-technical context of non-participation, and use our findings to promote reflective practice in HCI research that aims to address complex social issues.\n",
      "93\n",
      "Staying the Course: System-Driven Lapse Management for Supporting Behavior Change\n",
      "The negative effect of lapses during a behavior-change program has been shown to increase the risk of repeated lapses and, ultimately, program abandonment. In this paper, we examine the potential of system-driven lapse management -- supporting users through lapses as part of a behavior-change tool. We first review lessons from domains such as dieting and addiction research and discuss the design space of lapse management. We then explore the value of one approach to lapse management -- the use of \"cheat points\" -- as a way to encourage sustained participation. In an online study, we first examine interpretations of progress that was reached through using cheat points. We then present findings from a deployment of lapse management in a two-week field study with 30 participants. Our results demonstrate the potential of this approach to motivate and change users' behavior. We discuss important open questions for the design of future technology-mediated behavior change programs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "Anxiety and Autism: Towards Personalized Digital Health\n",
      "For many people living with conditions such as autism, anxiety manifests so powerfully it has a big impact on quality of life. By investigating the suitability of truly customizable wearable health devices we build on prior research that found each experience of anxiety in people with autism is unique, so 'one-suits all' solutions are not suitable. In addition, users desire agency and control in all aspects of the system. The participative approach we take is to iteratively co-develop prototypes with end users. Here we describe a case study of the co-development of one prototype, a digital stretch wristband that records interaction for later reflection called Snap. Snap has been designed to sit within a platform that allows the distributed and sustainable design, manufacture and data analysis of customizable digital health technologies. We contribute to HCI with (1) lessons learned from a DIY co-development process that follows the principles of modularity, participation and iteration and (2) the potential impact of technology in self-management of anxiety and the broader design implications of addressing unique anxiety experiences.\n",
      "128\n",
      "Programming, Problem Solving, and Self-Awareness: Effects of Explicit Guidance\n",
      "More people are learning to code than ever, but most learning opportunities do not explicitly teach the problem solving skills necessary to succeed at open-ended programming problems. In this paper, we present a new approach to impart these skills, consisting of: 1) explicit instruction on programming problem solving, which frames coding as a process of translating mental representations of problems and solutions into source code, 2) a method of visualizing and monitoring progression through six problem solving stages, 3) explicit, on-demand prompts for learners to reflect on their strategies when seeking help from instructors, and 4) context-sensitive help embedded in a code editor that reinforces the problem solving instruction. We experimentally evaluated the effects of our intervention across two 2-week web development summer camps with 48 high school students, finding that the intervention increased productivity, independence, programming self-efficacy, metacognitive awareness, and growth mindset. We discuss the implications of these results on learning technologies and classroom instruction.\n",
      "152\n",
      "'Don't Waste My Time': Use of Time Information Improves Focus\n",
      "Maintaining work focus when on a computer is a major challenge, and people often feel that they use their time ineffectively. To improve focus we designed meTime, a real-time awareness application that shows users how they allocate their time across applications. In two real-world deployments involving 118 participants, we examined whether greater awareness of time use improves focus. In our first deployment, we provided awareness information using meTime, to both office workers and students. Exposure to meTime reduced use of social media, email, browsing and total time online. However increased awareness didn't affect time spent in productivity applications. A second educational deployment largely replicated these results and showed that meTime also reduced users' perceptions of their ability to focus effectively. Changed perceptions were associated with higher class grades. We discuss practical and theoretical implications as well as design principles for use of time applications.\n",
      "163\n",
      "Facilitator, Functionary, Friend or Foe?: Studying the Role of iPads within Learning Activities Across a School Year\n",
      "We present the findings from a longitudinal study of iPad use in a Primary school classroom. While tablet devices have found their way into classroom environments, we still lack in-depth and long-term studies of how they integrate into everyday classroom activities. Our findings illustrate in-classroom tablet use and the broad range of learning activities in subjects such as maths, languages, social sciences, and even physical education. Our observations expand current models on teaching and learning supported by tablet technology. Our findings are child-centred, focusing on three different roles that tablets can play as part of learning activities: Friend, Functionary, and Facilitator. This new perspective on in-classroom tablet use can facilitate critical discussions around the integration and impact of these devices in the educational context, from a design and educational point of view.\n",
      "238\n",
      "Atelier: Repurposing Expert Crowdsourcing Tasks as Micro-internships\n",
      "Expert crowdsourcing marketplaces have untapped potential to empower workers' career and skill development. Currently, many workers cannot afford to invest the time and sacrifice the earnings required to learn a new skill, and a lack of experience makes it difficult to get job offers even if they do. In this paper, we seek to lower the threshold to skill development by repurposing existing tasks on the marketplace as mentored, paid, real-world work experiences, which we refer to as micro-internships. We instantiate this idea in Atelier, a micro-internship platform that connects crowd interns with crowd mentors. Atelier guides mentor-intern pairs to break down expert crowdsourcing tasks into milestones, review intermediate output, and problem-solve together. We conducted a field experiment comparing Atelier's mentorship model to a non-mentored alternative on a real-world programming crowdsourcing task, finding that Atelier helped interns maintain forward progress and absorb best practices.\n",
      "285\n",
      "Alloy: Clustering with Crowds and Computation\n",
      "Crowdsourced clustering approaches present a promising way to harness deep semantic knowledge for clustering complex information. However, existing approaches have difficulties supporting the global context needed for workers to generate meaningful categories, and are costly because all items require human judgments. We introduce Alloy, a hybrid approach that combines the richness of human judgments with the power of machine algorithms. Alloy supports greater global context through a new \"sample and search\" crowd pattern which changes the crowd's task from classifying a fixed subset of items to actively sampling and querying the entire dataset. It also improves efficiency through a two phase process in which crowds provide examples to help a machine cluster the head of the distribution, then classify low-confidence examples in the tail. To accomplish this, Alloy introduces a modular \"cast and gather\" approach which leverages a machine learning backbone to stitch together different types of judgment tasks.\n",
      "318\n",
      "\"Counting on the Group\": Reconciling Online and Offline Social Support among Older Informal Caregivers\n",
      "Awareness of the huge amount of work faced by relatives in caring for a person suffering from a loss of autonomy has led to research focusing on ways to ease the burden on informal caregivers. Among them, services and devices aimed at providing social support and fighting the isolation that may be caused by the caregiving tasks appear important. However, little is known about the social support informal caregivers actually value and look for in practice. To fill this gap, we conducted a multi-sited study, focusing on older informal caregivers, because they are numerous and have lower experience with technology. Our study highlights that being part of a group is a key element in helping informal caregivers to feel that they are not alone, continue leisure activities, learn from others and sustain participation in organized activities. Through this understanding, we discuss design opportunities in a sociotechnical approach complementing online and offline social support.\n",
      "329\n",
      "Telling Stories about Dynamic Networks with Graph Comics\n",
      "In this paper, we explore graph comics as a medium to communicate changes in dynamic networks. While previous re- search has focused on visualizing dynamic networks for data exploration, we want to see if we can take advantage of the visual expressiveness and familiarity of comics to present and explain temporal changes in networks to an audience. To understand the potential of comics as a storytelling medium, we first created a variety of comics during a 3 month structured design process, involving domain experts from public education and neuroscience. This process led to the definition of 8 design factors for creating graph comics and propose design solutions for each. Results from a qualitative study suggest that a general audience is quickly able understand complex temporal changes through graph comics, provided with minimal textual annotations and no training.\n",
      "350\n",
      "Designing Cyberbullying Mitigation and Prevention Solutions through Participatory Design With Teenagers\n",
      "While social media platforms enable individuals to easily communicate and share experiences, they have also emerged as a tool for cyberbullying. Teenagers represent an especially vulnerable population for negative emotional responses to cyberbullying. At the same time, attempts to mitigate or prevent cyberbullying from occurring in these networked spaces have largely failed because of the complexity and nuance with which young people bully others online. To address challenges related to designing for cyberbullying intervention and mitigation, we detail findings from participatory design work with two groups of high school students in spring 2015. Over the course of five design sessions spanning five weeks, participants shared their experiences with cyberbullying and iteratively designed potential solutions. We provide an in-depth discussion of the range of cyberbullying mitigation solutions participants designed. We focus on challenges participants' identified in designing for cyberbullying support and prevention and present a set of five potential cyberbullying mitigation solutions based on the results of the design sessions.\n",
      "381\n",
      "The Flat Finger: Exploring Area Touches on Smartwatches\n",
      "Smartwatches are emerging device category that feature highly limited input and display surfaces. We explore how touch contact areas, such as lines generated by flat fingers, can be used to increase input expressivity in these diminutive systems in three ways. Firstly, we present four design themes that emerged from an ideation workshop in which five designers proposed concepts for smartwatch touch area interaction. Secondly, we describe a sensor unit and study that captured user performance with 31 area touches and contrasted this against standard targeting performance. Finally, we describe three demonstration applications that instantiate ideas from the workshop and deploy the most reliably and rapidly produced area touches. We report generally positive user reactions to these demonstrators: the area touch interactions were perceived as quick, convenient and easy to learn and remember. Together this work characterizes how designers can use area touches in watch UIs, which area touches are most appropriate and how users respond to this interaction style.\n",
      "383\n",
      "How We Type: Movement Strategies and Performance in Everyday Typing\n",
      "This paper revisits the present understanding of typing, which originates mostly from studies of trained typists using the ten-finger touch typing system. Our goal is to characterise the majority of present-day users who are untrained and employ diverse, self-taught techniques. In a transcription task, we compare self-taught typists and those that took a touch typing course. We report several differences in performance, gaze deployment and movement strategies. The most surprising finding is that self-taught typists can achieve performance levels comparable with touch typists, even when using fewer fingers. Motion capture data exposes 3 predictors of high performance: 1) unambiguous mapping (a letter is consistently pressed by the same finger), 2) active preparation of upcoming keystrokes, and 3) minimal global hand motion. We release an extensive dataset on everyday typing behavior.\n",
      "419\n",
      "Empath: Understanding Topic Signals in Large-Scale Text\n",
      "Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like \"bleed\" and \"punch\" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r=0.906) with similar categories in LIWC.\n",
      "421\n",
      "Faster Command Selection on Touchscreen Watches\n",
      "Small touchscreens worn on the wrist are becoming increasingly common, but standard interaction techniques for these devices can be slow, requiring a series of coarse swipes and taps to perform an action. To support faster command selection on watches, we investigate two related interaction techniques that exploit spatial memory. WristTap uses multitouch to allow selection in a single action, and TwoTap uses a rapid combination of two sequential taps. In three quantitative studies, we investigate the design and performance of these techniques in comparison to standard methods. Results indicate that both techniques are feasible, able to accommodate large numbers of commands, and fast users are able to quickly learn the techniques and reach performance of ~1.0 seconds per selection, which is approximately one-third of the time of standard commercial techniques. We also provide insights into the types of applications for which these techniques are well-suited, and discuss how the techniques could be extended.\n",
      "425\n",
      "A Systematic Assessment of Smartphone Usage Gaps\n",
      "Researchers who analyse smartphone usage logs often make the assumption that users who lock and unlock their phone for brief periods of time (e.g., less than a minute) are continuing the same \"session\" of interaction. However, this assumption is not empirically validated, and in fact different studies apply different arbitrary thresholds in their analysis. To validate this assumption, we conducted a field study where we collected user-labelled activity data through ESM and sensor logging. Our results indicate that for the majority of instances where users return to their smartphone, i.e., unlock their device, they in fact begin a new session as opposed to continuing a previous one. Our findings suggest that the commonly used approach of ignoring brief standby periods is not reliable, but optimisation is possible. We therefore propose various metrics related to usage sessions and evaluate various machine learning approaches to classify gaps in usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "Learn Piano with BACh: An Adaptive Learning Interface that Adjusts Task Difficulty Based on Brain State\n",
      "We present Brain Automated Chorales (BACh), an adaptive brain-computer system that dynamically increases the levels of difficulty in a musical learning task based on pianists' cognitive workload measured by functional near-infrared spectroscopy. As users' cognitive workload fell below a certain threshold, suggesting that they had mastered the material and could handle more cognitive information, BACh automatically increased the difficulty of the learning task. We found that learners played with significantly increased accuracy and speed in the brain-based adaptive task compared to our control condition. Participant feedback indicated that they felt they learned better with BACh and they liked the timings of the level changes. The underlying premise of BACh can be applied to learning situations where a task can be broken down into increasing levels of difficulty.\n",
      "505\n",
      "Crumbs: Lightweight Daily Food Challenges to Promote Engagement and Mindfulness\n",
      "Many people struggle with efforts to make healthy behavior changes, such as healthy eating. Several existing approaches promote healthy eating, but present high barriers and yield limited engagement. As a lightweight alternative approach to promoting mindful eating, we introduce and examine crumbs: daily food challenges completed by consuming one food that meets the challenge. We examine crumbs through developing and deploying the iPhone application Food4Thought. In a 3 week field study with 61 participants, crumbs supported engagement and mindfulness while offering opportunities to learn about food. Our 2x2 study compared nutrition versus non-nutrition crumbs coupled with social versus non-social features. Nutrition crumbs often felt more purposeful to participants, but non-nutrition crumbs increased mindfulness more than nutrition crumbs. Social features helped sustain engagement and were important for engagement with non-nutrition crumbs. Social features also enabled learning about the variety of foods other people use to meet a challenge.\n",
      "510\n",
      "Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models\n",
      "Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these naïve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why specific datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.\n",
      "533\n",
      "\"Just whack it on until it gets hot\": Working with IoT Data in the Home\n",
      "This paper presents findings from a co-design project that aims to augment the practices of professional energy advisors with environmental data from sensors deployed in clients' homes. Premised on prior ethnographic observations we prototyped a sensor platform to support the work of tailoring advice-giving to particular homes. We report on the deployment process and the findings to emerge, particularly the work involved in making sense of or accounting for the data in the course of advice-giving. Our ethnomethodological analysis focuses on the ways in which data is drawn upon as a resource in the home visit, and how understanding and advice-giving turns upon unpacking the indexical relationship of the data to the situated goings-on in the home. This insight, coupled with further design workshops with the advisors, shaped requirements for an interactive system that makes the sensor data available for visual inspection and annotation to support the situated sense-making that is key to giving energy advice.\n",
      "2015\n",
      "42\n",
      "ModelTracker: Redesigning Performance Analysis Tools for Machine Learning\n",
      "Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker's debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance.\n",
      "57\n",
      "Sensors Know When to Interrupt You in the Car: Detecting Driver Interruptibility Through Monitoring of Peripheral Interactions\n",
      "Interruptions while driving can be quite dangerous, whether these are self-interruptions or external interruptions. They increase driver workload and reduce performance on the primary driving task. Being able to identify when a driver is interruptible is critical for building systems that can mediate these interruptions. In this paper, we collect sensor and human-annotated data from 15 drivers, including vehicle motion, traffic states, physiological responses and driver motion. We demonstrate that this data can be used to build a machine learning classifier that can determine interruptibility every second with a 94% accuracy. We present both population and individual models and discuss the features that contribute to the high performance of this system. Such a classifier can be used to build systems that mediate when drivers use technology to self-interrupt and when drivers are interrupted by technology.\n",
      "61\n",
      "The Virtual Meditative Walk: Virtual Reality Therapy for Chronic Pain Management\n",
      "Because the nature of chronic pain is complex, pharmacological analgesics are often not enough to achieve an ideal treatment plan. Virtual Reality (VR) technologies have emerged within medical research in recent years for treating acute pain, and proved to be an effective strategy based on pain distraction. This paper describes a VR system designed for chronic pain patients. The system incorporates biofeedback sensors, an immersive virtual environment, and stereoscopic sound titled the \"Virtual Meditative Walk\" (VMW). It was designed to enable chronic pain patients to learn Mindfulness-based stress reduction (MBSR), a form of meditation. By providing real-time visual and sonic feedback, VMW enables patients to learn how to manage their pain. A proof-of-concept user study was conducted to investigate the effectiveness of the VR system with chronic pain patients in clinical settings. Results show that the VMW was more effective in reducing perceived pain compared to the non-VR control condition.\n",
      "73\n",
      "The Proper Care and Feeding of Hackerspaces: Care Ethics and Cultures of Making\n",
      "Communities of making have been at the center of attention in popular, business, political, and academic research circles in recent years. In HCI, they seem to carry the promise of new forms of computer use, education, innovation, and even ways of life. In the West in particular, the maker manifestos of these communities have shown strong elements of a neoliberal ethos, one that prizes self-determination, tech-savvy, independence, freedom from government, suspicion of authority, and so forth. Yet such communities, to function as communities, also require values of collaboration, cooperation, interpersonal support-in a word, care. In this ethnographic study, we studied and participated as members of a hackerspace for 19 months, focusing in particular not on their technical achievements, innovations, or for glimmers of a more sustainable future, but rather to make visible and to analyze the community maintenance labor that helps the hackerspace support the practices that its members, society, and HCI research are so interested in. We found that the maker ethic entails a complex negotiation of both a neoliberal libertarian ethos and a care ethos.\n",
      "79\n",
      "Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos\n",
      "Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity. Moreover, the content of comments would further affect learners' intention of commenting. Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education.\n",
      "98\n",
      "Fluid Grouping: Quantifying Group Engagement around Interactive Tabletop Exhibits in the Wild\n",
      "Interactive surfaces are increasingly common in museums and other informal learning environments where they are seen as a medium for promoting social engagement. However, despite their increasing prevalence, we know very little about factors that contribute to collaboration and learning around interactive surfaces. In this paper we present analyses of visitor engagement around several multi-touch tabletop science exhibits. Observations of 629 visitors were collected through two widely used techniques: video study and shadowing. We make four contributions: 1) we present an algorithm for identifying groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures of group-level engagement along with methods for statistically analyzing these measures; 3) we assess the effect of observational techniques on visitors' engagement, demonstrating that consented video studies do not necessarily reflect visitor behavior in more naturalistic circumstances; and 4) we present an analysis showing that groups of two, groups with both children and adults, and groups that take turns spend longer at the exhibits and engage more with scientific concepts.\n",
      "115\n",
      ": Haptic Feedback to Enhance Early Reading\n",
      "Engaging children with traditional approaches in education, especially reading, grows ever more difficult in the face of their attachment to tablets and computer games. We explore the possibility of making the story reading experience more interesting and memorable for children using haptic augmentation. In this paper, we present FeelSleeve, an interface that allows children to feel story events in their hands while they are reading on a mobile device. FeelSleeve uses transducers and audio output from the tablet within a gloved attachment to create vibratory effects that are meaningfully related to story content. We describe a study investigating whether embedding such haptic feedback into stories enhances reading for six to nine year olds. Our results indicate that story events accompanied by haptic feedback are better comprehended and appear to be more salient in memory. These results provide evidence that haptic effects have the potential to improve children's reading experience and make it more memorable.\n",
      "116\n",
      "BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization\n",
      "Internal organs are hidden and untouchable, making it difficult for children to learn their size, position, and function. Traditionally, human anatomy (body form) and physiology (body function) are taught using techniques ranging from worksheets to three-dimensional models. We present a new approach called BodyVis, an e-textile shirt that combines biometric sensing and wearable visualizations to reveal otherwise invisible body parts and functions. We describe our 15-month iterative design process including lessons learned through the development of three prototypes using participatory design and two evaluations of the final prototype: a design probe interview with seven elementary school teachers and three single-session deployments in after-school programs. Our findings have implications for the growing area of wearables and tangibles for learning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos\n",
      "Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners' responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural knowledge. Teachers found the exercises useful for capturing students' thought processes, identifying misconceptions, and engaging students with content.\n",
      "179\n",
      "Mudslide: A Spatially Anchored Census of Student Confusion for Online Lecture Videos\n",
      "Educators have developed an effective technique to get feedback after in-person lectures, called \"muddy cards.\" Students are given time to reflect and write the \"muddiest\" (least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students' muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers' and students' experiences with our prototype.\n",
      "191\n",
      "Sensitive Lifelogs: A Privacy Analysis of Photos from Wearable Cameras\n",
      "While media reports about wearable cameras have focused on the privacy concerns of bystanders, the perspectives of the `lifeloggers' themselves have not been adequately studied. We report on additional analysis of our previous in-situ lifelogging study in which 36 participants wore a camera for a week and then reviewed the images to specify privacy and sharing preferences. In this Note, we analyze the photos themselves, seeking to understand what makes a photo private, what participants said about their images, and what we can learn about privacy in this new and very different context where photos are captured automatically by one's wearable camera. We find that these devices record many moments that may not be captured by traditional (deliberate) photography, with camera owners concerned about impression management and protecting private information of both themselves and bystanders.\n",
      "219\n",
      "Understanding and Supporting Fathers and Fatherhood on Social Media Sites\n",
      "Fathers are taking on more childcare and household responsibilities than they used to and many non-profit and government organizations have pushed for changes in policies to support fathers. Despite this effort, little research has explored how fathers go online related to their roles as fathers. Drawing on an interview study with 37 fathers, we find that they use social media to document and archive fatherhood, learn how to be a father, and access social support. They also go online to support diverse family needs, such as single fathers' use of Reddit instead of Facebook, fathers raised by single mothers' search for role models online, and stay-at-home fathers' use of father blogs. However, fathers are constrained by privacy concerns and perceptions of judgment relating to sharing content online about their children. Drawing on theories of fatherhood, we present theoretical and design ideas for designing online spaces to better support fathers and fatherhood. We conclude with a call for a research agenda to support fathers online.\n",
      "231\n",
      "Flow is Not Enough: Understanding the Needs of Advanced Amateur Runners to Design Motivation Technology\n",
      "Motivation studies on running are often focused on how to convince non-runners to run, mainly through designing for extrinsic motivations such as health concerns or external reward systems. In contrast, we conducted a structured inquiry into understanding how to design technology for those whom are already committed to running and participate in organized races. Through interviews, focus groups, ethnographic observation, questionnaires, and design-based research over the course of two years, we investigated the needs of the advanced amateur runner community. An analysis of the gathered data led to five design themes -- Festival, Competition, Practicalities, Togetherness, and Support -- to inform future runner motivation technology. While flow theory appears to be a convenient tool to understand support during a race, we observed a number of other factors that need to be considered. Through combining the themes with previous research, we conclude by presenting nine guidelines for designing technology for this domain.\n",
      "238\n",
      "Expanding and Refining Design and Criticality in HCI\n",
      "The term 'critical design' is on the upswing in HCI. We analyze how discourses around 'critical design' are diverging in Design and HCI. We argue that this divergence undermines HCI's ability to learn from and appropriate the design approaches signaled by this term. Instead, we articulate two ways to broaden and deepen connections between Design and HCI: (1) develop a broader collective understanding of what these design approaches can be, without forcing them to be about 'criticality' or 'critical design,' narrowly construed; and (2) shape a variation of design criticism to better meet Design practices, terms, and ways of knowing.\n",
      "257\n",
      "Moving Beyond Fun: Evaluating Serious Experience in Digital Games\n",
      "Games are normally considered to be \"fun\", though recently there is growing interest in how gameplay can promote empathy and encourage reflection through \"serious experience\". However, when looking beyond enjoyment, it is not clear how to actually evaluate serious experience. We present an evaluation of four games that were submitted to a student game design competition; the competition challenged teams to design a game that inspired curiosity around human error and blame culture within the context of healthcare. The entries were judged by a panel of six experts and subjected to a round of play testing by twelve participants. Methods included gameplay observation, questionnaires, post-play interviews and follow-up email questions. We discuss the utility of these methods, with particular emphasis on how they enabled a consideration of the immediate and longer term impact of serious experience on players.\n",
      "328\n",
      "Scaling the Security Wall: Developing a Security Behavior Intentions Scale (SeBIS)\n",
      "Despite the plethora of security advice and online education materials offered to end-users, there exists no standard measurement tool for end-user security behaviors. We present the creation of such a tool. We surveyed the most common computer security advice that experts offer to end-users in order to construct a set of Likert scale questions to probe the extent to which respondents claim to follow this advice. Using these questions, we iteratively surveyed a pool of 3,619 computer users to refine our question set such that each question was applicable to a large percentage of the population, exhibited adequate variance between respondents, and had high reliability (i.e., desirable psychometric properties). After performing both exploratory and confirmatory factor analysis, we identified a 16-item scale consisting of four sub-scales that measures attitudes towards choosing passwords, device securement, staying up-to-date, and proactive awareness.\n",
      "364\n",
      "You Tweet What You Eat: Studying Food Consumption Through Twitter\n",
      "Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis & Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships.\n",
      "419\n",
      "Wait-Learning: Leveraging Wait Time for Second Language Education\n",
      "Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. In this paper, we explore wait-learning: leveraging brief moments of waiting during a person's existing conversations for second language vocabulary practice, even if the conversation happens in the native language. We present an augmented version of instant messaging, WaitChatter, that supports the notion of wait-learning by displaying contextually relevant foreign language vocabulary and micro-quizzes just-in-time while the user awaits a response from her conversant. Through a two week field study of WaitChatter with 20 people, we found that users were able to learn 57 new words on average during casual instant messaging. Furthermore, we found that users were most receptive to learning opportunities immediately after sending a chat message, and that this timing may be critical given user tendency to multi-task during waiting periods.\n",
      "425\n",
      "Computer-Enabled Project Spaces: Connecting with Palestinian Refugees across Camp Boundaries\n",
      "Come_IN computer clubs are an established approach to support inter-cultural and inter-generational learning in German neighborhoods. We explore the adaptation of the come_IN concept to the Palestinian context as a means to bridge the social and economic divide that has plagued West Bank society for a period of more than six decades. Social exclusion, political conflicts and prolonged military occupation have kept the refugee camps in a perpetual state of marginalization. In this paper we report on our work in Al Amari-- a Palestinian refugee camp adjacent to the city of Ramallah. We examine how the computer club enables the emergence of social ties among residents of the camp and university students acting as tutors. Even though the ties are small-scale and informal, they have the potential to generate new and wider opportunities for exchange that may eventually support more social integration between the camp's marginalized population and the wider Palestinian population.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "50\n",
      "Faceted metadata for image search and browsing\n",
      "There are currently two dominant interface types for searching and browsing large image collections: keyword-based search, and searching by overall similarity to sample images. We present an alternative based on enabling users to navigate along conceptual dimensions that describe the images. The interface makes use of hierarchical faceted metadata and dynamically generated query previews. A usability study, in which 32 art history students explored a collection of 35,000 fine arts images, compares this approach to a standard image search interface. Despite the unfamiliarity and power of the interface (attributes that often lead to rejection of new search interfaces), the study results show that 90% of the participants preferred the metadata approach overall, 97% said that it helped them learn more about the collection, 75% found it more flexible, and 72% found it easier to use than a standard baseline system. These results indicate that a category-based approach is a successful way to provide access to image collections.\n",
      "73\n",
      "Is seeing believing?: how recommender system interfaces affect users' opinions\n",
      "Recommender systems use people's opinions about items in an information domain to help people choose other items. These systems have succeeded in domains as diverse as movies, news articles, Web pages, and wines. The psychological literature on conformity suggests that in the course of helping people make choices, these systems probably affect users' opinions of the items. If opinions are influenced by recommendations, they might be less valuable for making recommendations for other users. Further, manipulators who seek to make the system generate artificially high or low recommendations might benefit if their efforts influence users to change the opinions they contribute to the recommender. We study two aspects of recommender system interfaces that may affect users' opinions: the rating scale and the display of predictions at the time users rate items. We find that users rate fairly consistently across rating scales. Users can be manipulated, though, tending to rate toward the prediction the system shows, whether the prediction is accurate or not. However, users can detect systems that manipulate predictions. We discuss how designers of recommender systems might react to these findings.\n",
      "2002\n",
      "21\n",
      "An evaluation of a multiple interface design solution for bloated software\n",
      "This study examines a novel interface design for heavily-featured productivity software. The design includes two interfaces between which the user can easily toggle: (1) an interface personalized by the user containing desired features only, and (2) the default interface with all the standard features. This design was prototyped as a front-end to a commercial word processor and evaluated in a comprehensive field study. The study tested the effects of different interface designs on users' satisfaction and their perceived ability to navigate, control, and learn the software. There were two conditions: a commercial word processor with adaptive menus and our two-interface prototype with adaptable menus for the same word processor. Results showed that participants were better able to navigate through the menus and toolbars and were better able to learn with our prototype. There were also significant differences in satisfaction and control with our design\n",
      "1992\n",
      "4\n",
      "Evaluating video as a technology for informal communication\n",
      "Collaborations in organizations thrive on communication that is informal because informal communication is frequent, interactive, and expressive. Informal communication is crucial for the coordination of work, learning an organization's culture, the perpetuation of the social relations that underlie collaboration, and, in general, any situation that requires communication to resolve ambiguity. Informal communication is traditionally mediated by physical proximity, but physical proximity cannot mediate in geographically distributed organizations. The research described here evaluates the adequacy of a version of a desktop video/audio conferencing system for supporting informal communication in a research and development laboratory. The evaluation took place during a trial in which the system was used by summer employees and their supervisor-mentors. While the system was used frequently, the most common uses and users' assessments suggest that it was used more like a telephone or electronic mail than like physically mediated face-to-face communication. However, some features of its use transcended traditional media and allowed users to gain awareness of their work environment. The paper concludes with a discussion of requirements for successful technology to support informal communication.\n",
      "29\n",
      "Survey on user interface programming\n",
      "This paper reports on the results of a survey of user interface programming. The survey was widely distributed, and we received 74 responses. The results show that in today's applications, an average of 48% of the code is devoted to the user interface portion. The average time spent on the user interface portion is 45% during the design phase, 50% during the implementation phase, and 37% during the maintenance phase. 34% of the systems were implemented using a toolkit, 27% used a UIMS, 14% used an interface builder, and 26% used no tools. This appears to be because the toolkit systems had more sophisticated user interfaces. The projects using UIMSs or interface builders spent the least percent of time and code on the user interface (around 41%) suggesting that these tools are effective. In general, people were happy with the tools they used, especially the graphical interface builders. The most common problems people reported when developing a user interface included getting users' requirements, writing help text, achieving consistency, learning how to use the tools, getting acceptable performance, and communicating among various parts of the program.\n",
      "96\n",
      "Dynamic queries for information exploration: an implementation and evaluation\n",
      "We designed, implemented and evaluated a new concept for direct manipulation of databases, called dynamic queries, that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster using a dynamic queries interface compared to two interfaces both providing form fill-in as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to explore the periodic table of elements and search on their properties.\n",
      "Using spatial cues to improve videoconferencing\n",
      "An abstract is not available.\n",
      "103\n",
      "1991\n",
      "EAGER: programming repetitive tasks by example\n",
      "An abstract is not available.\n",
      "5\n",
      "Technology affordances\n",
      "An abstract is not available.\n",
      "11\n",
      "Effective sounds in complex systems: the ARKOLA simulation\n",
      "An abstract is not available.\n",
      "12\n",
      "Disembodied conduct: communication through video in a multi-media office environment\n",
      "An abstract is not available.\n",
      "14\n",
      "User interface evaluation in the real world: a comparison of four techniques\n",
      "An abstract is not available.\n",
      "17\n",
      "Triggers and barriers to customizing software\n",
      "An abstract is not available.\n",
      "22\n",
      "A comparison of input devices in element pointing and dragging tasks\n",
      "An abstract is not available.\n",
      "23\n",
      "The perspective wall: detail and context smoothly integrated\n",
      "An abstract is not available.\n",
      "25\n",
      "The information visualizer, an information workspace\n",
      "An abstract is not available.\n",
      "26\n",
      "Cone Trees: animated 3D visualizations of hierarchical information\n",
      "An abstract is not available.\n",
      "27\n",
      "Experiences in the use of a media space\n",
      "An abstract is not available.\n",
      "29\n",
      "PICTIVE—an exploration in participatory design\n",
      "An abstract is not available.\n",
      "32\n",
      "VideoWhiteboard: video shadows to support remote collaboration\n",
      "An abstract is not available.\n",
      "45\n",
      "2018\n",
      "68\n",
      "Blocks4All: Overcoming Accessibility Barriers to Blocks Programming for Children with Visual Impairments\n",
      "Blocks-based programming environments are a popular tool to teach children to program, but they rely heavily on visual metaphors and are therefore not fully accessible for children with visual impairments. We evaluated existing blocks-based environments and identified five major accessibility barriers for visually impaired users. We explored techniques to overcome these barriers in an interview with a teacher of the visually impaired and formative studies on a touchscreen blocks-based environment with five children with visual impairments. We distill our findings on usable touchscreen interactions into guidelines for designers of blocks-based environments.\n",
      "103\n",
      "On the Design of OLO Radio: Investigating Metadata as a Design Material\n",
      "With the massive adoption of music streaming services globally, metadata is being generated that captures people's music listening histories in more precise detail than ever before. These metadata archives offer a valuable and overlooked resource for designing new ways of supporting people in experiencing the music they have listened to over the course of their lives. Yet, little research has demonstrated how metadata can be applied as a material in design practice. We describe the design of OLO Radio, a device that leverages music listening history metadata to support experiences of exploring and living with music from one's past. We unpack and reflect on design choices that made use of the exacting precision captured in listening history metadata archives to support relatively imprecise qualities of feedback and interaction to encourage rich, open-ended experiences of contemplation, curiosity, and enjoyment over time. We conclude with implications for HCI research and practice in this space.\n",
      "124\n",
      "Co-performance: Conceptualizing the Role of Artificial Agency in the Design of Everyday Life\n",
      "This paper introduces the notion of co-performance, with the aim to offer Human-Computer Interaction (HCI) researchers and practitioners a new perspective on the role of artificial agency in everyday life, from automated systems to autonomous devices. In contrast to 'smartness,' which focuses on a supposed autonomy of artifacts, co-performance considers artifacts as capable of learning and performing next to people. This shifts the locus of design from matters of distributions of agency at design time, to matters of embodied learning in everyday practice for both human and artificial performers. From this perspective, co-performance acknowledges the dynamic differences in capabilities between humans and artifacts, and highlights the fundamentally recursive relation between professional design and use. Implications for HCI design practice are unpacked through reflections on smart thermostat design in light of historic changes in roles between humans and heating systems, and changing ideas of appropriateness in everyday practices of domestic heating.\n",
      "129\n",
      "Mapping Machine Learning Advances from HCI Research to Reveal Starting Places for Design Innovation\n",
      "HCI has become particularly interested in using machine learning (ML) to improve user experience (UX). However, some design researchers claim that there is a lack of design innovation in envisioning how ML might improve UX. We investigate this claim by analyzing 2,494 related HCI research publications. Our review confirmed a lack of research integrating UX and ML. To help span this gap, we mined our corpus to generate a topic landscape, mapping out 7 clusters of ML technical capabilities within HCI. Among them, we identified 3 under-explored clusters that design researchers can dig in and create sensitizing concepts for. To help operationalize these technical design materials, our analysis then identified value channels through which the technical capabilities can provide value for users: self, context, optimal, and utility-capability. The clusters and the value channels collectively mark starting places for envisioning new ways for ML technology to improve people's lives.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "Coco's Videos: An Empirical Investigation of Video-Player Design Features and Children's Media Use\n",
      "In this study, we present Coco's Videos, a video-viewing platform for preschoolers designed to support them in learning to self-manage their media consumption. We report results from a three-week experimental deployment in 24 homes in which preschoolers used three different versions of the platform: one that is neutral to the limits they set, one that enforces the limits they set, and one that attempts to erode the limits they set by automatically playing additional content after the planned content is finished (\"post-play\"). We found that post-play significantly reduced children's autonomy and likelihood of self-regulation, extended video-viewing time, and led to increases in parent intervention. We found that the lock-out mechanism did not reduce video-viewing time or the likelihood of parent intervention. Together, our results suggest that avoiding platforms that work to undermine the user's intentions is more likely to help children self-regulate their media use than rigid parental controls.\n",
      "264\n",
      "Bots & (Main)Frames: Exploring the Impact of Tangible Blocks and Collaborative Play in an Educational Programming Game\n",
      "While recent work has begun to evaluate the efficacy of educational programming games, many common design decisions in these games (e.g., single player gameplay using touchpad or mouse) have not been explored for learning outcomes. For instance, alternative design approaches such as collaborative play and embodied interaction with tangibles may also provide important benefits to learners. To better understand how these design decisions impact learning and related factors, we created an educational programming game that allows for systematically varying input method and mode of play. In this paper, we describe design rationale for mouse and tangible versions of our game, and report a 2x2 factorial experiment comparing efficacy of mouse and tangible input methods with individual and collaborative modes of play. Results indicate tangibles have a greater positive impact on learning, situational interest, enjoyment, and programming self-beliefs. We also found collaborative play helps further reduce programming anxiety over individual play.\n",
      "276\n",
      "Science Everywhere: Designing Public, Tangible Displays to Connect Youth Learning Across Settings\n",
      "A major challenge in education is understanding how to connect learning experiences across settings (e.g., school, afterschool, and home) for youth. In this paper, we introduce and describe the participatory design process we undertook to develop Science Everywhere (SE), which is a sociotechnical system where children share their everyday science learning via social media. Public displays installed throughout the neighborhood invite parents, adults, peers, and community members to interact with children's ideas to better develop connections for learning across settings. Our case study of community interactions with the public displays illuminate how these technologies encouraged behaviors such as the noticing of children's ideas, recognition of people in the neighborhood, and bridging to new learning opportunities for youth.\n",
      "344\n",
      "“Bursting the Assistance Bubble”: Designing Inclusive Technology with Children with Mixed Visual Abilities\n",
      "Children living with visual impairments (VIs) are increasingly educated in mainstream rather than special schools. But knowledge about the challenges they face in inclusive schooling environments and how to design technology to overcome them remains scarce. We report findings from a field study involving interviews and observations of educators and children with/without VIs in mainstream schools, in which we identified the \"teaching assistant bubble\" as a potential barrier to group learning, social play and independent mobility. We present co-design activities blending elements of future workshops, multisensory crafting, fictional inquiry and bodystorming, demonstrating that children with and without VIs can jointly lead design processes and explore design spaces reflective of mixed visual abilities and shared experiences. We extend previous research by characterising challenges and opportunities for improving inclusive education of children with VIs in mainstream schools, in terms of balancing assistance and independence, and reflect on the process and outcomes of co-designing with mixed-ability groups in this context.\n",
      "385\n",
      "ConceptScape: Collaborative Concept Mapping for Video Learning\n",
      "While video has become a widely adopted medium for online learning, existing video players provide limited support for navigation and learning. It is difficult to locate parts of the video that are linked to specific concepts. Also, most video players afford passive watching, thus making it difficult for learners with limited metacognitive skills to deeply engage with the content and reflect on their understanding. To support concept-driven navigation and comprehension of lecture videos, we present ConceptScape, a system that generates and presents a concept map for lecture videos. ConceptScape engages crowd workers to collaboratively generate a concept map by prompting them to externalize reflections on the video. We present two studies to show that (1) interactive concept maps can be useful tools for concept-based video navigation and comprehension, and (2) with ConceptScape, novice crowd workers can collaboratively generate complex concept maps that match the quality of those by experts.\n",
      "387\n",
      "Prayana: Intermediated Financial Management in Resource-Constrained Settings\n",
      "We describe the design of a novel mobile phone-based application for loan management in a resource-constrained setting. In this setting, a social enterprise manages auto-rickshaw loans for drivers, taking charge of collections. The design was informed by an ethnographic study which revealed how loan management for this financially vulnerable population is a daily struggle, and loan payment is a collaborative achievement between collectors and drivers. However, drivers and collectors have limited resources to-hand for loan management. To address this, we designed Prayana, an intermediated financial management app. Prayana shares the principles of many persuasive technologies, such as education, motivation, and nudges, but is designed for users with a range of print, technical, and financial literacies and embodies the core design sensibility of enhancing users' agency. Furthermore, it does not put the onus solely on drivers to better manage their money, instead it aims to enhance the collaborative work of loan management, supporting both the drivers and collectors.\n",
      "390\n",
      "Coding Tactile Symbols for Phonemic Communication\n",
      "We present a study to examine one's learning and processing capacity of broadband tactile information, such as that derived from speech. In Study 1, we tested a user's capability to recognize tactile locations and movements on the forearm in the presence of masking stimuli and determined 9 distinguishable tactile symbols. We associated these symbols to 9 phonemes using two approaches, random and articulation associations. Study 2 showed that novice participants can learn both associations. However, performance for retention, construction of words and knowledge transfer to recognize unlearned words was better with articulation association. In study 3, we trained novel participants to directly recognize words before learning phonemes. Our results show that novel users can retain and generalize the knowledge to recognize new words faster when they were directly train on words. Finally, Study 4 examined optimal presentation rate for the tactile symbols without compromising learning and recognition rate.\n",
      "396\n",
      "Pocket Skills: A Conversational Mobile Web App To Support Dialectical Behavioral Therapy\n",
      "Mental health disorders are a leading cause of disability worldwide. Although evidence-based psychotherapy is effective, engagement from such programs can be low. Mobile apps have the potential to help engage and support people in their therapy. We developed Pocket Skills, a mobile web app based on Dialectical Behavior Therapy (DBT). Pocket Skills teaches DBT via a conversational agent modeled on Marsha Linehan, who developed DBT. We examined the feasibility of Pocket Skills in a 4-week field study with 73 individuals enrolled in psychotherapy. After the study, participants reported decreased depression and anxiety and increased DBT skills use. We present a model based on qualitative findings of how Pocket Skills supported DBT. Pocket Skills helped participants engage in their DBT and practice and implement skills in their environmental context, which enabled them to see the results of using their DBT skills and increase their self-efficacy. We discuss the design implications of these findings for future mobile mental health systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n",
      "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making\n",
      "Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions-like taxation, justice, and child protection-are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and 'discrimination-aware' machine learning-absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the 'street-level bureaucrats' on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.\n",
      "480\n",
      "The Dream is Collapsing: The Experience of Exiting VR\n",
      "Research on virtual reality (VR) has studied users' experience of immersion, presence, simulator sickness, and learning effects. However, the momentary experience of exiting VR and transitioning back to the real-world is not well understood. Do users become self-conscious of their actions upon exit? Are users nervous of their surroundings? Using explicitation interviews, we explore the moment of exit from VR across four applications. Analysis of the interviews reveals five components of experience: space, control, sociality, time, and sensory adaptation. Participants described spatial disorientation, for example, regardless of the complexity of the VR scene. Participants also described a window across which they exit VR, for example mentally first and then physically. We present six designs for easing or heightening the exit experience, as described by the participants. Based on these findings, we further discuss the ?moment of exit' as an opportunity for designing engaging and enhanced VR experiences.\n",
      "531\n",
      "The Dark (Patterns) Side of UX Design\n",
      "Interest in critical scholarship that engages with the complexity of user experience (UX) practice is rapidly expanding, yet the vocabulary for describing and assessing criticality in practice is currently lacking. In this paper, we outline and explore the limits of a specific ethical phenomenon known as \"dark patterns,\" where user value is supplanted in favor of shareholder value. We assembled a corpus of examples of practitioner-identified dark patterns and performed a content analysis to determine the ethical concerns contained in these examples. This analysis revealed a wide range of ethical issues raised by practitioners that were frequently conflated under the umbrella term of dark patterns, while also underscoring a shared concern that UX designers could easily become complicit in manipulative or unreasonably persuasive practices. We conclude with implications for the education and practice of UX designers, and a proposal for broadening research on the ethics of user experience.\n",
      "552\n",
      "Collaborative Live Media Curation: Shared Context for Participation in Online Learning\n",
      "In recent years, online education's reach and scale have increased through new platforms for large and small online courses. However, these platforms often rely on impoverished modalities, which provide limited support for participation in social learning experiences. We present Collaborative Live Media Curation (CLMC), a new medium for sharing context and participation in online learning. CLMC involves collaborative, synchronous collection, creation, and assemblage of web media, including images, text, video, and sketch. CLMC integrates live media including streaming video, screenshares, audio, and text chat. We deploy and study LiveMâché, a CLMC technology probe, in four situated online learning contexts. We discovered student and instructor strategies for sharing context and participating including creating curations in advance, sketching to illustrate and gesture, real-time transformations, sharing perspective, and assembling live streams. We develop implications through live experience patterns, which describe how spatial and computing structures support social activities.\n",
      "581\n",
      "In a New Land: Mobile Phones, Amplified Pressures and Reduced Capabilities\n",
      "Framed within the theoretical lens of positive and negative security, this paper presents a study of newcomers to Sweden and the roles of mobile phones in the establishment of a new life. Using creative engagement methods through a series of workshops, two researchers engaged 70 adult participants enrolled into further education colleges in Sweden. Group narratives about mobile phone use were captured in creative outputs, researcher observations and notes and were analysed using thematic analysis. Key findings show that the mobile phone offers security for individuals and a safe space for newcomers to establish a new life in a new land as well as capitalising on other spaces of safety, such as maintaining old ties. This usage produces a series of threats and vulnerabilities beyond traditional technological security thinking related to mobile phone use. The paper concludes with recommendations for policies and support strategies for those working with newcomers.\n",
      "626\n",
      "Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: a Participatory Design Approach\n",
      "Current low-tech Orientation & Mobility (O&M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.\n",
      "653\n",
      "A Qualitative Exploration of Perceptions of Algorithmic Fairness\n",
      "Algorithmic systems increasingly shape information people are exposed to as well as influence decisions about employment, finances, and other opportunities. In some cases, algorithmic systems may be more or less favorable to certain groups or individuals, sparking substantial discussion of algorithmic fairness in public policy circles, academia, and the press. We broaden this discussion by exploring how members of potentially affected communities feel about algorithmic fairness. We conducted workshops and interviews with 44 participants from several populations traditionally marginalized by categories of race or class in the United States. While the concept of algorithmic fairness was largely unfamiliar, learning about algorithmic (un)fairness elicited negative feelings that connect to current national discussions about racial injustice and economic inequality. In addition to their concerns about potential harms to themselves and society, participants also indicated that algorithmic fairness (or lack thereof) could substantially affect their trust in a company or product.\n",
      "2010\n",
      "15\n",
      "Student socialization in the age of facebook\n",
      "Most research regarding online social networks such as Facebook, MySpace, Linked-In and Friendster has looked at these networks in terms of activity within the online network, such as profile management and friending behavior. In this paper we are instead focusing on offline socializing structures around an online social network (exemplified by Facebook) and how this can facilitate in-person social life for students. Because students lead nomadic lives, they find Facebook a particularly useful tool for initiating and managing social gatherings, and as they adopt mobile technologies that can access online social networks, their ad-hoc social life is further enabled. We conclude that online social networks are a powerful tool for encouraging peripheral friendships, important in particular to students. We emphasize that the use of online social networks must be viewed from a perspective of use that involves both mobile and stationary platforms and that it is important to relate online and offline social practices.\n",
      "21\n",
      "Blowing in the wind: unanchored patient information work during cancer care\n",
      "Patients do considerable information work. Technologies that help patients manage health information so they can play active roles in their health-care, such as personal health records, provide patients with effective support for focused and sustained personal health tasks. Yet, little attention has been paid to patients' needs for information management support while on the go and away from their personal health information collections. Through a qualitative field study, we investigated the information work that breast cancer patients do in such 'unanchored settings'. We report on the types of unanchored information work that patients do over the course of cancer treatment, reasons this work is challenging, and strategies used by patients to overcome those challenges. Our description of unanchored patient information work expands our understanding of patients' information practices and points to valuable design directions for supporting critical but unmet needs.\n",
      "80\n",
      "Avaaj Otalo: a field study of an interactive voice forum for small farmers in rural India\n",
      "In this paper we present the results of a field study of Avaaj Otalo (literally, \"voice stoop\"), an interactive voice application for small-scale farmers in Gujarat, India. Through usage data and interviews, we describe how 51 farmers used the system over a seven month pilot deployment. The most popular feature of Avaaj Otalo was a forum for asking questions and browsing others' questions and responses on a range of agricultural topics. The forum developed into a lively social space with the emergence of norms, persistent moderation, and a desire for both structured interaction with institutionally sanctioned authorities and open discussion with peers. For all 51 users this was the first experience participating in an online community of any sort. In terms of usability, simple menu-based navigation was readily learned, with users preferring numeric input over speech. We conclude by discussing implications of our findings for designing voice-based social media serving rural communities in India and elsewhere.\n",
      "81\n",
      "An exploratory study of unsupervised mobile learning in rural India\n",
      "Cellphones have the potential to improve education for the millions of underprivileged users in the developing world. However, mobile learning in developing countries remains under-studied. In this paper, we argue that cellphones are a perfect vehicle for making educational opportunities accessible to rural children in places and times that are more convenient than formal schooling. We carried out participant observations to identify the opportunities in their everyday lives for mobile learning. We next conducted a 26-week study to investigate the extent to which rural children will voluntarily make use of cellphones to access educational content. Our results show a reasonable level of academic learning and motivation. We also report on the social context around these results. Our goal is to examine the feasibility of mobile learning in out-of-school settings in rural, underdeveloped areas, and to help more researchers learn how to undertake similarly difficult studies around mobile computing in the developing world.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "pCubee: a perspective-corrected handheld cubic display\n",
      "In this paper, we describe the design of a personal cubic display that offers novel interaction techniques for static and dynamic 3D content. We extended one-screen Fish Tank VR by arranging five small LCD panels into a box shape that is light and compact enough to be handheld. The display uses head-coupled perspective rendering and a real-time physics simulation engine to establish an interaction metaphor of having real objects inside a physical box that a user can hold and manipulate. We evaluated our prototype as a visualization tool and as an input device by comparing it with a conventional LCD display and mouse for a 3D tree-tracing task. We found that bimanual interaction with pCubee and a mouse offered the best performance and was most preferred by users. pCubee has potential in 3D visualization and interactive applications such as games, storytelling and education, as well as viewing 3D maps, medical and architectural data.\n",
      "178\n",
      "Standardizing privacy notices: an online study of the nutrition label approach\n",
      "Earlier work has shown that consumers cannot effectively find information in privacy policies and that they do not enjoy using them. In our previous research we developed a standardized table format for privacy policies. We compared this standardized format, and two short variants (one tabular, one text) with the current status quo: full text natural-language policies and layered policies. We conducted an online user study of 764 participants to test if these three more-intentionally designed, standardized privacy policy formats, assisted by consumer education, can benefit consumers. Our results show that standardized privacy policy presentations can have significant positive effects on accuracy and speed of information finding and on reader enjoyment of privacy policies.\n",
      "182\n",
      "Expressive robots in education: varying the degree of social supportive behavior of a robotic tutor\n",
      "Teaching is inherently a social interaction between teacher and student. Despite this knowledge, many educational tools, such as vocabulary training programs, still model the interaction in a tutoring scenario as unidirectional knowledge transfer rather than a social dialog. Therefore, ongoing research aims to develop virtual agents as more appropriate media in education. Virtual agents can induce the perception of a life-like social interaction partner that communicates through natural modalities such as speech, gestures and emotional expressions. This effect can be additionally enhanced with a physical robotic embodiment. This paper presents the development of social supportive behaviors for a robotic tutor to be used in a language learning application. The effect of these behaviors on the learning performance of students was evaluated. The results support that employing social supportive behavior increases learning efficiency of students.\n",
      "210\n",
      "UpStream: motivating water conservation with low-cost water flow sensing and persuasive displays\n",
      "Water is our most precious and most rapidly declining natural resource. We explore pervasive technology as an approach for promoting water conservation in public and private spaces. We hope to motivate immediate reduction in water use as well as higher-order behaviors (seeking new information, etc) through unobtrusive low-cost water flow sensing and several persuasive displays. Early prototypes were installed at public faucets and a private (shared) shower, logging water usage first without and then with ambient displays. This pilot study led to design iterations, culminating in long-term deployment of sensors in four private showers over the course of three weeks. Sensors first logged baseline water usage without visualization. Then, two display styles, ambient and numeric, were deployed in random order, each showing individual and average water consumption. Quantitative data along with participants' feedback contrast the effectiveness of numeric displays against abstract visualization in this very important domain of water conservation and public health.\n",
      "215\n",
      "Mobile-izing health workers in rural India\n",
      "Researchers have long been interested in the potential of ICTs to enable positive change in developing regions communities. In these environments, ICT interventions often fail because political, social and cultural forces work against the changes ICTs entail. We argue that familiar uses of ICTs for information services in these contexts are less potent than their use for persuasion and motivation in order to facilitate change. We focus on India's rural maternal health system where health workers are employed in villages to persuade pregnant women to utilize health services. Health workers face challenges due to resistance to change in the village, and because of their limited education, training and status. These factors appear to reduce the motivation of health workers and impair their performance. For two months, we deployed short videos on mobile phones designed to persuade village women and motivate health workers. We also asked health workers to record their own videos. While our results are preliminary, they show evidence that the creation and use of videos did help (1) engage village women in dialogue, (2) show positive effects toward health worker motivation and learning, and (3) motivate key community influencers to participate in promoting the health workers.\n",
      "217\n",
      "Social network activity and social well-being\n",
      "Previous research has shown a relationship between use of social networking sites and feelings of social capital. However, most studies have relied on self-reports by college students. The goals of the current study are to (1) validate the common self-report scale using empirical data from Facebook, (2) test whether previous findings generalize to older and international populations, and (3) delve into the specific activities linked to feelings of social capital and loneliness. In particular, we investigate the role of directed interaction between pairs---such as wall posts, comments, and \"likes\" --- and consumption of friends' content, including status updates, photos, and friends' conversations with other friends. We find that directed communication is associated with greater feelings of bonding social capital and lower loneliness, but has only a modest relationship with bridging social capital, which is primarily related to overall friend network size. Surprisingly, users who consume greater levels of content report reduced bridging and bonding social capital and increased loneliness. Implications for designs to support well-being are discussed.\n",
      "229\n",
      "The design of eco-feedback technology\n",
      "Eco-feedback technology provides feedback on individual or group behaviors with a goal of reducing environmental impact. The history of eco-feedback extends back more than 40 years to the origins of environmental psychology. Despite its stated purpose, few HCI eco-feedback studies have attempted to measure behavior change. This leads to two overarching questions: (1) what can HCI learn from environmental psychology and (2) what role should HCI have in designing and evaluating eco-feedback technology? To help answer these questions, this paper conducts a comparative survey of eco-feedback technology, including 89 papers from environmental psychology and 44 papers from the HCI and UbiComp literature. We also provide an overview of predominant models of proenvironmental behaviors and a summary of key motivation techniques to promote this behavior.\n",
      "244\n",
      "Towards customizable games for stroke rehabilitation\n",
      "Stroke is the leading cause of long term disability among adults in industrialized nations. The partial paralysis that stroke patients often experience can make independent living difficult or impossible. Research suggests that many of these patients could recover by performing hundreds of daily repetitions of motions with their affected limbs. Yet, only 31% of patients perform the exercises recommended by their therapists. Home-based stroke rehabilitation games may help motivate stroke patients to perform the necessary exercises to recover. In this paper, we describe a formative study in which we designed and user tested stroke rehabilitation games with both stroke patients and therapists. We describe the lessons we learned about what makes games useful from a therapeutic point of view.\n",
      "245\n",
      "Designing patient-centric information displays for hospitals\n",
      "Electronic medical records are increasingly comprehensive, and this vast repository of information has already contri-buted to medical efficiency and hospital procedure. However, this information is not typically accessible to patients, who are frequently under-informed and unclear about their own hospital courses. In this paper, we propose a design for in-room, patient-centric information displays, based on iterative design with physicians. We use this as the basis for a Wizard-of-Oz study in an emergency department, to assess patient and provider responses to in-room information displays. 18 patients were presented with real-time information displays based on their medical records. Semi-structured interviews with patients, family members, and hospital staff reveal that subjective response to in-room displays was overwhelmingly positive, and through these interviews we elicited guidelines regarding specific information types, privacy, use cases, and information presentation techniques. We describe these findings, and we discuss the feasibility of a fully-automatic implementation of our design.\n",
      "272\n",
      "Powerful and consistent analysis of likert-type ratingscales\n",
      "Likert-type scales are used extensively during usability evaluations, and more generally evaluations of interactive experiences, to obtain quantified data regarding attitudes, behaviors, and judgments of participants. Very often this data is analyzed using parametric statistics like the Student t-test or ANOVAs. These methods are chosen to ensure higher statistical power of the test (which is necessary in this field of research and practice where sample sizes are often small), or because of the lack of software to handle multi-factorial designs nonparametrically. With this paper we present to the HCI audience new developments from the field of medical statistics that enable analyzing multiple factor designs nonparametrically. We demonstrate the necessity of this approach by showing the errors in the parametric treatment of nonparametric data in experiments of the size typically reported in HCI research. We also provide a practical resource for researchers and practitioners who wish to use these new methods.\n",
      "274\n",
      "Are your participants gaming the system?: screening mechanical turk workers\n",
      "In this paper we discuss a screening process used in conjunction with a survey administered via Amazon.com's Mechanical Turk. We sought an easily implementable method to disqualify those people who participate but don't take the study tasks seriously. By using two previously pilot tested screening questions, we identified 764 of 1,962 people who did not answer conscientiously. Young men seem to be most likely to fail the qualification task. Those that are professionals, students, and non-workers seem to be more likely to take the task seriously than financial workers, hourly workers, and other workers. Men over 30 and women were more likely to answer seriously.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "After access: challenges facing mobile-only internet users in the developing world\n",
      "This study reports results of an ethnographic action research study, exploring mobile-centric internet use. Over the course of 13 weeks, eight women, each a member of a livelihoods collective in urban Cape Town, South Africa, received training to make use of the data (internet) features on the phones they already owned. None of the women had previous exposure to PCs or the internet. Activities focused on social networking, entertainment, information search, and, in particular, job searches. Results of the exercise reveal both the promise of, and barriers to, mobile internet use by a potentially large community of first-time, mobile-centric users. Discussion focuses on the importance of self-expression and identity management in the refinement of online and offline presences, and considers these forces relative to issues of gender and socioeconomic status.\n",
      "2005\n",
      "20\n",
      "AppLens and launchTile: two designs for one-handed thumb use on small devices\n",
      "We present two interfaces to support one-handed thumb use for PDAs and cell phones. Both use Scalable User Interface (ScUI) techniques to support multiple devices with different resolutions and aspect ratios. The designs use variations of zooming interface techniques to provide multiple views of application data: AppLens uses tabular fisheye to access nine applications, while LaunchTile uses pure zoom to access thirty-six applications. We introduce two sets of thumb gestures, each representing different philosophies for one-handed interaction. We conducted two studies to evaluate our designs. In the first study, we explored whether users could learn and execute the AppLens gesture set with minimal training. Participants performed more accurately and efficiently using gestures for directional navigation than using gestures for object interaction. In the second study, we gathered user reactions to each interface, as well as comparative preferences. With minimal exposure to each design, most users favored AppLens's tabular fisheye interface.\n",
      "53\n",
      "Livenotes: a system for cooperative and augmented note-taking in lectures\n",
      "We describe Livenotes, a shared whiteboard system and educational practice that uses wireless communication and tablet computing to support real-time conversations within small groups of students during lectures, independent of class size. We present an interface design that enables group members to interact with one another by taking lecture notes cooperatively, as well as to augment student note-taking by providing instructor slides in the background to annotate over. Livenotes was designed to facilitate more efficient, stimulating modes of learning that other collaborative approaches do not. We report how the system impacts cooperative learning in an undergraduate class and how students interacted with background slides in the workspace. We conclude with directions for improving the system and learning practice.\n",
      "54\n",
      "Stencils-based tutorials: design and evaluation\n",
      "Users of traditional tutorials and help systems often have difficulty finding the components described or pictured in the procedural instructions. Users also unintentionally miss steps, and perform actions that the documentation's authors did not intend, moving the application into an unknown state. We introduce Stencils, an interaction technique for presenting tutorials that uses translucent colored stencils containing holes that direct the user's attention to the correct interface component and prevent the user from interacting with other components. Sticky notes on the stencil's surface provide necessary tutorial material in the context of the application. In a user study comparing a Stencils-based and paper-based version of the same tutorial in Alice, a complex software application designed to teach introductory computer programming, we found that users of a Stencils-based tutorial were able complete the tutorial 26% faster, with fewer errors, and less reliance on human assistance. Users of the Stencils-based and paper-based tutorials attained statistically similar levels of learning.\n",
      "86\n",
      "Extending tangible interfaces for education: digital montessori-inspired manipulatives\n",
      "This paper introduces a new framework for thinking about tangible interfaces in education, with specific focus on abstract problem domains.Manipulatives are physical objects specifically designed to foster learning. We offer a new classification of Manipulatives: \"Froebel-inspired Manipulatives\" (FiMs) and \"Montessori-inspired Manipulatives\" (MiMs). We argue that FiMs are design materials, fostering modeling of real-world structures, while MiMs foster modeling of more abstract structures. We show that our classification extends to computationally enhanced versions of manipulatives.We present Digital MiMs - computationally enhanced building blocks. We describe two prototypical members of the Digital MiMs class: FlowBlocks and SystemBlocks, physical, modular interactive systems that serve as general-purpose modeling and simulation tools for dynamic behavior. We present findings from qualitative studies, and conclude that digital MiMs are accessible to young children, engaging, and encourage learning of abstract structures of dynamic behavior through an iterative process of hands-on modeling, simulating, and analogizing.\n",
      "87\n",
      "Effectiveness of end-user debugging software features: are there gender issues?\n",
      "Although gender differences in a technological world are receiving significant research attention, much of the research and practice has aimed at how society and education can impact the successes and retention of female computer science professionals-but the possibility of gender issues within software has received almost no attention. If gender issues exist with some types of software features, it is possible that accommodating them by changing these features can increase effectiveness, but only if we know what these issues are. In this paper, we empirically investigate gender differences for end users in the context of debugging spreadsheets. Our results uncover significant gender differences in self-efficacy and feature acceptance, with females exhibiting lower self-efficacy and lower feature acceptance. The results also show that these differences can significantly reduce females' effectiveness.\n",
      "2004\n",
      "48\n",
      "Off-task behavior in the cognitive tutor classroom: when students \"game the system\"\n",
      "We investigate the prevalence and learning impact of different types of off-task behavior in classrooms where students are using intelligent tutoring software. We find that within the classrooms studied, no other type of off-task behavior is associated nearly so strongly with reduced learning as \"gaming the system\": behavior aimed at obtaining correct answers and advancing within the tutoring curriculum by systematically taking advantage of regularities in the software's feedback and help. A student's frequency of gaming the system correlates as strongly to post-test score as the student's prior domain knowledge and general academic achievement. Controlling for prior domain knowledge, students who frequently game the system score substantially lower on a post-test than students who never game the system. Analysis of students who choose to game the system suggests that learned helplessness or performance orientation might be better accounts for why students choose this behavior than lack of interest in the material. This analysis will inform the future re-design of tutors to respond appropriately when students game the system.\n",
      "60\n",
      "Putting the users center stage: role playing and low-fi prototyping enable end users to design mobile systems\n",
      "This paper sums up lessons learned from a sequence of cooperative design workshops where end users were enabled to design mobile systems through scenario building, role playing, and low-fidelity prototyping. We present a resulting fixed workshop structure with well-chosen constraints that allows for end users to explore and design new technology and work practices. In these workshops, the systems developers get input to design from observing how users stage and act out current and future use scenarios and improvise new technology to fit their needs. A theoretical framework is presented to explain the creative processes involved and the workshop as a user-centered design method. Our findings encourage us to recommend the presented workshop structure for design projects involving mobility and computer-mediated communication, in particular project where the future use of the resulting products and services also needs to be designed.\n",
      "81\n",
      "Topobo: a constructive assembly system with kinetic memory\n",
      "We introduce Topobo, a 3D constructive assembly system embedded with kinetic memory, the ability to record and playback physical motion. Unique among modeling systems is Topobo's coincident physical input and output behaviors. By snapping together a combination of Passive (static) and Active (motorized) components, people can quickly assemble dynamic biomorphic forms like animals and skeletons with Topobo,animate those forms by pushing, pulling, and twisting them, and observe the system repeatedly play back those motions. For example, a dog can be constructed and then taught to gesture and walk by twisting its body and legs. The dog will then repeat those movements and walk repeatedly.Our evaluation of Topobo in classrooms with children ages 5-13 suggests that children develop affective relationships with Topobo creations and that their experimentation with Topobo allows them to learn about movement and animal locomotion through comparisons of their creations to their own bodies. Eighth grade science students' abilities to quickly develop various types of walking robots suggests that a tangible interface can support understanding how balance, leverage and gravity affect moving structures because the interface itself responds to the forces of nature that constrain such systems.\n",
      "84\n",
      "Twiddler typing: one-handed chording text entry for mobile phones\n",
      "An experienced user of the Twiddler, a one--handed chording keyboard, averages speeds of 60 words per minute with letter--by--letter typing of standard test phrases. This fast typing rate coupled with the Twiddler's 3x4 button design, similar to that of a standard mobile telephone, makes it a potential alternative to multi--tap for text entry on mobile phones. Despite this similarity, there is very little data on the Twiddler's performance and learnability. We present a longitudinal study of novice users' learning rates on the Twiddler. Ten participants typed for 20 sessions using two different methods. Each session is composed of 20 minutes of typing with multi--tap and 20 minutes of one--handed chording on the Twiddler. We found that users initially have a faster average typing rate with multi--tap; however, after four sessions the difference becomes negligible, and by the eighth session participants type faster with chording on the Twiddler. Furthermore, after 20 sessions typing rates for the Twiddler are still increasing.\n",
      "1996\n",
      "Talk and embodiment in collaborative virtual environments\n",
      "An abstract is not available.\n",
      "7\n",
      "Multimodal interfaces for dynamic interactive maps\n",
      "An abstract is not available.\n",
      "12\n",
      "The WebBook and the Web Forager: an information workspace for the World-Wide Web\n",
      "An abstract is not available.\n",
      "14\n",
      "Silk from a sow's ear: extracting usable structures from the Web\n",
      "An abstract is not available.\n",
      "15\n",
      "Wayfinding strategies and behaviors in large virtual worlds\n",
      "An abstract is not available.\n",
      "18\n",
      "A case for interaction: a study of interactive information retrieval behavior and effectiveness\n",
      "An abstract is not available.\n",
      "26\n",
      "Scatter/gather browsing communicates the topic structure of a very large text collection\n",
      "An abstract is not available.\n",
      "27\n",
      "LifeLines: visualizing personal histories\n",
      "An abstract is not available.\n",
      "28\n",
      "Remote evaluation: the network as an extension of the usability laboratory\n",
      "An abstract is not available.\n",
      "29\n",
      "Email overload: exploring personal information management of email\n",
      "An abstract is not available.\n",
      "35\n",
      "The influence of muscle groups on performance of multiple degree-of-freedom input\n",
      "An abstract is not available.\n",
      "39\n",
      "2001\n",
      "3\n",
      "Listen reader: an electronically augmented paper-based book\n",
      "While predictions abound that electronic books will supplant traditional paper-based books, many people bemoan the coming loss of the book as cultural artifact. In this project we deliberately keep the affordances of paper books while adding electronic augmentation. The Listen Reader combines the look and feel of a real book - a beautiful binding, paper pages and printed images and text - with the rich, evocative quality of a movie soundtrack. The book's multi-layered interactive soundtrack consists of music and sound effects. Electric field sensors located in the book binding sense the proximity of the reader's hands and control audio parameters, while RFID tags embedded in each page allow fast, robust page identification.Three different Listen Readers were built as part of a six-month museum exhibit, with more than 350,000 visitors. This paper discusses design, implementation, and lessons learned through the iterative design process, observation, and visitor interviews.\n",
      "7\n",
      "Empirically validated web page design metrics\n",
      "A quantitative analysis of a large collection of expert-rated web sites reveals that page-level metrics can accurately predict if a site will be highly rated. The analysis also provides empirical evidence that important metrics, including page composition, page formatting, and overall page characteristics, differ among web site categories such as education, community, living, and finance. These results provide an empirical foundation for web site design guidelines and also suggest which metrics can be most important for evaluation via user studies.\n",
      "25\n",
      "Does organisation by similarity assist image browsing?\n",
      "In current systems for browsing image collections, users are presented with sets of thumbnail images arranged in some default order on the screen. We are investigating whether it benefits users to have sets of thumbnails arranged according to their mutual similarity, so images that are alike are placed together. There are, of course, many possible definitions of “similarity”: so far we have explored measurements based on low-level visual features, and on the textual captions assigned to the images. Here we describe two experiments, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task. Firstly, the two types of similarity-based arrangement were informally compared. Then, an arrangement based on visual similarity was more formally compared with a control of a random arrangement. We believe this work should be of interest to anyone designing a system that involves presenting sets of images to users.\n",
      "32\n",
      "Locus of feedback control in computer-based tutoring: impact on learning rate, achievement and attitudes\n",
      "The advent of second-generation intelligent computer tutors raises an important instructional design question: when should tutorial advice be presented in problem solving? This paper examines four feedback conditions in the ACT Programming Tutor. Three versions offer the student different levels of control over error feedback and correction: (a) immediate feedback and immediate error correction; (b) immediate error flagging and student control of error correction; (c) feedback on demand and student control of error correction. A fourth, No-tutor condition offers no stepby-step problem solving support. The immediate feedback group with greatest tutor control of problem solving yielded the most efficient learning. These students completed the tutor problems fastest, and the three tutor-supported groups performed equivalently on tests. Questionnaires revealed little student preference among the four conditions. These results suggest that students will need explicit guidance to benefit from learning opportunities that arise when they have greater control over tutorial assistance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "15\n",
      "Airport Accessibility and Navigation Assistance for People with Visual Impairments\n",
      "\" People with visual impairments often have to rely on the assistance of sighted guides in airports, which prevents them from having an independent travel experience. In order to learn about their perspectives on current airport accessibility, we conducted two focus groups that discussed their needs and experiences in-depth, as well as the potential role of assistive technologies. We found that independent navigation is a main challenge and severely impacts their overall experience. As a result, we equipped an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed a real-world study where users navigated routes relevant for their travel experience. We found that despite the challenging environment participants were able to complete their itinerary independently, presenting none to few navigation errors and reasonable timings. This study presents the first systematic evaluation posing BLE technology as a strong approach to increase the independence of visually impaired people in airports.\n",
      "461\n",
      "Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild\n",
      "\" As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses' frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day.\n",
      "597\n",
      "Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?\n",
      "The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs.\n",
      "2017\n",
      "9\n",
      ": The Effects of Curriculum-Aligned Making on Children's Self-Identity\n",
      "Prior research investigating the effects of incorporating Making into educational contexts has been limited to snapshot studies. These studies however do not allow for the investigation of aspects that require longer-term development and nurture. We present a longitudinal study that investigates the effects of Making on children's degree of science self-efficacy, identity formation as possible scientists and engineers, and academic performance in science. Designed interactions with Making technology were integrated into the science curriculum of elementary school classrooms in a public school with a high proportion of students from minority populations for a year. Results showed significant differences between the \"Making classrooms\" and the control classrooms, and from pre- to post-test on the students' inclination towards science. The results support the promise and potential of incorporating Making into formal schooling on the growth and long-term attitudes of children towards science and STEM in general.\n",
      "24\n",
      "UX Design Innovation: Challenges for Working with Machine Learning as a Design Material\n",
      "Machine learning (ML) is now a fairly established technology, and user experience (UX) designers appear regularly to integrate ML services in new apps, devices, and systems. Interestingly, this technology has not experienced a wealth of design innovation that other technologies have, and this might be because it is a new and difficult design material. To better understand why we have witnessed little design innovation, we conducted a survey of current UX practitioners with regards to how new ML services are envisioned and developed in UX practice. Our survey probed on how ML may or may not have been a part of their UX design education, on how they work to create new things with developers, and on the challenges they have faced working with this material. We use the findings from this survey and our review of related literature to present a series of challenges for UX and interaction design research and education. Finally, we discuss areas where new research and new curriculum might help our community unlock the power of design thinking to re-imagine what ML might be and might do.\n",
      "55\n",
      "Self-tracking for Mental Wellness: Understanding Expert Perspectives and Student Experiences\n",
      "Previous research suggests an important role for self-tracking in promoting mental wellness. Recent studies with college student populations have examined the feasibility of collecting everyday mood, activity, and social data. However, these studies do not account for students' experiences and challenges adopting self-tracking technologies to support mental wellness goals. We present two studies conducted to better understand self-tracking for stress management and mental wellness in student populations. First, focus groups and card sorting activities with 14 student health professionals reveal expert perspectives on the usefulness of tracking for three scenarios. Second, an online survey of 297 students examines personal experiences with self-tracking and attitudes toward sharing self-tracked data with others. We draw on findings from these studies to characterize students' motivations, challenges and preferences in collecting and viewing self-tracked data related to mental wellness, and we compare findings between students with diagnosed mental illnesses and those without. We conclude with a discussion of challenges and opportunities in leveraging self-tracking for mental wellness, highlighting several design considerations.\n",
      "117\n",
      "Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data\n",
      "Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support learning. We present multiple graphically-based techniques for eliciting and incorporating a user's prior knowledge about data into visualization interaction. We use controlled experiments to evaluate how graphically eliciting forms of prior knowledge and presenting feedback on the gap between prior knowledge and the observed data impacts a user's ability to recall and understand the data. We find that participants who are prompted to reflect on their prior knowledge by predicting and self-explaining data outperform a control group in recall and comprehension. These effects persist when participants have moderate or little prior knowledge on the datasets. We discuss how the effects differ based on text versus visual presentations of data. We characterize the design space of graphical prediction and feedback techniques and describe design recommendations.\n",
      "140\n",
      "A Social Media Based Index of Mental Well-Being in College Campuses\n",
      "Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multi-campus data on mental well-being presents significant challenges to intervention and mitigation efforts in college campuses. We examine the potential of social media as a new \"barometer\" for quantifying the mental well-being of college populations. Utilizing student-contributed data in Reddit communities of over 100 universities, we first build and evaluate a transfer learning based classification approach that can detect mental health expressions with 97% accuracy. Thereafter, we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI is able to reveal meaningful temporal patterns of mental well-being in campuses, and to assess how their expressions relate to university attributes like size, academic prestige, and student demographics. We discuss the implications of our work for improving counselor efforts, and in the design of tools that can enable better assessment of the mental health climate of college campuses.\n",
      "154\n",
      "Why Tangibility Matters: A Design Case Study of At-Risk Children Learning to Read and Spell\n",
      "Tangibles may be effective for reading applications. Letters can be represented as 3D physical objects. Words are spatially organized collections of letters. We explore how tangibility impacts reading and spelling acquisition for young Anglophone children who have dyslexia. We describe our theory-based design rationale and present a mixed-methods case study of eight children using our PhonoBlocks system. All children made significant gains in reading and spelling on trained and untrained (new) words, and could apply all spelling rules a month later. We discuss the design features of our system that contributed to effective learning processes, resulting in successful learning outcomes: dynamic colour cues embedded in 3D letters, which can draw attention to how letter(s) position changes their sounds; and the form of 3D tangible letters, which can enforce correct letter orientation and enable epistemic strategies in letter organization that simplify spelling tasks. We conclude with design guidelines for tangible reading systems.\n",
      "158\n",
      "Respeak: A Voice-based, Crowd-powered Speech Transcription System\n",
      "Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present Respeak - a voice-based, crowd-powered system that capitalizes on the strengths of crowdsourcing and automatic speech recognition (instead of typing) to transcribe such audio files. We created Respeak and optimized its design through a series of cognitive experiments. We deployed it with 25 university students in India who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied audio content, and collectively earning USD 46 as mobile airtime. The Respeak engine aligned the transcript generated by five randomly selected users to transcribe Hindi and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively. The cost of speech transcription was USD 0.83 per minute with a turnaround time of 39.8 hours, substantially less than industry standards. Using a mixed-methods analysis of cognitive experiments, system performance and qualitative interviews, we evaluate Respeak's design, user experience, strengths, and weaknesses. Our findings suggest that Respeak improves the quality of speech transcription while enhancing the earning potential of low-income populations in resource-constrained settings.\n",
      "200\n",
      "Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets\n",
      "Crowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating detailed label guidelines by harnessing crowd disagreements to identify ambiguous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments comparing Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt's ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt's collaborative and non-collaborative variants show that collaboration reaches higher label accuracy with lower monetary cost.\n",
      "205\n",
      "Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop\n",
      "Although we may complain about meetings, they are an essential part of an information worker's work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant executing an unstructured macrotask. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.\n",
      "214\n",
      "Five Lenses for Designing Exertion Experiences\n",
      "The field of HCI has increasingly looked at ways to support the physically active human being, however, new work suggests that the field has only begun to understand the many virtues of exertion. To further the field, we present a set of five design lenses extended primarily from sports philosophy literature to help approach exertion not just as a means of deferring death, but also as an opportunity for personal growth. The lenses facilitate learning how to appreciate a void (Reverie), welcome pleasure (Pleasure), become humble (Humility), as well as be fearful and excited simultaneously (Sublime), whilst being more carefully aware of one's own body (Oneness). Using these lenses, we articulate associated technology opportunities through related work as well as our own craft knowledge. With our work, we aim to support designers who want to facilitate the many virtues of exertion so that ultimately more people profit from the many benefits of being physically active.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "Sidestepping the Elephant in the Classroom: Using Culturally Localized Technology To Teach Around Taboos\n",
      "Cultural taboos can restrict student learning on topics of critical importance. In India, such taboos have led multiple states to ban materials intended to educate youth about HIV, putting millions at risk. We present the design of TeachAIDS, a software application that leverages cultural insights, learning science, and affordances of technology to provide comprehensive HIV education while circumventing taboos. Using a mixed-methods evaluation, we demonstrate that this software leaves students with significantly increased knowledge about HIV and reduced stigma toward individuals infected with the virus. Validating the effectiveness of TeachAIDS in circumventing taboos, students report comfort in learning from the software, and it has since been deployed in tens of thousands of schools throughout India. The methodology presented here has broader implications for the design and implementation of interactive technologies for providing education on sensitive topics in health and other areas.\n",
      "246\n",
      "ProCom: Designing and Evaluating a Mobile and Wearable System to Support Proximity Awareness for People with Autism\n",
      "People with autism are at risk for social isolation due to differences in their perception and engagement with the social world. In this work, we aim to address one specific concern related to socialization the understanding, awareness, and use of interpersonal space. Over the course of a year, we iteratively designed and tested a series of concepts for supporting children with autism in perceiving, understanding, and responding to physical proximity with other people. During this process, we developed ProCom, a prototype system for measuring proximity without requiring instrumentation of the environment or another person. We used a variety of low and high fidelity prototypes, culminating in ProCom, to assess the feasibility, utility, and challenges of this approach. The results of these iterative design engagements indicate that wearable assistive technologies can support people in developing awareness of physical proximity in social settings. However, challenges related to both personal and collective use remain\n",
      "247\n",
      "Smartphone-Based Gaze Gesture Communication for People with Motor Disabilities\n",
      "Current eye-tracking input systems for people with ALS or other motor impairments are expensive, not robust under sunlight, and require frequent re-calibration and substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech alternative, are challenging to master and offer slow communication rates. To mitigate the drawbacks of these two status quo approaches, we created GazeSpeak, an eye gesture communication system that runs on a smartphone, and is designed to be low-cost, robust, portable, and easy-to-learn, with a higher communication bandwidth than an e-tran board. GazeSpeak can interpret eye gestures in real time, decode these gestures into predicted utterances, and facilitate communication, with different user interfaces for speakers and interpreters. Our evaluations demonstrate that GazeSpeak is robust, has good user satisfaction, and provides a speed improvement with respect to an e-tran board; we also identify avenues for further improvement to low-cost, low-effort gaze-based communication technologies.\n",
      "276\n",
      "You Want Me to Work with \n",
      "Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based courses. An instructor uses the tool to form teams by surveying students' working styles, skills, and demographics; then configuring these criteria as input into an algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge their perceptions of the strengths and weaknesses of the tool and ideas for improving it. We also interviewed instructors (N=13) different from those who taught the eight courses to learn about their criteria selections and perceptions of the tool. Students valued the rational basis for forming teams but desired a stronger voice in criteria selection and explanations as to why they were assigned to a particular team. Instructors appreciated the efficiency of team formation but wanted to view exemplars of criteria used in similar courses. This work contributes recommendations for deploying team formation tools in educational settings and for better satisfying the goals of all stakeholders.\n",
      "313\n",
      "WireDraw: 3D Wire Sculpturing Guided with Mixed Reality\n",
      "The availability of commodity 3D extruder pen allows direct drawing of 3D wire sculptures for novice users, enabling many novel applications such as intuitive spatial intelligence development for school students. However, the lack of spatial and structural cues among individual pen strokes makes the 3D drawing process challenging, which often leads to highly distorted and even incomplete wire sculptures. We present a mixed reality system, called `WireDraw', to immersively guide the 3D drawing for easy wire sculpturing. The system design is based on novel 3D drawing principles and the subsequent optimization, making the stroke sequence of the wire model drawable and easy to draw. On-the-fly edits on unsatisfactory strokes are also allowed for creative design. We demonstrate the effectiveness of our system by testing on a variety of wire models and a user study. The results show that the visual guidance provided by our system is extremely helpful for drawing high-quality wire sculptures.\n",
      "331\n",
      "TriTap: Identifying Finger Touches on Smartwatches\n",
      "The small screens of smartwatches provide limited space for input tasks. Finger identification is a promising technique to address this problem by associating different functions with different fingers. However, current technologies for finger identification are unavailable or unsuitable for smartwatches. To address this problem, this paper observes that normal smartwatch use takes places with a relatively static pose between the two hands. In this situation, we argue that the touch and angle profiles generated by different fingers on a standard smartwatch touch screen will differ sufficiently to support reliable identification. The viability of this idea is explored in two studies that capture touches in natural and exaggerated poses during tapping and swiping tasks. Machine learning models report accuracies of up to 93% and 98% respectively, figures that are sufficient for many common interaction tasks. Furthermore, the exaggerated poses show modest costs (in terms of time/errors) compared to the natural touches. We conclude by presenting examples and discussing how interaction designs using finger identification can be adapted to the smartwatch form factor.\n",
      "379\n",
      "Online Feedback Exchange: A Framework for Understanding the Socio-Psychological Factors\n",
      "To meet the demand for authentic, timely, and affordable feedback, researchers have explored technologies to connect designers with feedback providers online. While researchers have implemented mechanisms to improve the content of feedback, most systems for online feedback exchange do not support an end-to-end cycle, from help-seeking to sense-making to action. Building on extant literature in learning sciences, design, organizational behavior, and online communities, we propose a conceptual framework to highlight critical processes that affect online feedback exchange. We contribute research questions for future feedback systems and argue that online feedback systems must be able to support designers through five activities that happen before, during, and after the feedback exchange. Our framework suggests that systems should address broader socio-psychological factors, such as how intent should be communicated online, how dialogue can support the interpretation of feedback, and how to balance the tradeoffs of anonymizing feedback providers.\n",
      "381\n",
      "Tap, Dwell or Gesture?: Exploring Head-Based Text Entry Techniques for HMDs\n",
      "Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the user controls a pointer on a virtual keyboard using head rotation. Specifically, we investigate three techniques: TapType, DwellType, and GestureType. Users of TapType select a letter by pointing to it and tapping a button. Users of DwellType select a letter by pointing to it and dwelling over it for a period of time. Users of GestureType perform word-level input using a gesture typing style. Two lab studies were conducted. In the first study, users typed 10.59 WPM, 15.58 WPM, and 19.04 WPM with DwellType, TapType, and GestureType, respectively. Users subjectively felt that all three of the techniques were easy to learn and considered the induced fatigue to be acceptable. In the second study, we further investigated GestureType. We improved its gesture-word recognition algorithm by incorporating the head movement pattern obtained from the first study. This resulted in users reaching 24.73 WPM after 60 minutes of training. Based on these results, we argue that head-based text entry is feasible and practical on HMDs, and deserves more attention.\n",
      "391\n",
      "Examining Crowd Work and Gig Work Through The Historical Lens of Piecework\n",
      "The internet is empowering the rise of crowd work, gig work, and other forms of on-demand labor. A large and growing body of scholarship has attempted to predict the socio-technical outcomes of this shift, especially addressing three questions: 1) What are the complexity limits of on-demand work?, 2) How far can work be decomposed into smaller microtasks?, and 3) What will work and the place of work look like for workers? In this paper, we look to the historical scholarship on piecework — a similar trend of work decomposition, distribution, and payment that was popular at the turn of the 20th century — to understand how these questions might play out with modern on-demand work. We identify the mechanisms that enabled and limited piecework historically, and identify whether on-demand work faces the same pitfalls or might differentiate itself. This approach introduces theoretical grounding that can help address some of the most persistent questions in crowd work, and suggests design interventions that learn from history rather than repeat it.\n",
      "413\n",
      "Teaching Programming with Gamified Semantics\n",
      "Dominant approaches to programming education emphasize program construction over language comprehension. We present Reduct, an educational game embodying a new, comprehension-first approach to teaching novices core programming concepts which include functions, Booleans, equality, conditionals, and mapping functions over sets. In this novel teaching strategy, the player executes code using reduction-based operational semantics. During gameplay, code representations fade from concrete, block-based graphics to the actual syntax of JavaScript ES2015. We describe our design rationale and report on the results of a study evaluating the efficacy of our approach on young adults (18+) without prior coding experience. In a short timeframe, novices demonstrated promising learning of core concepts expressed in actual JavaScript. We also present results from an online deployment. Finally, we discuss ramifications for the design of future computational thinking games.\n",
      "414\n",
      "Investigating the Suitability of the Asynchronous, Remote, Community-based Method for Pregnant and New Mothers\n",
      "Traditional qualitative research methods, such as, interviews and focus groups, may not be feasible for certain populations- who face time, mobility, and availability constraints. We adapted the Asynchronous, Remote, Community-based (ARC) method that used closed Facebook groups to study people with rare diseases, to study a different population - pregnant and new mothers. During the course of eight weeks, we engaged 48 participants in 19 study activities using three closed Facebook groups. We added new activities to the original ARC method, informed by past HCI research, to triangulate participant input. We carefully analyzed participation patterns and activity engagement, to assess the suitability of the ARC method for engaging pregnant and new mothers in remote, group-based, qualitative research. We provide an in-depth analysis of the ARC method, noting participation characteristics, activity preferences, and the suitability of the ARC method as an online focus group.\n",
      "419\n",
      "WAVES: A Wearable Asymmetric Vibration Excitation System for Presenting Three-Dimensional Translation and Rotation Cues\n",
      "WAVES, a Wearable Asymmetric Vibration Excitation System, is a novel wearable haptic device for presenting three dimensions of translation and rotation guidance cues. In contrast to traditional vibration feedback, which usually requires that users learn to interpret a binary cue, asymmetric vibrations have been shown to induce a pulling sensation in a desired direction. When attached to the fingers, a single voicecoil actuator presents a translation guidance cue and a pair of voicecoil actuators presents a rotation guidance cue. The directionality of mechanoreceptors in the skin led to our choice of the location and orientation of the actuators in order to elicit very strong sensations in certain directions. For example, users distinguished a \"left\" cue versus a \"right\" cue 94.5% of the time. When presented with one of six possible direction cues, users on average correctly identified the direction of translation cues 86.1% of the time and rotation cues 69.0% of the time.\n",
      "468\n",
      "Finding Similar People to Guide Life Choices: Challenge, Design, and Evaluation\n",
      "People often seek examples of similar individuals to guide their own life choices. For example, students making academic plans refer to friends; patients refer to acquaintances with similar conditions, physicians mention past cases seen in their practice. How would they want to search for similar people in databases? We discuss the challenge of finding similar people to guide life choices and report on a need analysis based on 13 interviews. Our PeerFinder prototype enables users to find records that are similar to a seed record, using both record attributes and temporal events found in the records. A user study with 18 participants and four experts shows that users are more engaged and more confident about the value of the results to provide useful evidence to guide life choices when provided with more control over the search process and more context for the results, even at the cost of added complexity.\n",
      "493\n",
      "People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges\n",
      "Blind people often need to identify objects around them, from packages of food to items of clothing. Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people with different background clutter, scale, viewpoints, occlusion, and image quality than in photos taken by blind users. We explore personal object recognizers, where visually impaired people train a mobile application with a few snapshots of objects of interest and provide custom labels. We adopt transfer learning with a deep learning system for user-defined multi-label k-instance classification. Experiments with blind participants demonstrate the feasibility of our approach, which reaches accuracies over 90% for some participants. We analyze user data and feedback to explore effects of sample size, photo-quality variance, and object shape; and contrast models trained on photos by blind participants to those by sighted participants and generic recognizers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "SUGILITE: Creating Multimodal Smartphone Automation by Demonstration\n",
      "SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that users with little or no programming knowledge can successfully automate smartphone tasks using SUGILITE.\n",
      "531\n",
      "Tap the \"Make This Public\" Button: A Design-Based Inquiry into Issue Advocacy and Digital Civics\n",
      "This paper examines the strategies of cycling advocates when deploying digital tools in their advocacy work as they support and create better cycling infrastructure and policies. Over the course of two years, we interviewed and conducted design-based fieldwork in two large U.S. cities with individuals and advocacy organizations, learning about the goals, motivations, and constraints that inform their work in their respective urban homes. Our design-based investigation and fieldwork advance a deeper, situated understanding of the role that computing technology plays when engaging across multiple sites of advocacy work. From this, we add detail to the connections across resources, identities, and issues and continue to advance the emerging area of digital civics, which seeks to design tools that support relational civic interactions across multiple categories of civic actors.\n",
      "562\n",
      "Gender-Inclusiveness Personas vs. Stereotyping: Can We Have it Both Ways?\n",
      "Personas often aim to improve product designers' ability to \"see through the eyes of\" target users through the empathy personas can inspire - but personas are also known to promote stereotyping. This tension can be particularly problematic when personas (who, of course as \"people\" have genders) are used to promote gender inclusiveness - because reinforcing stereotypical perceptions can run counter to gender inclusiveness. In this paper we explicitly investigate this tension through a new approach to personas: one that includes multiple photos (of males and females) for a single persona. We compared this approach to an identical persona with only one photo using a controlled laboratory study and an eye-tracking study. Our goal was to answer the following question: is it possible for personas to encourage product designers to engage with personas while at the same avoiding promoting gender stereotyping? Our results are encouraging about the use of personas with multiple pictures as a way to expand participants' consideration of multiple genders without reducing their engagement with the persona.\n",
      "579\n",
      "Self-Experimentation for Behavior Change: Design and Formative Evaluation of Two Approaches\n",
      "Desirable outcomes such as health are tightly linked to behaviors, thus inspiring research on technologies that support people in changing those behaviors. Many behavior-change technologies are designed by HCI experts but this approach can make it difficult to personalize support to each user's unique goals and needs. This paper reports on the iterative design of two complementary support strategies for helping users create their own personalized behavior-change plans via self-experimentation: One emphasized the use of interactive instructional materials, and the other additionally introduced context-aware computing to enable user creation of \"just in time\" home-based interventions. In a formative trial with 27 users, we compared these two approaches to an unstructured sleep education control. Results suggest great promise in both strategies and provide insights on how to develop personalized behavior-change technologies.\n",
      "2009\n",
      "3\n",
      "Designing digital games for rural children: a study of traditional village games in India\n",
      "Low educational levels hinder economic empowerment in developing countries. We make the case that educational games can impact children in the developing world. We report on exploratory studies with three communities in North and South India to show some problems with digital games that fail to match rural children's understanding of games, to highlight that there is much for us to learn about designing games that are culturally meaningful to them. We describe 28 traditional village games that they play, based on our contextual interviews. We analyze the mechanics in these games and compare these mechanics against existing videogames to show what makes traditional games unique. Our analysis has helped us to interpret the playability issues that we observed in our exploratory studies, and informed the design of a new videogame that rural children found to be more intuitive and engaging.\n",
      "5\n",
      "A comparative study of speech and dialed input voice interfaces in rural India\n",
      "In this paper we present a study comparing speech and dialed input voice user interfaces for farmers in Gujarat, India. We ran a controlled, between-subjects experiment with 45 participants. We found that the task completion rates were significantly higher with dialed input, particularly for subjects under age 30 and those with less than an eighth grade education. Additionally, participants using dialed input demonstrated a significantly greater performance improvement from the first to final task, and reported less difficulty providing input to the system.\n",
      "43\n",
      "Fast gaze typing with an adjustable dwell time\n",
      "Previous research shows that text entry by gaze using dwell time is slow, about 5-10 words per minute (wpm). These results are based on experiments with novices using a constant dwell time, typically between 450 and 1000 ms. We conducted a longitudinal study to find out how fast novices learn to type by gaze using an adjustable dwell time. Our results show that the text entry rate increased from 6.9 wpm in the first session to 19.9 wpm in the tenth session. Correspondingly, the dwell time decreased from an average of 876 ms to 282 ms, and the error rates decreased from 1.28% to .36%. The achieved typing speed of nearly 20 wpm is comparable with the result of 17.3 wpm achieved in an earlier, similar study with Dasher.\n",
      "48\n",
      "Designing for the self: making products that help people become the person they desire to be\n",
      "Product attachment theory describes how people learn to love certain possessions through a process of meaning making. It provides a rich and as yet untapped source of inspiration for driving the practice of experience design. However, there are currently no guidelines that describe how to apply this theory in design practice. Taking a research through design approach, I made many different products with the goal of helping people become the person they desire to be through their product interactions. Then, in order to better understand how the different design teams applied attachment theory, I created a set of design patterns that document the application of product attachment theory to the interaction design of each product. I clustered the patterns based on similarities across the different artifacts, and this produced six framing constructs, which work as specific perspectives designers can take when applying product attachment theory in an experience design project.\n",
      "51\n",
      "Learning from IKEA hacking: i'm not one to decoupage a tabletop and call it a day.\n",
      "We present a qualitative study based on interviews with nine IKEA Hackers - people who go online to share the process of repurposing IKEA products to create personalized objects. Whether they were making a self-conscious artistic statement or simply modifying a towel rack to fit in a small bathroom, IKEA hackers illuminate an emergent practice that provides insights into contemporary changes in creativity. We discuss the motivations for IKEA hacking and explore the impact of information technology on do-it-yourself culture, design, and HCI.\n",
      "73\n",
      "Signpost from the masses: learning effects in an exploratory social tag search browser\n",
      "Social tagging arose out of the need to organize found content that is worth revisiting. A significant side effect has been the use of social tagging sites as navigational signposts for interesting content. The collective behavior of users who tagged contents seems to offer a good basis for exploratory search interfaces, even for users who are not using social bookmarking sites. In this paper, we present the design of a tag-based exploratory system and detail an experiment in understanding its effectiveness. The tag-based search system allows users to utilize relevance feedback on tags to indicate their interest in various topics, enabling rapid exploration of the topic space. The experiment shows that the system seems to provide a kind of scaffold for users to learn new topics.\n",
      "87\n",
      "Facts or friends?: distinguishing informational and conversational questions in social Q&A sites\n",
      "Tens of thousands of questions are asked and answered every day on social question and answer (Q&A) Web sites such as Yahoo Answers. While these sites generate an enormous volume of searchable data, the problem of determining which questions and answers are archival quality has grown. One major component of this problem is the prevalence of conversational questions, identified both by Q&A sites and academic literature as questions that are intended simply to start discussion. For example, a conversational question such as \"do you believe in evolution?\" might successfully engage users in discussion, but probably will not yield a useful web page for users searching for information about evolution. Using data from three popular Q&A sites, we confirm that humans can reliably distinguish between these conversational questions and other informational questions, and present evidence that conversational questions typically have much lower potential archival value than informational questions. Further, we explore the use of machine learning techniques to automatically classify questions as conversational or informational, learning in the process about categorical, linguistic, and social differences between different question types. Our algorithms approach human performance, attaining 89.7% classification accuracy in our experiments.\n",
      "90\n",
      "SmartPlayer: user-centric video fast-forwarding\n",
      "In this paper we propose a new video interaction model called adaptive fast-forwarding to help people quickly browse videos with predefined semantic rules. This model is designed around the metaphor of scenic car driving, in which the driver slows down near areas of interest and speeds through unexciting areas. Results from a preliminary user study of our video player suggest the following: (1) the player should adaptively adjust the current playback speed based on the complexity of the present scene and predefined semantic events; (2) the player should learn user preferences about predefined event types as well as a suitable playback speed; (3) the player should fast-forward the video continuously with a playback rate acceptable to the user to avoid missing any undefined events or areas of interest. Furthermore, our user study results suggest that for certain types of video, our SmartPlayer yields better user experiences in browsing and fast-forwarding videos than existing video players' interaction models.\n",
      "111\n",
      "Comparing the use of tangible and graphical programming languages for informal science education\n",
      "Much of the work done in the field of tangible interaction has focused on creating tools for learning; however, in many cases, little evidence has been provided that tangible interfaces offer educational benefits compared to more conventional interaction techniques. In this paper, we present a study comparing the use of a tangible and a graphical interface as part of an interactive computer programming and robotics exhibit that we designed for the Boston Museum of Science. In this study, we have collected observations of 260 museum visitors and conducted interviews with 13 family groups. Our results show that visitors found the tangible and the graphical systems equally easy to understand. However, with the tangible interface, visitors were significantly more likely to try the exhibit and significantly more likely to actively participate in groups. In turn, we show that regardless of the condition, involving multiple active participants leads to significantly longer interaction times. Finally, we examine the role of children and adults in each condition and present evidence that children are more actively involved in the tangible condition, an effect that seems to be especially strong for girls.\n",
      "137\n",
      "Tabletop displays for small group study: affordances of paper and digital materials\n",
      "In this paper we compare the affordances of presenting educational material on a tabletop display with presenting the same material using traditional paper handouts. Ten pairs of undergraduate students used digital or paper materials to prepare for exams during four one-hour study sessions over the course of a term. Students studying with the tabletop display solved problems on their own before resorting to answer keys and repeated activities more often than students studying with paper documents. We summarize study activities and discuss the benefits and drawbacks of each medium.\n",
      "142\n",
      "Taking the time to care: empowering low health literacy hospital patients with virtual nurse agents\n",
      "Ninety million Americans have inadequate health literacy, resulting in a reduced ability to read and follow directions in the healthcare environment. We describe an animated, empathic virtual nurse interface for educating and counseling hospital patients with inadequate health literacy in their hospital beds at the time of discharge. The development methodology, design rationale, and two iterations of user testing are described. Results indicate that hospital patients with low health literacy found the system easy to use, reported high levels of satisfaction, and most said they preferred receiving the discharge information from the agent over their doctor or nurse. Patients also expressed appreciation for the time and attention provided by the virtual nurse, and felt that it provided an additional authoritative source for their medical information.\n",
      "145\n",
      "EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers\n",
      "Machine learning is an increasingly used computational tool within human-computer interaction research. While most researchers currently utilize an iterative approach to refining classifier models and performance, we propose that ensemble classification techniques may be a viable and even preferable alternative. In ensemble learning, algorithms combine multiple classifiers to build one that is superior to its components. In this paper, we present EnsembleMatrix, an interactive visualization system that presents a graphical view of confusion matrices to help users understand relative merits of various classifiers. EnsembleMatrix allows users to directly interact with the visualizations in order to explore and build combination models. We evaluate the efficacy of the system and the approach in a user study. Results show that users are able to quickly combine multiple classifiers operating on multiple feature sets to produce an ensemble classifier with accuracy that approaches best-reported performance classifying images in the CalTech-101 dataset.\n",
      "155\n",
      "Learning how: the search for craft knowledge on the internet\n",
      "Communicating the subtleties of a craft technique, like putting a zipper into a garment or throwing a clay pot, can be challenging even when working side by side. Yet How-To content - including text, images, animations, and videos - is available online for a wide variety of crafts. We interviewed people engaged in various crafts to investigate how online resources contributed to their craft practice. We found that participants sought creative inspiration as well as technical clarification online. In this domain, keyword search can be difficult, so supplemental strategies are used. Participants sought information iteratively, because they often needed to enact their knowledge in order to evaluate it. Our description of people learning how allows us to elaborate existing understandings of information-seeking behavior by considering how search originates and is evaluated in knowledge domains involving physical objects and physical processes.\n",
      "183\n",
      "Two studies of opportunistic programming: interleaving web foraging, learning, and writing code\n",
      "This paper investigates the role of online resources in problem solving. We look specifically at how programmers - an exemplar form of knowledge workers - opportunistically interleave Web foraging, learning, and writing code. We describe two studies of how programmers use online resources. The first, conducted in the lab, observed participants' Web use while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches, clarify and extend their existing knowledge, and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries \"in the wild\" have the same range of intentions, or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal, examining the lexical structure, refinements made, and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming, and suggest opportunities for tools to facilitate online knowledge work.\n",
      "184\n",
      "Comparison of three one-question, post-task usability questionnaires\n",
      "Post-task ratings of difficulty in a usability test have the potential to provide diagnostic information and be an additional measure of user satisfaction. But the ratings need to be reliable as well as easy to use for both respondents and researchers. Three one-question rating types were compared in a study with 26 participants who attempted the same five tasks with two software applications. The types were a Likert scale, a Usability Magnitude Estimation (UME) judgment, and a Subjective Mental Effort Question (SMEQ). All three types could distinguish between the applications with 26 participants, but the Likert and SMEQ types were more sensitive with small sample sizes. Both the Likert and SMEQ types were easy to learn and quick to execute. The online version of the SMEQ question was highly correlated with other measures and had equal sensitivity to the Likert question type.\n",
      "203\n",
      "A comparison of mobile money-transfer UIs for non-literate and semi-literate users\n",
      "Due to the increasing penetration of mobile phones even into poor communities, mobile payment schemes could bring formal financial services to the \"unbanked\". However, because poverty for the most part also correlates with low levels of formal education, there are questions as to whether electronic access to complex financial services is enough to bridge the gap, and if so, what sort of UI is best. In this paper, we present two studies that provide preliminary answers to these questions. We first investigated the usability of existing mobile payment services, through an ethnographic study involving 90 subjects in India, Kenya, the Philippines and South Africa. This was followed by a usability study with another 58 subjects in India, in which we compared non-literate and semi-literate subjects on three systems: text-based, spoken dialog (without text), and rich multimedia (also without text). Results confirm that non-text designs are strongly preferred over text-based designs and that while task-completion rates are better for the rich multimedia UI, speed is faster and less assistance is required on the spoken-dialog system.\n",
      "209\n",
      "With a little help from my friends: examining the impact of social annotations in sensemaking tasks\n",
      "In prior work we reported on the design of a social annotation system, SparTag.us, for use in sensemaking activities such as work-group reading and report writing. Previous studies of note-taking systems have demonstrated behavioral differences in social annotation practices, but are not clear in the actual performance gains provided by social features. This paper presents a laboratory study aimed at evaluating the learning effect of social features in SparTag.us. We found significant learning gains, and consider implications for design and for understanding the underlying mechanisms in play when people use social annotation systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "Amplifying community content creation with mixed initiative information extraction\n",
      "Although existing work has explored both information extraction and community content creation, most research has focused on them in isolation. In contrast, we see the greatest leverage in the synergistic pairing of these methods as two interlocking feedback cycles. This paper explores the potential synergy promised if these cycles can be made to accelerate each other by exploiting the same edits to advance both community content creation and learning-based information extraction. We examine our proposed synergy in the context of Wikipedia infoboxes and the Kylin information extraction system. After developing and refining a set of interfaces to present the verification of Kylin extractions as a non primary task in the context of Wikipedia articles, we develop an innovative use of Web search advertising services to study people engaged in some other primary task. We demonstrate our proposed synergy by analyzing our deployment from two complementary perspectives: (1) we show we accelerate community content creation by using Kylin's information extraction to significantly increase the likelihood that a person visiting a Wikipedia article as a part of some other primary task will spontaneously choose to help improve the article's infobox, and (2) we show we accelerate information extraction by using contributions collected from people interacting with our designs to significantly improve Kylin's extraction performance.\n",
      "257\n",
      "Anatomy of a failure: how we knew when our design went wrong, and what we learned from it\n",
      "In this paper, we describe the failure of a novel sensor-based system intended to evoke user interpretation and appropriation in domestic settings. We contrast participants' interactions in this case study with those observed during more successful deployments to identify 'symptoms of failure' under four themes: engagement, reference, accommodation, and surprise and insight. These themes provide a set of sensitivities or orientations that may complement traditional task-based approaches to evaluation as well as the more open-ended ones we describe here. Our system showed symptoms of failure under each of these themes. We examine the reasons for this at three levels: problems particular to the specific design hypothesis; problems relevant for input-output mapping more generally; and problems in the design process we used. We conclude by noting that, although interpretive systems such as the one we describe here may succeed in a myriad of different ways, it is reassuring to know that they can also fail, and fail incontrovertibly, yet instructively.\n",
      "260\n",
      "Tactile motion instructions for physical activities\n",
      "While learning new motor skills, we often rely on feedback from a trainer. Auditive feedback and demonstrations are used most frequently, but in many domains they are inappropriate or impractical. We introduce tactile instructions as an alternative to assist in correcting wrong posture during physical activities, and present a set of full-body vibrotactile patterns. An initial study informed the design of our tactile patterns, and determined appropriate locations for feedback on the body. A second experiment showed that users perceived and correctly classified our tactile instruction patterns in a relaxed setting and during a cognitively and physically demanding task. In a final experiment, snowboarders on the slope compared their perception of tactile instructions with audio instructions under real-world conditions. Tactile instructions achieved overall high recognition accuracy similar to audio instructions. Moreover, participants responded quicker to instructions delivered over the tactile channel than to instructions presented over the audio channel. Our findings suggest that these full-body tactile feedback patterns can replace audio instructions during physical activities.\n",
      "265\n",
      "GestureBar: improving the approachability of gesture-based interfaces\n",
      "GestureBar is a novel, approachable UI for learning gestural interactions that enables a walk-up-and-use experience which is in the same class as standard menu and toolbar interfaces. GestureBar leverages the familiar, clean look of a common toolbar, but in place of executing commands, richly discloses how to execute commands with gestures, through animated images, detail tips and an out-of-document practice area. GestureBar's simple design is also general enough for use with any recognition technique and for integration with standard, non-gestural UI components. We evaluate GestureBar in a formal experiment showing that users can perform complex, ecologically valid tasks in a purely gestural system without training, introduction, or prior gesture experience when using GestureBar, discovering and learning a high percentage of the gestures needed to perform the tasks optimally, and significantly outperforming a state of the art crib sheet. The relative contribution of the major design elements of GestureBar is also explored. A second experiment shows that GestureBar is preferred to a basic crib sheet and two enhanced crib sheet variations.\n",
      "2008\n",
      "18\n",
      "Explore! possibilities and challenges of mobile learning\n",
      "This paper reports the experimental studies we have performed to evaluate Explore!, an m-learning system that supports middle school students during a visit to an archaeological park. It exploits a learning technique called excursion-game, whose aim is to help students to acquire historical notions while playing and to make archaeological visits more effective and exciting. In order to understand the potentials and limitations of Explore!, our studies compare the experience of playing the excursion-game with and without technological support. The design and evaluation of Explore! have provided knowledge on the advantages and pitfalls of m-learning that may be instrumental in informing the current debate on e-learning.\n",
      "43\n",
      "Sustainable millennials: attitudes towards sustainability and the material effects of interactive technologies\n",
      "This paper describes the design and interprets the results of a survey of 435 undergraduate students concerning the attitudes of this mainly millennial population towards sustainability apropos of the material effects of information technologies. This survey follows from earlier work on notions of Sustainable Interaction Design (SID)---that is the perspective that sustainability can and should be a central focus within HCI. In so doing it advances to some degree the empirical resources needed to scaffold an understanding of the theory and principles of SID. The interpretations offered yield key insights about understanding different notions of what it means to be successful in a material sense to this population and specific design principles for creating interactive designs differently such that more sustainable behaviors are palatable to individuals of varying attitudes.\n",
      "46\n",
      "Playful toothbrush: ubicomp technology for teaching tooth brushing to kindergarten children\n",
      "This case study in UbiComp technology and design presents a \"Playful Toothbrush\" system for assisting parents and teachers to motivate kindergarten children to learn proper and thorough brushing skills. The system includes a vision-based motion tracker that recognizes different tooth brushing strokes and a tooth brushing game in which the child cleans a virtual, mirror picture of his/her dirty teeth by physically brushing his/her own teeth. The user study results suggest that Playful Toothbrush enhances the effectiveness of kindergarten children in brushing their teeth, as measured by number of brushing strokes, duration of brushing and thoroughness of teeth cleaning.\n",
      "51\n",
      "K-sketch: a 'kinetic' sketch pad for novice animators\n",
      "Because most animation tools are complex and time-consuming to learn and use, most animations today are created by experts. To help novices create a wide range of animations quickly, we have developed a general-purpose, informal, 2D animation sketching system called K-Sketch. Field studies investigating the needs of animators and would-be animators helped us collect a library of usage scenarios for our tool. A novel optimization technique enabled us to design an interface that is simultaneously fast, simple, and powerful. The result is a pen-based system that relies on users' intuitive sense of space and time while still supporting a wide range of uses. In a laboratory experiment that compared K-Sketch to a more formal animation tool (PowerPoint), participants worked three times faster, needed half the learning time, and had significantly lower cognitive load with K-Sketch.\n",
      "52\n",
      "The LilyPad Arduino: using computational textiles to investigate engagement, aesthetics, and diversity in computer science education\n",
      "The advent of novel materials (such as conductive fibers) combined with accessible embedded computing platforms have made it possible to re-imagine the landscapes of fabric and electronic crafts--extending these landscapes with the creative range of electronic/computational textiles or e-textiles. This paper describes the LilyPad Arduino, a fabric-based construction kit that enables novices to design and build their own soft wearables and other textile artifacts. The kit consists of a microcontroller and an assortment of sensors and actuators in stitch-able packages; these elements can be sewn to cloth substrates and each other with conductive thread to build e-textiles. This paper will introduce the latest version of the kit; reflect on its affordances; present the results of our most recent user studies; and discuss possible directions for future work in the area of personalized e-textile design and its relation to technology education.\n",
      "56\n",
      "Aligning temporal data by sentinel events: discovering patterns in electronic health records\n",
      "Electronic Health Records (EHRs) and other temporal databases contain hidden patterns that reveal important cause-and-effect phenomena. Finding these patterns is a challenge when using traditional query languages and tabular displays. We present an interactive visual tool that complements query formulation by providing operations to align, rank and filter the results, and to visualize estimates of the intervals of validity of the data. Display of patient histories aligned on sentinel events (such as a first heart attack) enables users to spot precursor, co-occurring, and aftereffect events. A controlled study demonstrates the benefits of providing alignment (with a 61% speed improvement for complex tasks). A qualitative study and interviews with medical professionals demonstrates that the interface can be learned quickly and seems to address their needs.\n",
      "79\n",
      "Experience sampling for building predictive user models: a comparative study\n",
      "Experience sampling has been employed for decades to collect assessments of subjects' intentions, needs, and affective states. In recent years, investigators have employed automated experience sampling to collect data to build predictive user models. To date, most procedures have relied on random sampling or simple heuristics. We perform a comparative analysis of several automated strategies for guiding experience sampling, spanning a spectrum of sophistication, from a random sampling procedure to increasingly sophisticated active learning. The more sophisticated methods take a decision-theoretic approach, centering on the computation of the expected value of information of a probe, weighing the cost of the short-term disruptiveness of probes with their benefits in enhancing the long-term performance of predictive models. We test the different approaches in a field study, focused on the task of learning predictive models of the cost of interruption.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "CareLog: a selective archiving tool for behavior management in schools\n",
      "Identifying the function of problem behavior can lead to the development of more effective interventions. One way to identify the function is through functional behavior assessment (FBA). Teachers conduct FBA in schools. However, the task load of recording the data manually is high, and the challenge of accurately identifying antecedents and consequences is significant while interacting with students. These issues often result in imperfect information capture. CareLog allows teachers more easily to conduct FBAs and enhances the capture of relevant information. In this paper, we describe the design process that led to five design principles that governed the development of CareLog. We present results from a five-month, quasi-controlled study aimed at validating those design principles. We reflect on how various constraints imposed by special education settings impact the design and evaluation process for HCI practitioners and researchers.\n",
      "149\n",
      "Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces\n",
      "Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.\n",
      "2007\n",
      "3\n",
      "How it works: a field study of non-technical users interacting with an intelligent system\n",
      "In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems.\n",
      "46\n",
      "Investigating attractiveness in web user interfaces\n",
      "A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed.\n",
      "80\n",
      "Understanding and developing models for detecting and differentiating breakpoints during interactive tasks\n",
      "The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks.\n",
      "81\n",
      "Implicit coordination in firefighting practice: design implications for teaching fire emergency responders\n",
      "Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.\n",
      "93\n",
      "The life and death of online gaming communities: a look at guilds in world of warcraft\n",
      "Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or \"guilds\" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.\n",
      "101\n",
      "Protecting people from phishing: the design and evaluation of an embedded training email system\n",
      "Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems.\n",
      "120\n",
      "Modeling and understanding students' off-task behavior in intelligent tutoring systems\n",
      "We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "Grow and know: understanding record-keeping needs for tracking the development of young children\n",
      "From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain.\n",
      "165\n",
      "Storytelling alice motivates middle school girls to learn computer programming\n",
      "We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.\n",
      "180\n",
      "Multiple mice for retention tasks in disadvantaged schools\n",
      "This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.\n",
      "181\n",
      "Strategies for accelerating on-line learning of hotkeys\n",
      "Hotkeys are extremely useful in leveraging expert performance, but learning them is a slow process. This paper investigates alternative menu designs that can motivate and help users remember associations between menu commands and hotkeys. Building upon previous work on paired-associate learning, we suggest that the transition to expert use can be accelerated by manipulating feedback and cost associated with menu selection. We evaluate five designs in a pilot study and then two of the most promising ones in a formal experiment, showing that the speed of hotkey learning can indeed be significantly increased with little modifications to the standard menu/hotkey paradigm.\n",
      "1998\n",
      "Squeeze me, hold me, tilt me! An exploration of manipulative user interfaces\n",
      "An abstract is not available.\n",
      "2\n",
      "Web page design: implications of memory, structure and scent for information retrieval\n",
      "An abstract is not available.\n",
      "3\n",
      "Information archiving with bookmarks: personal Web space construction and organization\n",
      "An abstract is not available.\n",
      "5\n",
      "Triangles: tangible interface for manipulation and exploration of digital information topography\n",
      "An abstract is not available.\n",
      "6\n",
      "Evolving video skims into useful multimedia abstractions\n",
      "An abstract is not available.\n",
      "22\n",
      "Persuasive computers: perspectives and research directions\n",
      "An abstract is not available.\n",
      "29\n",
      "A diary study of work-related reading: design implications for digital reading devices\n",
      "An abstract is not available.\n",
      "31\n",
      "Beyond paper: supporting active reading with free form digital ink annotations\n",
      "An abstract is not available.\n",
      "32\n",
      "Digital manipulatives: new toys to think with\n",
      "An abstract is not available.\n",
      "36\n",
      "PRoP: personal roving presence\n",
      "An abstract is not available.\n",
      "38\n",
      "Quantifying coordination in multiple DOF movement and its application to evaluating 6 DOF input devices\n",
      "An abstract is not available.\n",
      "41\n",
      "A multiple device approach for supporting whiteboard-based interactions\n",
      "An abstract is not available.\n",
      "44\n",
      "Visualizing the evolution of Web ecologies\n",
      "An abstract is not available.\n",
      "51\n",
      "Investigating the capture, integration and access problem of ubiquitous computing in an educational setting\n",
      "An abstract is not available.\n",
      "56\n",
      "Heart rate variability: indicator of user state as an aid to human-computer interaction\n",
      "An abstract is not available.\n",
      "61\n",
      "Trust breaks down in electronic contexts but can be repaired by some initial face-to-face contact\n",
      "An abstract is not available.\n",
      "63\n",
      "Illuminating light: an optical design tool with a luminous-tangible interface\n",
      "An abstract is not available.\n",
      "69\n",
      "Designing audio aura\n",
      "An abstract is not available.\n",
      "72\n",
      "1994\n",
      "Computers are social actors\n",
      "An abstract is not available.\n",
      "10\n",
      "Interactive graphic design using automatic presentation knowledge\n",
      "An abstract is not available.\n",
      "16\n",
      "Informal workplace communication: what is it like and how might we support it?\n",
      "An abstract is not available.\n",
      "19\n",
      "Enhancing the explanatory power of usability heuristics\n",
      "An abstract is not available.\n",
      "22\n",
      "The marks are on the knowledge worker\n",
      "An abstract is not available.\n",
      "27\n",
      "User learning and performance with marking menus\n",
      "An abstract is not available.\n",
      "38\n",
      "FILOCHAT: handwritten notes provide access to recorded conversations\n",
      "An abstract is not available.\n",
      "40\n",
      "The movable filter as a user interface tool\n",
      "An abstract is not available.\n",
      "45\n",
      "Visual information seeking: tight coupling of dynamic query filters with starfield displays\n",
      "An abstract is not available.\n",
      "46\n",
      "The table lens: merging graphical and symbolic representations in an interactive focus + context visualization for tabular information\n",
      "An abstract is not available.\n",
      "47\n",
      "The alphaslider: a compact and rapid selector\n",
      "An abstract is not available.\n",
      "54\n",
      "Two-handed input in a compound task\n",
      "An abstract is not available.\n",
      "62\n",
      "Passive real-world interface props for neurosurgical visualization\n",
      "An abstract is not available.\n",
      "67\n",
      "2014\n",
      "1\n",
      "Quantifying visual preferences around the world\n",
      "Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as \"good design\" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.\n",
      "4\n",
      "Stress and multitasking in everyday college life: an empirical study of online activity\n",
      "While HCI has focused on multitasking with information workers, we report on multitasking among Millennials who grew up with digital media - focusing on college students. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. We found a significant positive relationship with stress and daily time spent on computers. Stress is positively associated with the amount of multitasking. Conversely, stress is negatively associated with Facebook and social media use. Heavy multitaskers use significantly more social media and report lower positive affect than light multitaskers. Night habits affect multitasking the following day: late-nighters show longer duration of computer use and those ending their activities earlier in the day multitask less. Our study shows that college students multitask at double the frequency compared to studies of information workers. These results can inform designs for stress management of college students.\n",
      "52\n",
      "\"now that's definitely a proper hack\": self-made tools in hackerspaces\n",
      "Cultures of making - that is, social practices of hacking, DIY, tinkering, repair, and craft - continue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a 9-month ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practice - tool-making - within the hackerspace we studied.\n",
      "54\n",
      "Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness\n",
      "Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly \"in the wild\" contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.\n",
      "88\n",
      "Practical trigger-action programming in the smart home\n",
      "We investigate the practicality of letting average users customize smart-home devices using trigger-action (\"if, then\") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "Understanding quantified-selfers' practices in collecting and exploring personal data\n",
      "Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these \"extreme users,\" who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did, how they did it, and what they learned. We highlight several common pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.\n",
      "131\n",
      "Beyond ethnography: engagement and reciprocity as foundations for design research out here\n",
      "This paper explores an emerging paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover rapid ethnographic research often does not seem the best or most appropriate course of action. We draw upon a project working with a remote Australian Aboriginal community to illustrate an alternative approach in Indigenous research, where the notion of reciprocity is first and foremost. We argue that this can lead to sustainable designs, valid research and profound innovation.\n",
      "151\n",
      "Seeking and sharing health information online: comparing search engines and social media\n",
      "Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.\n",
      "188\n",
      "Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard\n",
      "We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.\n",
      "194\n",
      "Circuit stickers: peel-and-stick construction of interactive electronic prototypes\n",
      "We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call circuit stickers, involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be interfaced to a microcontroller or PC. In this paper we illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found circuit stickers to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research proto-typing, education and for hobbyist projects.\n",
      "200\n",
      "Involving children in content control: a collaborative and education-oriented content filtering approach\n",
      "We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.\n",
      "219\n",
      "Reading critical designs: supporting reasoned interpretations of critical design\n",
      "Critical Design has emerged as an important concept in HCI research and practice. Yet researchers have noted that its uptake has been limited by certain lacks of intellectual infrastructure theories, methodologies, canons and exemplars, and a community of practice. We argue that one way to create this infrastructure is to cultivate a community adept at reading that is, critically interpreting and making reasoned judgments about critical designs. We propose an approach to developing close readings of critical designs, which are both evidence-based and carefully reasoned. The approach highlights analytical units of analysis, the relevance of design languages and social norms, and the analytical contemplation of critical aspects of a design. It is intended to be relatively easy to learn, to try out, and to teach, in the hopes of inviting more members of the HCI community to engage in this practice. We exemplify the approach with readings of two critical designs and reflect on different ways that a design might serve a critical purpose or offer a critical argument about design, society, and the future.\n",
      "225\n",
      "28 frames later: predicting screen touches from back-of-device grip changes\n",
      "We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.\n",
      "248\n",
      "Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames\n",
      "Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how the balancing approach affects performance, experience, and self-esteem'especially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.\n",
      "249\n",
      "Supporting the creative game design process with exertion cards\n",
      "Advances in sensing technologies have led to research into exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are few tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the \"Exertion Framework\", grounded in our experience of creating exertion games for over a decade. We present results demonstrating the value and utility of these Exertion Cards based on our studies of their use in three workshops held over seven sessions with 134 design students and experts. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.\n",
      "257\n",
      "@BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones\n",
      "The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their children's progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.\n",
      "263\n",
      "Hooked on smartphones: an exploratory study on smartphone overuse among college students\n",
      "The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.\n",
      "279\n",
      "Addressing misconceptions about code with always-on programming visualizations\n",
      "We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.\n",
      "283\n",
      "A novel knee rehabilitation system for the home\n",
      "In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.\n",
      "302\n",
      "Understanding sustained community engagement: a case study in heritage preservation in rural argentina\n",
      "HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. In this paper we investigate what factors are important for developing long lasting community ICT interventions. We do this by analysing a successful action research project and provide five recommendations for facilitating sustained community engagement. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy.\n",
      "317\n",
      "StepStream: a school-based pervasive social fitness system for everyday adolescent health\n",
      "Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.\n",
      "321\n",
      "SensaBubble: a chrono-sensory mid-air display of sight and smell\n",
      "We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until it bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubble's design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts -- from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.\n",
      "344\n",
      "Structured labeling for facilitating concept evolution in machine learning\n",
      "Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution, the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n",
      "Brain points: a growth mindset incentive structure boosts persistence in an educational game\n",
      "There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present \"brain points,\" a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the \"brain points\" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.\n",
      "377\n",
      "Combining crowdsourcing and learning to improve engagement and performance\n",
      "Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing to benefit both the workers and the requesters. Workers gain new skills through interactive step-by-step tutorials and test their knowledge by improving real-world images submitted by requesters. In a series of three deployments spanning two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system workers gained new skills and produced high-quality edits for requested images, even if they had little prior experience editing images.\n",
      "398\n",
      "Shared values/conflicting logics: working around e-government systems\n",
      "In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.\n",
      "406\n",
      "Twitch crowdsourcing: crowd contributions in short bursts of time\n",
      "To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.\n",
      "2012\n",
      "1\n",
      "Pay attention!: designing adaptive agents that monitor and improve user engagement\n",
      "Embodied agents hold great promise as educational assistants, exercise coaches, and team members in collaborative work. These roles require agents to closely monitor the behavioral, emotional, and mental states of their users and provide appropriate, effective responses. Educational agents, for example, will have to monitor student attention and seek to improve it when student engagement decreases. In this paper, we draw on techniques from brain-computer interfaces (BCI) and knowledge from educational psychology to design adaptive agents that monitor student attention in real time using measurements from electroencephalography (EEG) and recapture diminishing attention levels using verbal and nonverbal cues. An experimental evaluation of our approach showed that an adaptive robotic agent employing behavioral techniques to regain attention during drops in engagement improved student recall abilities 43% over the baseline regardless of student gender and significantly improved female motivation and rapport. Our findings offer guidelines for developing effective adaptive agents, particularly for educational settings.\n",
      "2\n",
      "Regroup: interactive machine learning for on-demand group creation in social networks\n",
      "We present ReGroup, a novel end-user interactive machine learning system for helping people create custom, on demand groups in online social networks. As a person adds members to a group, ReGroup iteratively learns a probabilistic model of group membership specific to that group. ReGroup then uses its currently learned model to suggest additional members and group characteristics for filtering. Our evaluation shows that ReGroup is effective for helping people create large and varied groups, whereas traditional methods (searching by name or selecting from an alphabetical list) are better suited for small groups whose members can be easily recalled by name. By facilitating on demand group creation, ReGroup can enable in-context sharing and potentially encourage better online privacy practices. In addition, applying interactive machine learning to social network group creation introduces several challenges for designing effective end-user interaction with machine learning. We identify these challenges and discuss how we address them in ReGroup.\n",
      "7\n",
      "The impact of tutorials on games of varying complexity\n",
      "One of the key challenges of video game design is teaching new players how to play. Although game developers frequently use tutorials to teach game mechanics, little is known about how tutorials affect game learnability and player engagement. Seeking to estimate this value, we implemented eight tutorial designs in three video games of varying complexity and evaluated their effects on player engagement and retention. The results of our multivariate study of over 45,000 players show that the usefulness of tutorials depends greatly on game complexity. Although tutorials increased play time by as much as 29% in the most complex game, they did not significantly improve player engagement in the two simpler games. Our results suggest that investment in tutorials may not be justified for games with mechanics that can be discovered through experimentation.\n",
      "45\n",
      "SpaceSense: representing geographical information to visually impaired people using spatial tactile feedback\n",
      "Learning an environment can be challenging for people with visual impairments. Braille maps allow their users to understand the spatial relationship between a set of places. However, physical Braille maps are often costly, may not always cover an area of interest with sufficient detail, and might not present up-to-date information. We built a handheld system for representing geographical information called SpaceSense, which includes custom spatial tactile feedback hardware-multiple vibration motors attached to different locations on a mobile touch-screen device. It offers high-level information about the distance and direction towards a destination and bookmarked places through vibrotactile feedback to help the user maintain the spatial relationships between these points. SpaceSense also adapts a summarization technique for online user reviews of public and commercial venues. Our user study shows that participants could build and maintain the spatial relationships between places on a map more accurately with SpaceSense compared to a system without spatial tactile feedback. They pointed specifically to having spatial tactile feedback as the contributing factor in successfully building and maintaining their mental map.\n",
      "51\n",
      "Semantic interaction for visual text analytics\n",
      "Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual document collections in a spatial metaphor, where similarities between documents are approximately represented through their relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analysts' mental models of the document collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users must interact with such visualizations using controls external to the visual metaphor, such as sliders, menus, or text fields, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called semantic interaction, which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, called ForceSPIRE, for interactive analysis of textual data within a spatial visualization. Analysts can express their expert domain knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking the user's feedback into account.\n",
      "85\n",
      "Animating paper using shape memory alloys\n",
      "Our aim is to make shape memory alloys (SMAs) accessible and visible as creative crafting materials by combining them with paper. In this paper, we begin by presenting mechanisms for actuating paper with SMAs along with a set of design guidelines for achieving dramatic movement. We then describe how we tested the usability and educational potential of one of these mechanisms in a workshop where participants, age 9 to 15, made actuated electronic origami cranes. We found that participants were able to successfully build constructions integrating SMAs and paper, that they enjoyed doing so, and were able to learn skills like circuitry design and soldering over the course of the workshop.\n",
      "86\n",
      "Intimacy in long-distance relationships over video chat\n",
      "Many couples live a portion of their lives in a long-distance relationship (LDR). This includes a large number of dating college students as well as couples who are geographically-separated because of situational demands such as work. We conducted interviews with individuals in LDRs to understand how they make use of video chat systems to maintain their relationships. In particular, we have investigated how couples use video to \"hang out\" together and engage in activities over extended periods of time. Our results show that regardless of the relationship situation, video chat affords a unique opportunity for couples to share presence over distance, which in turn provides intimacy. While beneficial, couples still face challenges in using video chat, including contextual (e.g., location of partners, time zones), technical (e.g., mobility, audio/video quality, networking), and personal (e.g., a lack of physicality needed by most for intimate sexual acts) challenges.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "CommunitySourcing: engaging local crowds to perform expert work via physical kiosks\n",
      "Online labor markets, such as Amazon's Mechanical Turk, have been used to crowdsource simple, short tasks like image labeling and transcription. However, expert knowledge is often lacking in such markets, making it impossible to complete certain classes of tasks. In this work we introduce an alternative mechanism for crowdsourcing tasks that require specialized knowledge or skill: communitysourcing --- the use of physical kiosks to elicit work from specific populations. We investigate the potential of communitysourcing by designing, implementing and evaluating Umati: the communitysourcing vending machine. Umati allows users to earn credits by performing tasks using a touchscreen attached to the machine. Physical rewards (in this case, snacks) are dispensed through traditional vending mechanics. We evaluated whether communitysourcing can accomplish expert work by using Umati to grade Computer Science exams. We placed Umati in a university Computer Science building, targeting students with grading tasks for snacks. Over one week, 328 unique users (302 of whom were students) completed 7771 tasks (7240 by students). 80% of users had never participated in a crowdsourcing market before. We found that Umati was able to grade exams with 2% higher accuracy (at the same price) or at 33% lower cost (at equivalent accuracy) than traditional single-expert grading. Mechanical Turk workers had no success grading the same exams. These results indicate that communitysourcing can successfully elicit high-quality expert work from specific communities.\n",
      "194\n",
      "Instructing people for training gestural interactive systems\n",
      "Entertainment and gaming systems such as the Wii and XBox Kinect have brought touchless, body-movement based interfaces to the masses. Systems like these enable the estimation of movements of various body parts from raw inertial motion or depth sensor data. However, the interface developer is still left with the challenging task of creating a system that recognizes these movements as embodying meaning. The machine learning approach for tackling this problem requires the collection of data sets that contain the relevant body movements and their associated semantic labels. These data sets directly impact the accuracy and performance of the gesture recognition system and should ideally contain all natural variations of the movements associated with a gesture. This paper addresses the problem of collecting such gesture datasets. In particular, we investigate the question of what is the most appropriate semiotic modality of instructions for conveying to human subjects the movements the system developer needs them to perform. The results of our qualitative and quantitative analysis indicate that the choice of modality has a significant impact on the performance of the learnt gesture recognition system; particularly in terms of correctness and coverage.\n",
      "211\n",
      "Successful classroom deployment of a social document annotation system\n",
      "NB is an in-place collaborative document annotation website targeting students reading lecture notes and draft textbooks. Serving as a discussion forum in the document margins, NB lets users ask and answer questions about their reading material as they are reading. NB users can read and annotate documents using their web browsers, without any special plug-ins. We describe the NB system and its evaluation in real class environment, where students used it to submit their reading assignments, ask questions and get or provide feedback. We show that this tool can be and has been successfully incorporated into a number of different classes at different institutions. To understand how and why, we focus on a particularly successful class deployment where the instructor adapted his teaching style to take students' comment into account. We analyze the annotation practices that were observed - including the way geographic locality was exploited in ways unavailable in traditional forums - and discuss general design implications for online annotation tools in academia.\n",
      "237\n",
      "Discovery-based games for learning software\n",
      "We propose using discovery-based learning games to teach people how to use complex software. Specifically, we developed Jigsaw, a learning game that asks players to solve virtual jigsaw puzzles using tools in Adobe Photoshop. We conducted an eleven-person lab study of the prototype, and found the game to be an effective learning medium that can complement demonstration-based tutorials. Not only did the participants learn about new tools and techniques while actively solving the puzzles in Jigsaw, but they also recalled techniques that they had learned previously but had forgotten.\n",
      "248\n",
      "Brainput: enhancing interactive systems with streaming fnirs brain input\n",
      "This paper describes the Brainput system, which learns to identify brain activity patterns occurring during multitasking. It provides a continuous, supplemental input stream to an interactive human-robot system, which uses this information to modify its behavior to better support multitasking. This paper demonstrates that we can use non-invasive methods to detect signals coming from the brain that users naturally and effortlessly generate while using a computer system. If used with care, this additional information can lead to systems that respond appropriately to changes in the user's state. Our experimental study shows that Brainput significantly improves several performance metrics, as well as the subjective NASA-Task Load Index scores in a dual-task human-robot activity.\n",
      "268\n",
      "The design and evaluation of prototype eco-feedback displays for fixture-level water usage data\n",
      "Few means currently exist for home occupants to learn about their water consumption: e.g., where water use occurs, whether such use is excessive and what steps can be taken to conserve. Emerging water sensing systems, however, can provide detailed usage data at the level of individual water fixtures (i.e., disaggregated usage data). In this paper, we perform formative evaluations of two sets of novel eco-feedback displays that take advantage of this disaggregated data. The first display set isolates and examines specific elements of an eco-feedback design space such as data and time granularity. Displays in the second set act as design probes to elicit reactions about competition, privacy, and integration into domestic space. The displays were evaluated via an online survey of 651 North American respondents and in-home, semi-structured interviews with 10 families (20 adults). Our findings are relevant not only to the design of future water eco-feedback systems but also for other types of consumption (e.g., electricity and gas).\n",
      "295\n",
      "MOSOCO: a mobile assistive tool to support children with autism practicing social skills in real-life situations\n",
      "MOSOCO is a mobile assistive application that uses augmented reality and the visual supports of a validated curriculum, the Social Compass, to help children with autism practice social skills in real-life situations. In this paper, we present the results of a seven-week deployment study of MOSOCO in a public school in Southern California with both students with autism and neurotypical students. The results of our study demonstrate that MOSOCO facilitates practicing and learning social skills, increases both quantity and quality of social interactions, reduces social and behavioral missteps, and enables the integration of children with autism in social groups of neurotypical children. The findings from this study reveal emergent practices of the uses of mobile assistive technologies in real-life situations.\n",
      "329\n",
      "Gesture coder: a tool for programming multi-touch gestures by demonstration\n",
      "Multi-touch gestures have become popular on a wide range of touchscreen devices, but the programming of these gestures remains an art. It is time-consuming and error-prone for a developer to handle the complicated touch state transitions that result from multiple fingers and their simultaneous movements. In this paper, we present Gesture Coder, which by learning from a few examples given by the developer automatically generates code that recognizes multi-touch gestures, tracks their state changes and invokes corresponding application actions. Developers can easily test the generated code in Gesture Coder, refine it by adding more examples, and once they are satisfied with its performance integrate the code into their applications. We evaluated our learning algorithm exhaustively with various conditions over a large set of noisy data. Our results show that it is sufficient for rapid prototyping and can be improved with higher quality and more training data. We also evaluated Gesture Coder's usability through a within-subject study in which we asked participants to implement a set of multi-touch interactions with and without Gesture Coder. The results show overwhelmingly that Gesture Coder significantly lowers the threshold of programming multi-touch gestures.\n",
      "351\n",
      "Phylo-Genie: engaging students in collaborative 'tree-thinking' through tabletop techniques\n",
      "Phylogenetic trees are representations of evolutionary relationships amongst species. Interviews of instructors and students have revealed that novice biologists have difficulty understanding phylogenetics. Moreover, misinterpretations of phylogenetics are common among college-level students. In this paper we present Phylo-Genie, a tabletop interface for fostering collaborative learning of phylogenetics. We conducted an experimental study with 56 participants, comparing students' conceptual learning and engagement using Phylo-Genie as: 1) a multi-touch tabletop interface and 2) a pen and paper activity. Our findings show that the tabletop implementation fosters collaborative learning by engaging users in the activity. We also shed light on the way in which our design principles facilitated engagement and collaborative learning in a tabletop environment.\n",
      "2011\n",
      "17\n",
      "Human model evaluation in interactive supervised learning\n",
      "Model evaluation plays a special role in interactive machine learning (IML) systems in which users rely on their assessment of a model's performance in order to determine how to improve it. A better understanding of what model criteria are important to users can therefore inform the design of user interfaces for model evaluation as well as the choice and design of learning algorithms. We present work studying the evaluation practices of end users interactively building supervised learning systems for real-world gesture analysis problems. We examine users' model evaluation criteria, which span conventionally relevant criteria such as accuracy and cost, as well as novel criteria such as unexpectedness. We observed that users employed evaluation techniques---including cross-validation and direct, real-time evaluation---not only to make relevant judgments of algorithms' performance and interactively improve the trained models, but also to learn to provide more effective training data. Furthermore, we observed that evaluation taught users about what types of models were easy or possible to build, and users sometimes used this information to modify the learning problem definition or their plans for using the trained models in practice. We discuss the implications of these findings with regard to the role of generalization accuracy in IML, the design of new algorithms and interfaces, and the scope of potential benefits of incorporating human interaction in the design of supervised learning systems.\n",
      "19\n",
      "Apolo: making sense of large network data by combining rich user interaction and machine learning\n",
      "Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.\n",
      "26\n",
      "Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles\n",
      "Little research exists on one of the most common, oldest, and most utilized forms of online social geographic information: the 'location' field found in most virtual community user profiles. We performed the first in-depth study of user behavior with regard to the location field in Twitter user profiles. We found that 34% of users did not provide real location information, frequently incorporating fake locations or sarcastic comments that can fool traditional geographic information tools. When users did input their location, they almost never specified it at a scale any more detailed than their city. In order to determine whether or not natural user behaviors have a real effect on the 'locatability' of users, we performed a simple machine learning experiment to determine whether we can identify a user's location by only looking at what that user tweets. We found that a user's country and state can in fact be determined easily with decent accuracy, indicating that users implicitly reveal location information, with or without realizing it. Implications for location-based services and privacy are discussed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "Eden: a professional multitouch tool for constructing virtual organic environments\n",
      "Set construction is the process of selecting and positioning virtual geometric objects to create a virtual environment used in a computer-animated film. Set construction artists often have a clear mental image of the set composition, but find it tedious to build their intended sets with current mouse and keyboard interfaces. We investigate whether multitouch input can ease the process of set construction. Working with a professional set construction artist at Pixar Animation Studios, we designed and developed Eden, a fully functional multitouch set construction application. In this paper, we describe our design process and how we balanced the advantages and disadvantages of multitouch input to develop usable gestures for set construction. Based on our design process and the user experiences of two set construction artists, we present a general set of lessons we learned regarding the design of a multitouch interface.\n",
      "178\n",
      "Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs\n",
      "Many people read online reviews written by other users to learn more about a product or venue. However, the overwhelming amount of user-generated reviews and variance in length, detail and quality across the reviews make it difficult to glean useful information. In this paper, we present the iterative design of our system, called Review Spotlight. It provides a brief overview of reviews using adjective-noun word pairs, and allows the user to quickly explore the reviews in greater detail. Through a laboratory user study which required participants to perform decision making tasks, we showed that participants could form detailed impressions about restaurants and decide between two options significantly faster with Review Spotlight than with traditional review webpages.\n",
      "182\n",
      "Rock & rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations\n",
      "Direct touch manipulations enable the user to interact with the on-screen content in a direct and easy manner closely mimicking the spatial manipulations in the physical world. However, they also suffer from well-known issues of precision, occlusion and an inability to isolate different degrees of freedom in spatial manipulations. We present a set of interactions, called Rock & Rails, that augment existing direct touch manipulations with shape-based gestures, thus providing on-demand gain control, occlusion avoidance, and separation of constraints in 2D manipulation tasks. Using shape gestures in combination with direct-manipulations allows us to do this without ambiguity in detection and without resorting to manipulation handles, which break the direct manipulation paradigm. Our set of interactions were evaluated by 8 expert graphic designers and were found to be easy to learn and master, as well as effective in accomplishing a precise graphical layout task.\n",
      "195\n",
      "Publics in practice: ubiquitous computing at a shelter for homeless mothers\n",
      "Today, commodity technologies like mobile phones - once symbols of status and wealth - have become deeply woven into social and economic participation in Western society. Despite the pervasiveness of these technologies, there remain groups who may not have extensive access to them but who are nonetheless deeply affected by their presence in everyday life. In light of this, we designed, built, and deployed a ubiquitous computing system for one such overlooked group: the staff and residents at a shelter for homeless mothers. Our system connects mobile phones, a shared display, and a Web application to help staff and residents stay connected. We report on the adoption and use of this system over the course of a 30 week deployment, discussing the substantial impact our system had on shelter life and the broader implications for such socio-technical systems that sit at the juncture of social action and organizational coordination.\n",
      "213\n",
      "Designing from within: humanaquarium\n",
      "We present an experience-based approach to designing a collaborative interactive performance, humanaquarium. Our research explores public interaction with digital technology through the practice-based inquiry of an inter-disciplinary team of interaction designers and musicians. We present a method of designing experience from within, literally situating ourselves within the performance/use space and assuming the roles both of performers and of designers as we develop and refine the humanaquarium project over the course of a year's worth of public performances.\n",
      "217\n",
      "Why is my internet slow?: making network speeds visible\n",
      "With widespread broadband adoption, more households report experiencing sub-optimal speeds. Not only are slow speeds frustrating, they may indicate consumers are not receiving the services they are paying for from their internet service providers. Yet, determining the speed and source of slow-downs is difficult because few tools exist for broadband management. We report on results of a field trial with 10 households using a visual network probe designed to address these problems. We describe the results of the study and provide design implications for future tools. More importantly, we argue that tools like this can educate and empower consumers by making broadband speeds and sources of slow-downs more visible.\n",
      "226\n",
      "Practical, appropriate, empirically-validated guidelines for designing educational games\n",
      "There has recently been a great deal of interest in the potential of computer games to function as innovative educational tools. However, there is very little evidence of games fulfilling that potential. Indeed, the process of merging the disparate goals of education and games design appears problematic, and there are currently no practical guidelines for how to do so in a coherent manner. In this paper, we describe the successful, empirically validated teaching methods developed by behavioural psychologists and point out how they are uniquely suited to take advantage of the benefits that games offer to education. We conclude by proposing some practical steps for designing educational games, based on the techniques of Applied Behaviour Analysis. It is intended that this paper can both focus educational games designers on the features of games that are genuinely useful for education, and also introduce a successful form of teaching that this audience may not yet be familiar with.\n",
      "252\n",
      "Bricolage: example-based retargeting for web design\n",
      "The Web provides a corpus of design examples unparalleled in human history. However, leveraging existing designs to produce new pages is often difficult. This paper introduces the Bricolage algorithm for transferring design and content between Web pages. Bricolage employs a novel, structured-prediction technique that learns to create coherent mappings between pages by training on human-generated exemplars. The produced mappings are then used to automatically transfer the content from one page into the style and layout of another. We show that Bricolage can learn to accurately reproduce human page mappings, and that it provides a general, efficient, and automatic technique for retargeting content between a variety of real Web pages.\n",
      "266\n",
      "Oops, I did it again: mitigating repeated access control errors on facebook\n",
      "We performed a study of Facebook users to examine how they coped with limitations of the Facebook privacy settings interface. Students graduating and joining the workforce create significant problems for all but the most basic privacy settings on social networking websites. We therefore created realistic scenarios exploiting work/play boundaries that required users to specify access control policies that were impossible due to various limitations. We examined whether users were aware of these problems without being prompted, and once given feedback, what their coping strategies were. Overall, we found that simply alerting participants to potential errors was ineffective, but when choices were also presented, participants introduced significantly fewer errors. Based on our findings, we designed a privacy settings interface based on Venn diagrams, which we validated with a usability study. We conclude that this interface may be more effective than the current privacy settings interface.\n",
      "272\n",
      "Target assistance for subtly balancing competitive play\n",
      "In games where skills such as targeting are critical to winning, it is difficult for players with different skill levels to have a competitive and engaging experience. Although several mechanisms for accommodating different skill levels have been proposed, traditional approaches can be too obvious and can change the nature of the game. For games involving aiming, we propose the use of target assistance techniques (such as area cursors, target gravity, and sticky targets) to accommodate skill imbalances. We compared three techniques in a study, and found that area cursors and target gravity significantly reduced score differential in a shooting-gallery game. Further, less skilled players reported having more fun when the techniques helped them be more competitive, and even after they learned assistance was given, felt that this form of balancing was good for group gameplay. Our results show that target assistance techniques can make target-based games more competitive for shared play.\n",
      "304\n",
      "A diary study of password usage in daily life\n",
      "While past work has examined password usage on a specific computer, web site, or organization, there is little work examining overall password usage in daily life. Through a diary study, we examine all usage of passwords, and offer some new findings based on quantitative analyses regarding how often people log in, where they log in, and how frequently people use foreign computers. Our analysis also confirms or updates existing statistics about password usage patterns. We also discuss some implications for design as well as security education.\n",
      "306\n",
      "Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations\n",
      "Whereas communication technology to connect people has long been an integral part of our everyday lives, it has only recently expanded to offer applications for dogs and dog-owners. In this paper, we present two explorative studies to understand the experiences and expectations of dog owners for communication technology to support their interaction with dogs. These studies look at two different user groups, hunters and pet owners, charting the lessons learnt from the current technology and exploring the aspects that should be taken into account when designing future applications and services. Our findings reveal that usability problems are still the dominant issue with current applications. We also suggest key design implications which can be utilized in the development of future human-dog interaction systems.\n",
      "317\n",
      "Multi-user interaction on media facades through live video on mobile devices\n",
      "The increasing number of media facades in urban spaces offers great potential for new forms of interaction especially for collaborative multi-user scenarios. In this paper, we present a way to directly interact with them through live video on mobile devices. We extend the Touch Projector interface to accommodate multiple users by showing individual content on the mobile display that would otherwise clutter the facade's canvas or distract other users. To demonstrate our concept, we built two collaborative multi-user applications: (1) painting on the facade and (2) solving a 15-puzzle. We gathered informal feedback during the ARS Electronica Festival in Linz, Austria and found that our interaction technique is (1) considered easy-to-learn, but (2) may leave users unaware of the actions of others.\n",
      "332\n",
      "Enhancing genomic learning through tabletop interaction\n",
      "We present G-nome Surfer 2.0, a tabletop interface for fostering inquiry-based learning of genomics. We conducted an experimental study with 48 participants that compared students' learning of genomic concepts using existing bioinformatics tools and using two alternative implementations of G-nome Surfer: a collaborative multi-mouse GUI and a tabletop interface. Our findings indicate that G-nome Surfer improves students' performance, reduces workload, and increases enjoyment. The comparison of tabletop and multi-mouse implementations further shows that the tabletop condition results in four educational benefits: 1) increasing physical participation, 2) encouraging reflection, 3) fostering effective collaboration, and 4) facilitating more intuitive interaction.\n",
      "360\n",
      "Motivating mobility: designing for lived motivation in stroke rehabilitation\n",
      "How to motivate and support behaviour change through design is becoming of increasing interest to the CHI community. In this paper, we present our experiences of building systems that motivate people to engage in upper limb rehabilitation exercise after stroke. We report on participatory design work with four stroke survivors to develop a holistic understanding of their motivation and rehabilitation needs, and to construct and deploy engaging interactive systems that satisfy these. We reflect on the limits of motivational theories in trying to design for the lived experience of motivation and highlight lessons learnt around: helping people articulate what motivates them; balancing work, duty, fun; supporting motivation over time; and understanding the wider social context. From these we identify design guidelines that can inform a toolkit approach to support both scalability and personalisability.\n",
      "372\n",
      "MicroMandarin: mobile language learning in context\n",
      "Learning a new language is hard, but learning to use it confidently in conversations with native speakers is even harder. From our field research with language learners, with support from Cognitive Psychology and Second Language Acquisition, we argue for the value of contextual microlearning in the many breaks spread across different places and throughout the day. We present a mobile application that supports such microlearning by leveraging the location-based service Foursquare to automatically provide contextually relevant content in the world's major cities. In an evaluation of Mandarin Chinese learning, a four-week, 23-user study spanning Beijing and Shanghai compared this contextual system to a system based on word frequency. Study sessions with the contextual version lasted half as long but occurred in twice as many places as sessions with the frequency version, suggesting a complementary relationship between the two approaches.\n",
      "387\n",
      "Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder\n",
      "In this paper we describe a co-located suite of games on a tabletop device to support social competence training for children with Autism Spectrum Disorder. This suite has been designed to use patterns of collaboration to support therapists in their use of Cognitive-Behavioral Therapy (CBT). In this paper, we discuss the observations collected during a field study where two therapists used the system for social competence training sessions with 8 children. We conclude with lessons learned from meshing software enhanced collaboration within the CBT model.\n",
      "393\n",
      "Unpacking exam-room computing: negotiating computer-use in patient-physician interactions\n",
      "The presence of computers - especially desktops - takes significant time and attention away from patients during medical visits. As a result, patients may feel disengaged and disregarded. In this study, we examined the impact of using \"Computer-on-Wheels\" (COWs) in exam-rooms. We found physicians constantly reorienting and resituating exam-room computers to different positions during the three stages of a medical visit: communication-intensive phase, lecturing phase and ordering phase. We refer to this behavior as micro-negotiation of computer-use. Analysis of its usage patterns, as well as physician and patient perceptions, show that micro-negotiations facilitate eye contact expression and encourage patient participation in medical visits. In addition, we identify two tensions and two unintended benefits resulting from micro-negotiations. These findings lead us to consider new modes of negotiation in the exam-room that could alleviate the tensions identified while enabling physicians to continue enjoying micro-negotiation benefits in their work practice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "3\n",
      "The design and evaluation of a high-performance soft keyboard\n",
      "The design and evaluation of a high performance soft keyboardfor mobile systems are described. Using a model to predict theupper-bound text entry rate for soft keyboards, we designed akeyboard layout with a predicted upper-bound entry rate of 58.2wpm. This is about 35% faster than the predicted rate for a QWERTYlayout. We compared our design (OPTI) with a QWERTY layout in alongitudinal evaluation using five participants and 20 45-minutesessions of text entry. Average entry rates for OPT1 increased from17.0 wpm initially to 44.3 wpm at session 20. The average ratesexceeded those for the QWERTY layout after the 10 session (about 4hours of practice). A regression equation (R = .997) in the form ofthe power-law of learning predicts that our upper-bound predictionwould be reach at about session 50.\n",
      "5\n",
      "Implications for a gesture design tool\n",
      "Interest in pen-based user interfaces is growing rapidly. Onepotentially useful feature of pen-based user interfaces isgestures, that is, a mark or stroke that causes a command toexecute. Unfortunately, it is difficult to design gestures that areeasy 1) for computers to recognize and 2) for humans to learn andremember. To investigate these problems, we built a prototype tooltypical fo those used for designing gesture sets. An experiment wasthen performed to gain insight into the gesture design process andto evaluate this style of tool. The experiment confirmed thatgesture design is very difficult and suggested several ways inwhich current tools can be improved. The most important improvementis to make the tools more active and provide more guidance fordesigners. This paper describes the gesture design tool, theexperiment, and its results.\n",
      "19\n",
      "Sympathetic interfaces: using a plush toy to direct synthetic characters\n",
      "We introduce the concept of a sympathetic inter$ace forcontrolling an animated synthetic character in a 3D virtualenvironment. A plush doll embedded with wireless sensors is used tomanipulate the virtual character in an iconic and intentionalmanner. The interface extends from the novel physical input devicethrough interpretation of sensor data to the behavioral brain ofthe virtual character. We discuss the design of the interface andfocus on its latest instantiation in the Swamped! exhibit atSIGGRAPH 98. We also present what we learned from hundreds ofcasual users, who ranged from young children to adults.\n",
      "73\n",
      "Mutual disambiguation of recognition errors in a multimodel architecture\n",
      "As a new generation of multimodal/media systems begins to defineitself, researchers are attempting to learn how to combinedifferent modes into strategically integrated whole systems. Intheory, well designed multimodal systems should be able tointegrate complementary modalities in a manner that supports mutualdisambiguation (MD) of errors and leads to more robust performance.In this study, over 2,000 multimodal utterances by both native andaccented speakers of English were processed by a multimodal system,and then logged and analyzed. The results confirmed that multimodalsystems can indeed support significant levels of MD, and alsohigher levels of MD for the more challenging accented users. As aresult, although speech recognition as a stand-alone performed farmore poorly for accented speakers, their multimodal recognitionrates did not differ from those of native speakers. Implicationsare discussed for the development of future multimodalarchitectures that can perform in a more robust and stable mannerthan individual recognition technologies. Also discussed is thedesign of interfaces that support diversity in tangible ways, andthat function well under challenging real-world usageconditions,\n",
      "1997\n",
      "Computational models of information scent-following in a very large browsable text collection\n",
      "An abstract is not available.\n",
      "0\n",
      "SenseMaker: an information-exploration interface supporting the contextual evolution of a user's interests\n",
      "An abstract is not available.\n",
      "1\n",
      "The design of a GUI paradigm based on tablets, two-hands, and transparency\n",
      "An abstract is not available.\n",
      "4\n",
      "An empirical evaluation of graspable user interfaces: towards specialized, space-multiplexed input\n",
      "An abstract is not available.\n",
      "5\n",
      "AROMA: abstract representation of presence supporting mutual awareness\n",
      "An abstract is not available.\n",
      "6\n",
      "Autonomous interface agents\n",
      "An abstract is not available.\n",
      "8\n",
      "How to personalize the Web\n",
      "An abstract is not available.\n",
      "9\n",
      "Aesthetics and apparent usability: empirically assessing cultural and methodological issues\n",
      "An abstract is not available.\n",
      "14\n",
      "Dynomite: a dynamically organized ink and audio notebook\n",
      "An abstract is not available.\n",
      "23\n",
      "“I'll get that off the audio”: a case study of salvaging multimedia meeting records\n",
      "An abstract is not available.\n",
      "25\n",
      "Tangible bits: towards seamless interfaces between people, bits and atoms\n",
      "An abstract is not available.\n",
      "29\n",
      "Making computers easier for older adults to use: area cursors and sticky icons\n",
      "An abstract is not available.\n",
      "33\n",
      "Beyond Fitts' law: models for trajectory-based HCI tasks\n",
      "An abstract is not available.\n",
      "37\n",
      "The Rockin'Mouse: integral 3D manipulation on a plane\n",
      "An abstract is not available.\n",
      "39\n",
      "PaperLink: a technique for hyperlinking from real paper to electronic content\n",
      "An abstract is not available.\n",
      "41\n",
      "A comparison of reading paper and on-line documents\n",
      "An abstract is not available.\n",
      "42\n",
      "Designing for or designing with? Informant design for interactive learning environments\n",
      "An abstract is not available.\n",
      "43\n",
      "The persona effect: affective impact of animated pedagogical agents\n",
      "An abstract is not available.\n",
      "45\n",
      "Effective view navigation\n",
      "An abstract is not available.\n",
      "46\n",
      "Life, death, and lawfulness on the electronic frontier\n",
      "An abstract is not available.\n",
      "48\n",
      "Revisitation patterns in World Wide Web navigation\n",
      "An abstract is not available.\n",
      "50\n",
      "Integration and synchronization of input modes during multimodal human-computer interaction\n",
      "An abstract is not available.\n",
      "52\n",
      "KidPad: a design collaboration between children, technologists, and educators\n",
      "An abstract is not available.\n",
      "58\n",
      "1995\n",
      "Interactive sketching for the early stages of user interface design\n",
      "An abstract is not available.\n",
      "5\n",
      "Information foraging in information access environments\n",
      "An abstract is not available.\n",
      "6\n",
      "TileBars: visualization of term distribution information in full text information access\n",
      "An abstract is not available.\n",
      "7\n",
      "A generic platform for addressing the multimodal challenge\n",
      "An abstract is not available.\n",
      "12\n",
      "Recommending and evaluating choices in a virtual community of use\n",
      "An abstract is not available.\n",
      "24\n",
      "Pointing the way: active collaborative filtering\n",
      "An abstract is not available.\n",
      "25\n",
      "Social information filtering: algorithms for automating “word of mouth”\n",
      "An abstract is not available.\n",
      "26\n",
      "Space-scale diagrams: understanding multiscale interfaces\n",
      "An abstract is not available.\n",
      "29\n",
      "User embodiment in collaborative virtual environments\n",
      "An abstract is not available.\n",
      "30\n",
      "Virtual reality on a WIM: interactive worlds in miniature\n",
      "An abstract is not available.\n",
      "33\n",
      "The “prince” technique: Fitts' law and selection using area cursors\n",
      "An abstract is not available.\n",
      "34\n",
      "Applying electric field sensing to human-computer interfaces\n",
      "An abstract is not available.\n",
      "35\n",
      "Designing SpeechActs: issues in speech user interfaces\n",
      "An abstract is not available.\n",
      "47\n",
      "A focus+context technique based on hyperbolic geometry for visualizing large hierarchies\n",
      "An abstract is not available.\n",
      "51\n",
      "Bricks: laying the foundations for graspable user interfaces\n",
      "An abstract is not available.\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "#审查high_cited文章\n",
    "education_keywords = ['education','learn','teach','educate','e-learning','exam','student','curriculum','course','mooc']\n",
    "for s in high_cited:\n",
    "    print (s)\n",
    "    for i in high_cited[s]:\n",
    "        #print (i)\n",
    "        title = total_article[s]['title'][i]\n",
    "        abstract = total_article[s]['abstract'][i]\n",
    "        \n",
    "        if abstract == 'null' or abstract == 'An abstract is not available.' or type(abstract) == list:\n",
    "            print (title)\n",
    "            print (abstract)\n",
    "            print (i)\n",
    "        else:\n",
    "            text = title + \" \" + abstract\n",
    "            sent = splitSentence(text) \n",
    "            word_list = []\n",
    "            for m in sent:\n",
    "                word = wordtokenizer(m)                  \n",
    "                word_list = word_list + word\n",
    "            word_standard = standardization(word_list)\n",
    "            word_ori = lemmatizer(word_standard)\n",
    "            for j in word_ori:\n",
    "                if j in education_keywords:\n",
    "                    print (i)\n",
    "                    print (title)\n",
    "                    print (abstract)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T05:42:22.944004Z",
     "start_time": "2019-11-21T05:42:22.938353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Effects of Cooperative, Competitive, and Individualistic Goal Structures on Achievement: A Meta-Analysis.'}, {'title': 'Playing together beats playing apart, especially for girls'}, {'title': 'Give and take: children collaborating on one computer'}, {'title': 'Multiplayer activities that develop mathematical coordination'}, {'title': 'Gender Differences in Loneliness'}, {'title': 'Equity issues in computer-based collaboration: looking beyond surface indicators'}, {'title': 'Cooperation versus competition in the classroom'}, {'title': 'Conceptualizing Sex as a Status Characteristic: Applications to Leadership Training Strategies.'}, {'title': 'Experimental Design: Input Device Protocols and Collaborative Learning'}]\n"
     ]
    }
   ],
   "source": [
    "print(total_reference['1997'][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T05:43:50.906895Z",
     "start_time": "2019-11-21T05:43:50.895890Z"
    }
   },
   "outputs": [],
   "source": [
    "def getReference(year, num):\n",
    "    reference = []\n",
    "    for s in total_reference[year][num]:\n",
    "        text =  splitSentence(s['text'])\n",
    "        if len(text) < 2:\n",
    "            text = s['text'].split(\", \")    \n",
    "        \n",
    "        count = 0\n",
    "        for i in text:\n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                continue\n",
    "            if len(i) > 30:\n",
    "                reference.append(i)\n",
    "                break\n",
    "    return reference\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:26:14.098186Z",
     "start_time": "2019-11-26T09:26:14.091217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "title = total_article['2016']['title'][484]\n",
    "chi_core[title] = {'position':('2016',484), 'reference': temp}\n",
    "print (len(chi_core[title]['reference']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:29:46.872001Z",
     "start_time": "2019-11-26T09:29:46.856138Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos\n",
      "Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity. Moreover, the content of comments would further affect learners' intention of commenting. Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education.\n"
     ]
    }
   ],
   "source": [
    "reference = getReference('2015',79)\n",
    "print (total_article['2015']['title'][79])\n",
    "print (total_article['2015']['abstract'][79])\n",
    "temp = []\n",
    "for s in range(len(reference)):\n",
    "    if s == 0:\n",
    "        temp.append(\"Interaction in distance education and online learning: Using evidence and theory to improve practice\")\n",
    "        continue\n",
    "    if s == 3:\n",
    "        temp.append(\"Synchronous and asynchronous communication tools in distance education\")\n",
    "        continue\n",
    "        \n",
    "    temp.append(reference[s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:29:47.062254Z",
     "start_time": "2019-11-26T09:29:47.031797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num': '1', 'text': 'Abrami, P. C., Bernard, R. M., Bures, E. M., Borokhovski, E., and Tamim, R. M. Interaction in distance education and online learning: Using evidence and theory to improve practice. Journal of Computing in Higher Education 23, 2--3 (2011), 82--103.'}\n",
      "Interaction in distance education and online learning: Using evidence and theory to improve practice\n",
      "\n",
      "\n",
      "{'num': '2', 'text': 'Ashton Anderson , Daniel Huttenlocher , Jon Kleinberg , Jure Leskovec, Engaging with massive online courses, Proceedings of the 23rd international conference on World wide web, April 07-11, 2014, Seoul, Korea 10.1145/2566486.2568042'}\n",
      "Engaging with massive online courses\n",
      "\n",
      "\n",
      "{'num': '3', 'text': 'Terry Anderson, The Theory and Practice of Online Learning, AU Press, 2009'}\n",
      "The Theory and Practice of Online Learning\n",
      "\n",
      "\n",
      "{'num': '4', 'text': 'Branon, R. F., and Essex, C. Synchronous and asynchronous communication tools in distance education. TechTrends 45, 1 (2001), 36--36.'}\n",
      "Synchronous and asynchronous communication tools in distance education\n",
      "\n",
      "\n",
      "{'num': '5', 'text': 'Bransford, J. D., Brown, A. L., and Cocking, R. R. How People Learn: Brain, Mind, Experience, and School. The National Academies Press, 2000.'}\n",
      "The National Academies Press, 2000.\n",
      "\n",
      "\n",
      "{'num': '6', 'text': 'Burnett, C. Learning to chat: Tutor participation in synchronous online chat. Teaching in higher education 8, 2 (2003), 247--261.'}\n",
      "Teaching in higher education 8, 2 (2003), 247--261.\n",
      "\n",
      "\n",
      "{'num': '7', 'text': 'Derrick Coetzee , Armando Fox , Marti A. Hearst , Bjoern Hartmann, Chatrooms in MOOCs: all talk and no action, Proceedings of the first ACM conference on Learning @ scale conference, March 04-05, 2014, Atlanta, Georgia, USA 10.1145/2556325.2566242'}\n",
      "Chatrooms in MOOCs: all talk and no action\n",
      "\n",
      "\n",
      "{'num': '8', 'text': 'Derrick Coetzee , Armando Fox , Marti A. Hearst , Björn Hartmann, Should your MOOC forum use a reputation system?, Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, February 15-19, 2014, Baltimore, Maryland, USA 10.1145/2531602.2531657'}\n",
      "Should your MOOC forum use a reputation system?\n",
      "\n",
      "\n",
      "{'num': '9', 'text': 'Andrew Cross , Mydhili Bayyapunedi , Dilip Ravindran , Edward Cutrell , William Thies, VidWiki: enabling the crowd to improve the legibility of online educational videos, Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, February 15-19, 2014, Baltimore, Maryland, USA 10.1145/2531602.2531670'}\n",
      "VidWiki: enabling the crowd to improve the legibility of online educational videos\n",
      "\n",
      "\n",
      "{'num': '10', 'text': 'Dixson, M. D. Creating effective student engagement in online courses: What do students find engaging? JoSoTL 10, 2 (2010).'}\n",
      "The use of online synchronous discussion groups to enhance community formation and professional identity development.\n",
      "\n",
      "\n",
      "{'num': '11', 'text': 'Duemer, L., Fontenot, D., Gumfory, K., Kallus, M., Larsen, J., Schafer, S., and Shaw, B. The use of online synchronous discussion groups to enhance community formation and professional identity development. Journal of Interactive Online Learning 1, 2 (2002), 1--12.'}\n",
      "Proceedings of the 21st annual ACM symposium on User interface software and technology\n",
      "\n",
      "\n",
      "{'num': '12', 'text': 'Dan B. Goldman , Chris Gonterman , Brian Curless , David Salesin , Steven M. Seitz, Video object annotation, navigation, and composition, Proceedings of the 21st annual ACM symposium on User interface software and technology, October 19-22, 2008, Monterey, CA, USA 10.1145/1449715.1449719'}\n",
      "Sociological theory 1 (1983), 201--233.\n",
      "\n",
      "\n",
      "{'num': '13', 'text': 'Granovetter, M. The strength of weak ties: A network theory revisited. Sociological theory 1 (1983), 201--233.'}\n",
      "Bulterman, \"Let me comment on your video\": supporting personalized end-user comments within third-party online videos, Proceedings of the 18th Brazilian symposium on Multimedia and the web, October 15-18, 2012, São Paulo/SP, Brazil 10.1145/2382636.2382690\n",
      "\n",
      "\n",
      "{'num': '14', 'text': 'Rodrigo Laiola Guimarães , Pablo Cesar , Dick C.A. Bulterman, \"Let me comment on your video\": supporting personalized end-user comments within third-party online videos, Proceedings of the 18th Brazilian symposium on Multimedia and the web, October 15-18, 2012, São Paulo/SP, Brazil 10.1145/2382636.2382690'}\n",
      "How video production affects student engagement: an empirical study of MOOC videos\n",
      "\n",
      "\n",
      "{'num': '15', 'text': 'Philip J. Guo , Juho Kim , Rob Rubin, How video production affects student engagement: an empirical study of MOOC videos, Proceedings of the first ACM conference on Learning @ scale conference, March 04-05, 2014, Atlanta, Georgia, USA 10.1145/2556325.2566239'}\n",
      "Effective discussion through a computer-mediated anchored forum.\n",
      "\n",
      "\n",
      "{'num': '16', 'text': 'Guzdial, M., and Turns, J. Effective discussion through a computer-mediated anchored forum. The journal of the learning sciences 9, 4 (2000), 437--469.'}\n",
      "Streaming on twitch: fostering participatory communities of play within live mixed media\n",
      "\n",
      "\n",
      "{'num': '17', 'text': 'William A. Hamilton , Oliver Garretson , Andruid Kerne, Streaming on twitch: fostering participatory communities of play within live mixed media, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada 10.1145/2556288.2557048'}\n",
      "Superposter behavior in MOOC forums\n",
      "\n",
      "\n",
      "{'num': '18', 'text': 'Jonathan Huang , Anirban Dasgupta , Arpita Ghosh , Jane Manning , Marc Sanders, Superposter behavior in MOOC forums, Proceedings of the first ACM conference on Learning @ scale conference, March 04-05, 2014, Atlanta, Georgia, USA 10.1145/2556325.2566249'}\n",
      "Attitude toward instructional technology following required versus optional WebCT usage.\n",
      "\n",
      "\n",
      "{'num': '19', 'text': 'Johnson, G., and Howell, A. Attitude toward instructional technology following required versus optional WebCT usage. Journal of Technology and Teacher Education 13, 4 (2005), 643--654.'}\n",
      "TechTrends 50, 4 (2006), 46--53.\n",
      "\n",
      "\n",
      "{'num': '20', 'text': 'Johnson, G. M. Synchronous and asynchronous text-based CMC in educational contexts: A review of recent research. TechTrends 50, 4 (2006), 46--53.'}\n",
      "Showing face in video instruction: effects on information retention\n",
      "\n",
      "\n",
      "{'num': '21', 'text': 'René F. Kizilcec , Kathryn Papadopoulos , Lalida Sritanyaratana, Showing face in video instruction: effects on information retention, visual attention, and affect, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 26-May 01, 2014, Toronto, Ontario, Canada 10.1145/2556288.2557207'}\n",
      "Differences in learning outcomes for the online and F2F versions of \"an introduction to shakespeare\".\n",
      "\n",
      "\n",
      "{'num': '22', 'text': 'Koory, M. A. Differences in learning outcomes for the online and F2F versions of \"an introduction to shakespeare\". Journal of Asynchronous Learning Networks 7, 2 (2003), 18--35.'}\n",
      "Will massive open online courses change how we teach?\n",
      "\n",
      "\n",
      "{'num': '23', 'text': 'Fred G. Martin, Will massive open online courses change how we teach?, Communications of the ACM, v.55 n.8, August 2012 10.1145/2240236.2240246'}\n",
      "The development and evaluation of a survey to measure user engagement\n",
      "\n",
      "\n",
      "{'num': '24', 'text': \"Heather L. O'Brien , Elaine G. Toms, The development and evaluation of a survey to measure user engagement, Journal of the American Society for Information Science and Technology, v.61 n.1, p.50-69, January 2010 10.1002/asi.v61:1\"}\n",
      ": the case of the user engagement scale, Proceedings of the third symposium on Information interaction in context, August 18-21, 2010, New Brunswick, New Jersey, USA 10.1145/1840784.1840835\n",
      "\n",
      "\n",
      "{'num': '25', 'text': \"Heather L. O'Brien , Elaine G. Toms, Is there a universal instrument for measuring interactive information retrieval?: the case of the user engagement scale, Proceedings of the third symposium on Information interaction in context, August 18-21, 2010, New Brunswick, New Jersey, USA 10.1145/1840784.1840835\"}\n",
      "Exploring asynchronous and synchronous tool use in online courses\n",
      "\n",
      "\n",
      "{'num': '26', 'text': 'Murat Oztok , Daniel Zingaro , Clare Brett , Jim Hewitt, Exploring asynchronous and synchronous tool use in online courses, Computers & Education, v.60 n.1, p.87-94, January, 2013 10.1016/j.compedu.2012.08.007'}\n",
      "Computer mediated communication, 397--431.\n",
      "\n",
      "\n",
      "{'num': '27', 'text': 'Romiszowski, A., and Mason, R. Handbook of research for educational communications and technology, 2 ed. Taylor & Francis, 2004, ch. Computer mediated communication, 397--431.'}\n",
      "The affordance of anchored discussion for the collaborative processing of academic texts.\n",
      "\n",
      "\n",
      "{'num': '28', 'text': 'van der Pol, J., Admiraal, W., and Simons, P. R.-J. The affordance of anchored discussion for the collaborative processing of academic texts. International Journal of Computer-Supported Collaborative Learning 1, 3 (2006), 339--357.'}\n",
      "Harvard university press, 1980.\n",
      "\n",
      "\n",
      "{'num': '29', 'text': 'Vygotsky, L. S. Mind in society: The development of higher psychological processes. Harvard university press, 1980.'}\n",
      "Introducing group-based asynchronous learning to business education.\n",
      "\n",
      "\n",
      "{'num': '30', 'text': 'Walker, R., and Arnold, I. Introducing group-based asynchronous learning to business education. reflections on effective course design and delivery. Educational media international 41, 3 (2004), 253--265.'}\n",
      "Watching together: integrating text chat with video\n",
      "\n",
      "\n",
      "{'num': '31', 'text': 'Justin D. Weisz , Sara Kiesler , Hui Zhang , Yuqing Ren , Robert E. Kraut , Joseph A. Konstan, Watching together: integrating text chat with video, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 28-May 03, 2007, San Jose, California, USA 10.1145/1240624.1240756'}\n",
      "In IEEE International Conference on Collaboration Technologies and Systems (2011), 569--578.\n",
      "\n",
      "\n",
      "{'num': '32', 'text': 'Zhang, S., Jiang, H., and Carroll, J. M. Integrating online and offline community through facebook. In IEEE International Conference on Collaboration Technologies and Systems (2011), 569--578.'}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-882-b931756932e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2015'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_reference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2015'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for s in range(len(total_reference['2015'][79])):\n",
    "    print (total_reference['2015'][79][s])\n",
    "    print (temp[s])\n",
    "    print ('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T08:32:58.235245Z",
     "start_time": "2019-11-26T08:32:58.218122Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-814-922210914f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal_reference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1997'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for s in total_reference['1997'][15]:\n",
    "    temp.append(s['title'])\n",
    "print (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T01:53:25.778523Z",
     "start_time": "2019-11-26T01:53:25.766121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (len(gi_core))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save&Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:06:27.642047Z",
     "start_time": "2019-11-26T09:06:27.634331Z"
    }
   },
   "outputs": [],
   "source": [
    "def saveData(dis_core, string):\n",
    "    import codecs\n",
    "              \n",
    "    f = codecs.open('/home/lr/Downloads/conference_data/' + string + '.txt', 'w', 'utf-8')\n",
    "    f.write(str(dis_core))\n",
    "    f.close() \n",
    "    \n",
    "    \n",
    "saveData(chi_core,'chi_core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T09:24:31.049936Z",
     "start_time": "2019-11-20T09:24:31.038282Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadData(string):    \n",
    "    f = open('/home/lr/Downloads/conference_data/' + string + '.txt','r')\n",
    "    sample = f.readlines()\n",
    "\n",
    "    dict_finallis_keyword = eval(sample[0])\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    return dict_finallis_keyword\n",
    "ls_core = loadData('ls_core')\n",
    "dis_core = loadData('dis_core')\n",
    "mobilechi_core = loadData('mobilechi_core')\n",
    "assets_core = loadData('assets_core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:06:35.511663Z",
     "start_time": "2019-11-26T09:06:35.505745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print (len(chi_core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
