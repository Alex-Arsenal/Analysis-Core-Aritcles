{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:58:49.617869Z",
     "start_time": "2020-01-20T09:58:49.609290Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadCoreArticle(string):    \n",
    "    f = open('/home/lr/Downloads/conference_data/' + string + '.txt','r')\n",
    "    sample = f.readlines()\n",
    "\n",
    "    dict_finallis_keyword = eval(sample[0])\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    return dict_finallis_keyword\n",
    "\"\"\"\n",
    "tochi_core = loadCoreArticle('tochi_core')\n",
    "avi_core = loadCoreArticle('avi_core')\n",
    "icmi_core = loadCoreArticle('icmi_core')\n",
    "gi_core = loadCoreArticle('gi_core')\n",
    "chi_core = loadCoreArticle('chi_core')\n",
    "idc_core = loadCoreArticle('idc_core')\n",
    "lak_review = loadCoreArticle('lak_review')\n",
    "\"\"\"\n",
    "\n",
    "cof = ['assets','avi','chi','cscw','dis','gi','group','icmi','idc','its','iui','lak','ls','mobilechi','tochi','ubicomp','uist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:58:50.008968Z",
     "start_time": "2020-01-20T09:58:49.970187Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "title_list = []\n",
    "reference_list = {}\n",
    "for s in cof:\n",
    "    name = s + \"_core\"\n",
    "    \n",
    "    data = loadCoreArticle(name)\n",
    "    #print (s)\n",
    "    #print (len(data))\n",
    "    title_list.extend(list(data.keys()))\n",
    "    for i in data:\n",
    "        reference_list[i] = copy.deepcopy(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:58:50.525854Z",
     "start_time": "2020-01-20T09:58:50.519556Z"
    }
   },
   "outputs": [],
   "source": [
    "title_list[8] = \": designing a new class of computational toys\"\n",
    "reference_list[title_list[8]] = reference_list['curlybot: designing a new class of computational toys']\n",
    "title_list[16] = \": Haptic Feedback to Enhance Early Reading\"\n",
    "reference_list[title_list[16]] = reference_list['FeelSleeve: Haptic Feedback to Enhance Early Reading']\n",
    "title_list[32] = \": The Effects of Curriculum-Aligned Making on Children's Self-Identity\"\n",
    "reference_list[title_list[32]] = reference_list[\"I Make, Therefor I Am: The Effects of Curriculum-Aligned Making on Children's Self-Identity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:58:53.552953Z",
     "start_time": "2020-01-20T09:58:50.906818Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "#获取数据\n",
    "from elasticsearch import helpers\n",
    "import elasticsearch\n",
    "\n",
    "\n",
    "total_text = {}\n",
    "total_bibliometrics = {}\n",
    "total_index_term = {}\n",
    "total_reference = {}\n",
    "total_author = {}\n",
    "article_author = {}\n",
    "total_article = {}\n",
    "total_id = {}\n",
    "total_conf = {}\n",
    "total_year = {}\n",
    "\n",
    "ES_SERVERS = [{\n",
    "    # 'host': 'localhost',\n",
    "    'host': '127.0.0.1',\n",
    "    'port': 9200\n",
    "}]\n",
    "\n",
    "es_client = elasticsearch.Elasticsearch(\n",
    "    hosts=ES_SERVERS\n",
    ")\n",
    "\n",
    "es_result = helpers.scan(\n",
    "    client=es_client,\n",
    "    query={\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "},\n",
    "    scroll='5m',\n",
    "    index='conference_total',\n",
    "    #doc_type='conference_total',\n",
    "    # timeout='1m'\n",
    ")\n",
    "# print(len(es_result))\n",
    "\n",
    "#h_heads=[]\n",
    "cont=0\n",
    "for i in es_result:\n",
    "    data_year = i['_source']\n",
    "    h_head = i['_source']['h_head']\n",
    "    id_num = i['_id']\n",
    "    year = data_year['h_year']\n",
    "    if year not in total_article.keys():\n",
    "        total_article[year] = {'title':[], 'abstract':[]}\n",
    "    #if 'group' not in data_year.keys():\n",
    "        #print (h_head)\n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "           \n",
    "    author = data_year['author']\n",
    "    #reference = data_year['reference']\n",
    "    index_term = data_year['index_term']\n",
    "    bibliometrics = data_year['citition']\n",
    "    title = data_year['title']\n",
    "    abstract = data_year['abstract']\n",
    "    if title not in title_list:\n",
    "        continue\n",
    "        \n",
    "    #if title == \"StudentLife: assessing mental health, academic performance and behavioral trends of college students using smartphones\":\n",
    "        #print (bibliometrics)\n",
    "        #print (cont)\n",
    "        \n",
    "    #print (title)\n",
    "    #print (cont)\n",
    "    #print (id_num)\n",
    "    cont += 1 \n",
    "    total_id.setdefault(year,[]).append(id_num)\n",
    "    total_bibliometrics.setdefault(year,[]).append(bibliometrics)\n",
    "    total_reference.setdefault(year,[]).append(reference_list[title])\n",
    "    total_index_term.setdefault(year,[]).append(index_term)\n",
    "    total_article[year]['title'].append(title)\n",
    "    total_article[year]['abstract'].append(abstract)\n",
    "    article_author.setdefault(year,[]).append(author)\n",
    "    total_conf.setdefault(year,[]).append(h_head)\n",
    " \n",
    "\n",
    "    \n",
    "author_data = article_author\n",
    "print (cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比共同作者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:46:07.618442Z",
     "start_time": "2020-01-20T06:46:07.520381Z"
    },
    "code_folding": [
     4,
     9,
     15
    ]
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#初始化列表\n",
    "num_same_author = {}\n",
    "single = {}\n",
    "for s in author_data:\n",
    "    #print (len(author_data[s]))\n",
    "    single[s] = [0] * len(author_data[s])\n",
    "#print (single)\n",
    "\n",
    "for s in author_data:\n",
    "    for i in author_data[s]:\n",
    "        num_same_author.setdefault(s,[]).append(copy.deepcopy(single))\n",
    "        \n",
    "#print (num_same_author)\n",
    "\n",
    "for s in author_data:\n",
    "    count = 0\n",
    "    for i in author_data[s]:\n",
    "        for j in i:\n",
    "            name1 = j['name']       \n",
    "            \n",
    "            for m in author_data:\n",
    "                temp = -1\n",
    "                for n in author_data[m]:\n",
    "                    temp += 1\n",
    "                    for o in n:\n",
    "                        name2 = o['name']\n",
    "                        \n",
    "                        if name1 == name2:\n",
    "                            num_same_author[s][count][m][temp] += 1\n",
    "                            \n",
    "                           \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比共同标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:46:08.568209Z",
     "start_time": "2020-01-20T06:46:08.487824Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#初始化列表\n",
    "num_same_index = {}\n",
    "single = {}\n",
    "for s in author_data:\n",
    "    #print (len(author_data[s]))\n",
    "    single[s] = [0] * len(author_data[s])\n",
    "#print (single)\n",
    "\n",
    "for s in author_data:\n",
    "    for i in author_data[s]:\n",
    "        num_same_index.setdefault(s,[]).append(copy.deepcopy(single))\n",
    "        \n",
    "for s in total_index_term:\n",
    "    count = 0\n",
    "    for i in total_index_term[s]:\n",
    "        #print (i)\n",
    "        for j in i:    \n",
    "            \n",
    "            for m in total_index_term:\n",
    "                temp = -1\n",
    "                for n in total_index_term[m]:\n",
    "                    temp += 1\n",
    "                    for o in n:                        \n",
    "                        if j == o:\n",
    "                            num_same_index[s][count][m][temp] += 1\n",
    "                            \n",
    "                           \n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比共同关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:43:54.628202Z",
     "start_time": "2020-01-21T03:43:54.602011Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, WordPunctTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "#设置stopwords，缩略词拆解\n",
    "\n",
    "stopwords = set (stopwords.words('english')+list(punctuation)+[').'])\n",
    "\n",
    "\n",
    "#分段成句和分句成词\n",
    "def splitSentence(paragraph):\n",
    "    sent = sent_tokenize(paragraph)\n",
    "    return sent\n",
    "\n",
    "\n",
    "def wordtokenizer(sentence):\n",
    "    word = []\n",
    "    words = WordPunctTokenizer().tokenize(sentence)\n",
    "    word = word + words\n",
    "    return word\n",
    "\n",
    "#文章预处理\n",
    "def standardization(word_sent):\n",
    "#转换为小写字母    \n",
    "    text = []\n",
    "    for s in word_sent:\n",
    "        text.append(s.lower())\n",
    "    \n",
    "    return text\n",
    "\n",
    "#词形还原\n",
    "def lemmatizer(word):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = []\n",
    "#对单词类型标注\n",
    "    text_tag = np.array(nltk.pos_tag(word))\n",
    "    #print (text_tag)\n",
    "    \n",
    "    for s in text_tag:\n",
    "        if s[1].startswith('N'):\n",
    "            if s[1] == 'NNS' or s[1] == 'NN':\n",
    "                text.append(wnl.lemmatize(s[0],'n'))\n",
    "            else:\n",
    "                text.append(s[0])\n",
    "        elif s[1].startswith('V'):\n",
    "            text.append(wnl.lemmatize(s[0], 'v'))\n",
    "        elif s[1].startswith('J'):\n",
    "            text.append(wnl.lemmatize(s[0], 'a'))\n",
    "        elif s[1].startswith('R'):\n",
    "            text.append(wnl.lemmatize(s[0], 'r'))\n",
    "        else:\n",
    "            text.append(s[0])\n",
    "            \n",
    "    #print (text)\n",
    "    new_text = [word for word in text if word not in stopwords and 3<len(word)]\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "def filtrated(word):\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = []\n",
    "#对单词类型标注\n",
    "    text_tag = np.array(nltk.pos_tag(word))\n",
    "    #print (text_tag)\n",
    "    \n",
    "    for s in text_tag:\n",
    "        if s[1].startswith('N'):            \n",
    "            text.append(s[0])\n",
    "        \n",
    "    \n",
    "    return text\n",
    "\n",
    "#统计词频\n",
    "def wordFreq(word):\n",
    "    word_Freq = {}\n",
    "    for s in word:\n",
    "        if not s in word_Freq:\n",
    "            word_Freq[s] = 1\n",
    "        else:\n",
    "            word_Freq[s] += 1\n",
    "    \n",
    "    num = 0\n",
    "    for key,value in word_Freq.items():\n",
    "        num = num + value\n",
    "    \n",
    "    return word_Freq, num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:43:56.792923Z",
     "start_time": "2020-01-21T03:43:56.786749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017', '2016', '2015', '2014', '2013', '2012', '2011', '2008', '2006', '2010', '2004', '2009', '2000', '2018', '2005', '2001', '2007', '1998', '1997']\n"
     ]
    }
   ],
   "source": [
    "year_list = []\n",
    "for s in total_bibliometrics:\n",
    "    year_list.append(s)\n",
    "print (year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:36:01.691749Z",
     "start_time": "2020-01-21T05:36:00.072741Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#1st提取关键词\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "education_keywords = ['education','learn','teach','educate','exam','classroom','student','curriculum','course','school','campus','college']\n",
    "online_learning = ['online','mooc']\n",
    "stem = ['program','app','programming']\n",
    "interface = ['interface','interact','interaction','agent','tangible']\n",
    "\n",
    "keyword_sum = {}\n",
    "count = 0\n",
    "for s in year_list:\n",
    "    for i in range(len(total_article[s]['title'])):\n",
    "        if total_article[s]['abstract'][i] != []:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i] + \" \" + total_article[s]['abstract'][i]\n",
    "        else:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i]\n",
    "            \n",
    "        sent = splitSentence(text) \n",
    "        \n",
    "        word_list = []\n",
    "        for m in sent:\n",
    "            word = wordtokenizer(m)                  \n",
    "            word_list = word_list + word\n",
    "        #print (word_list)\n",
    "        word_standard = standardization(word_list)\n",
    "        #print (word_standard)\n",
    "        word_ori = lemmatizer(word_standard)\n",
    "        \n",
    "        single = filtrated(word_ori)\n",
    "        word_Freq, num = wordFreq(single)\n",
    "        \n",
    "        temp = []\n",
    "        #print (word_Freq)\n",
    "        \n",
    "        group_count = {'online': 0,'stem':0,'interface':0,'student':0}\n",
    "        for j in word_Freq:\n",
    "            if word_Freq[j] > 1 and j not in education_keywords:\n",
    "                for m in range(word_Freq[j]):\n",
    "                    temp.append(j)\n",
    "\n",
    "        \"\"\"\n",
    "        if max(group_count, key = group_count.get) == 'student' and group_count['student'] == 1:\n",
    "            #print (count)\n",
    "            if count in high_cited:\n",
    "                temp = ['student'] * 20\n",
    "            else:                \n",
    "                temp.append('student')\"\"\"\n",
    "        \"\"\"elif max(group_count, key = group_count.get) == 'online' and group_count['online'] > 0:\n",
    "            temp = ['online'] * group_count['online']\n",
    "        elif max(group_count, key = group_count.get) == 'stem' and group_count['stem'] > 0:\n",
    "            temp = ['stem'] * group_count['stem']\n",
    "        elif max(group_count, key = group_count.get) == 'interface' and group_count['interface'] > 0:\n",
    "            temp = ['interface'] * group_count['interface']\n",
    "        else:\n",
    "            temp = []\"\"\"\n",
    "        #print (total_article[s]['title'][i])\n",
    "        #if total_article[s]['title'][i] == \"To block or not to block, that is the question: students' perceptions of blocks-based programming\":\n",
    "            #print (temp)\n",
    "            \n",
    "        \n",
    "        keyword_sum.setdefault(s,[]).append(temp)\n",
    "        #print (temp)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:46:18.569106Z",
     "start_time": "2020-01-20T06:46:17.184736Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_cited' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-82c820c028b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mgroup_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interface'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhigh_cited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_Freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                             \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interface\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_cited' is not defined"
     ]
    }
   ],
   "source": [
    "#提取关键词\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "education_keywords = ['education','learn','teach','educate','exam','classroom','student','curriculum','course','school','campus','college']\n",
    "online_learning = ['online','mooc']\n",
    "stem = ['program','app','programming']\n",
    "interface = ['interface','interact','interaction','agent','tangible']\n",
    "\n",
    "keyword_sum = {}\n",
    "count = 0\n",
    "for s in year_list:\n",
    "    for i in range(len(total_article[s]['title'])):\n",
    "        if total_article[s]['abstract'][i] != []:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i] + \" \" + total_article[s]['abstract'][i]\n",
    "        else:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i]\n",
    "            \n",
    "        sent = splitSentence(text) \n",
    "        \n",
    "        word_list = []\n",
    "        for m in sent:\n",
    "            word = wordtokenizer(m)                  \n",
    "            word_list = word_list + word\n",
    "        #print (word_list)\n",
    "        word_standard = standardization(word_list)\n",
    "        #print (word_standard)\n",
    "        word_ori = lemmatizer(word_standard)\n",
    "        \n",
    "        single = filtrated(word_ori)\n",
    "        word_Freq, num = wordFreq(single)\n",
    "        \n",
    "        temp = []\n",
    "        #print (word_Freq)\n",
    "        \n",
    "        group_count = {'online': 0,'stem':0,'interface':0,'student':0}\n",
    "        for j in word_Freq:\n",
    "            if word_Freq[j] > 1 and j not in education_keywords:\n",
    "                if j in online_learning:\n",
    "                    group_count['online'] += 1\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(j)\n",
    "                if j in stem:\n",
    "                    group_count['stem'] += 1\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(j)\n",
    "                if j in interface:\n",
    "                    group_count['interface'] += 1\n",
    "                    if count in high_cited:\n",
    "                        for m in range(word_Freq[j]*20):\n",
    "                            temp.append(\"interface\")\n",
    "                    else:\n",
    "                        for m in range(word_Freq[j]):\n",
    "                            temp.append(\"interface\")\n",
    "                else:\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(j)\n",
    "                        \n",
    "            if j == 'student':\n",
    "                group_count['student'] = 1\n",
    "        \"\"\"\n",
    "        if max(group_count, key = group_count.get) == 'student' and group_count['student'] == 1:\n",
    "            #print (count)\n",
    "            if count in high_cited:\n",
    "                temp = ['student'] * 20\n",
    "            else:                \n",
    "                temp.append('student')\"\"\"\n",
    "        \"\"\"elif max(group_count, key = group_count.get) == 'online' and group_count['online'] > 0:\n",
    "            temp = ['online'] * group_count['online']\n",
    "        elif max(group_count, key = group_count.get) == 'stem' and group_count['stem'] > 0:\n",
    "            temp = ['stem'] * group_count['stem']\n",
    "        elif max(group_count, key = group_count.get) == 'interface' and group_count['interface'] > 0:\n",
    "            temp = ['interface'] * group_count['interface']\n",
    "        else:\n",
    "            temp = []\"\"\"\n",
    "        #print (total_article[s]['title'][i])\n",
    "        #if total_article[s]['title'][i] == \"To block or not to block, that is the question: students' perceptions of blocks-based programming\":\n",
    "            #print (temp)\n",
    "            \n",
    "        \n",
    "        keyword_sum.setdefault(s,[]).append(temp)\n",
    "        #print (temp)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:44.696699Z",
     "start_time": "2020-01-21T06:07:43.046196Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'online': 0, 'stem': 0, 'student': 1, 'interface': 0}\n",
      "['analytics', 'analytics', 'analytics', 'analytics', 'analytics', 'data', 'data', 'data', 'data', 'data', 'mining', 'mining', 'mining', 'mining', 'towards', 'towards', 'communication', 'communication', 'communication', 'collaboration', 'collaboration', 'collaboration', 'increase', 'increase', 'research', 'research', 'research', 'method', 'method', 'community', 'community', 'student']\n"
     ]
    }
   ],
   "source": [
    "#final提取关键词\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "education_keywords = ['education','learn','teach','educate','exam','classroom','student','curriculum','course','school','campus','college']\n",
    "online_learning = ['online','mooc']\n",
    "stem = ['program','app','programming']\n",
    "interface = ['interface','interact','interaction','agent','tangible']\n",
    "student = ['mining','student','learner']\n",
    "keyword_sum = {}\n",
    "count = 0\n",
    "for s in year_list:\n",
    "    for i in range(len(total_article[s]['title'])):\n",
    "        if total_article[s]['abstract'][i] != []:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i] + \" \" + total_article[s]['abstract'][i]\n",
    "        else:\n",
    "            text = total_article[s]['title'][i] + ' ' + total_article[s]['title'][i]\n",
    "            \n",
    "        sent = splitSentence(text) \n",
    "        \n",
    "        word_list = []\n",
    "        for m in sent:\n",
    "            word = wordtokenizer(m)                  \n",
    "            word_list = word_list + word\n",
    "        #print (word_list)\n",
    "        word_standard = standardization(word_list)\n",
    "        #print (word_standard)\n",
    "        word_ori = lemmatizer(word_standard)\n",
    "        \n",
    "        single = filtrated(word_ori)\n",
    "        word_Freq, num = wordFreq(single)\n",
    "        \n",
    "        temp = []\n",
    "        #print (word_Freq)\n",
    "        #if total_article[s]['title'][i] == \"SmartGPA: how smartphones can assess and predict academic performance of college students\":\n",
    "            #print (single)\n",
    "        group_count = {'online': 0,'stem':0,'student':0,'interface':0}\n",
    "        for j in word_Freq:\n",
    "            if word_Freq[j] > 1 and j not in education_keywords:\n",
    "                if j in online_learning:\n",
    "                    group_count['online'] += 1\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(\"online\")\n",
    "                if j in stem:\n",
    "                    group_count['stem'] += 1\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(\"stem\")\n",
    "                if j in interface:\n",
    "                    group_count['interface'] += 1\n",
    "                    if count in high_cited:\n",
    "                        for m in range(word_Freq[j]*8):\n",
    "                            temp.append(\"interface\")\n",
    "                    else:\n",
    "                        for m in range(word_Freq[j]):\n",
    "                            temp.append(\"interface\")\n",
    "                else:\n",
    "                    for m in range(word_Freq[j]):\n",
    "                        temp.append(j)\n",
    "                        \n",
    "            if j in student:\n",
    "                group_count['student'] = 1\n",
    "            elif j in online_learning:\n",
    "                group_count['online'] += 1\n",
    "            elif j in stem:\n",
    "                group_count['stem'] += 1\n",
    "            elif j in interface:\n",
    "                group_count['interface'] += 1\n",
    "                \n",
    "        if max(group_count, key = group_count.get) == 'student' and group_count['student'] == 1:\n",
    "            #print (count)\n",
    "            if count in high_cited:\n",
    "                temp = ['student'] * 20\n",
    "            else:                \n",
    "                temp.append('student')\n",
    "        elif max(group_count, key = group_count.get) == 'online' and group_count['online'] > 0:\n",
    "            if count in high_cited:\n",
    "                temp = ['online'] * 20\n",
    "            else:\n",
    "                temp.append('online')\n",
    "        elif max(group_count, key = group_count.get) == 'stem' and group_count['stem'] > 0:\n",
    "            if count in high_cited:\n",
    "                temp = ['stem'] * 20  \n",
    "            else:\n",
    "                temp.append('stem')\n",
    "        elif max(group_count, key = group_count.get) == 'interface' and group_count['interface'] > 0:\n",
    "            if count in high_cited:\n",
    "                temp = ['interface'] * 20\n",
    "            else:\n",
    "                temp.append('interface')\n",
    "        \n",
    "            \n",
    "        #print (total_article[s]['title'][i])\n",
    "        if total_article[s]['title'][i] == \"Learning analytics and educational data mining: towards communication and collaboration\":\n",
    "            print (group_count)\n",
    "            print (temp)\n",
    "            \n",
    "        \n",
    "        keyword_sum.setdefault(s,[]).append(temp)\n",
    "        #print (temp)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:46.409181Z",
     "start_time": "2020-01-21T06:07:45.193992Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#初始化列表\n",
    "num_same_keyword = {}\n",
    "single = {}\n",
    "for s in author_data:\n",
    "    #print (len(author_data[s]))\n",
    "    single[s] = [0] * len(author_data[s])\n",
    "#print (single)\n",
    "\n",
    "for s in author_data:\n",
    "    for i in author_data[s]:\n",
    "        num_same_keyword.setdefault(s,[]).append(copy.deepcopy(single))\n",
    "        \n",
    "for s in keyword_sum:\n",
    "    count = 0\n",
    "    for i in keyword_sum[s]:\n",
    "        for j in i:    \n",
    "            \n",
    "            for m in keyword_sum:\n",
    "                temp = -1\n",
    "                for n in keyword_sum[m]:\n",
    "                    temp += 1\n",
    "                    for o in n:                        \n",
    "                        if j == o:\n",
    "                            num_same_keyword[s][count][m][temp] += 1\n",
    "                            break\n",
    "                            \n",
    "                           \n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比共同参考文献"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:49.635703Z",
     "start_time": "2020-01-21T06:07:48.014833Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#初始化列表\n",
    "num_same_ref = {}\n",
    "single = {}\n",
    "for s in author_data:\n",
    "    #print (len(author_data[s]))\n",
    "    single[s] = [0] * len(author_data[s])\n",
    "#print (single)\n",
    "\n",
    "for s in author_data:\n",
    "    for i in author_data[s]:\n",
    "        num_same_ref.setdefault(s,[]).append(copy.deepcopy(single))\n",
    "        \n",
    "\n",
    "for s in total_reference:\n",
    "    count = 0\n",
    "    for i in total_reference[s]:\n",
    "        #print (i)\n",
    "        for j in i['reference']:    \n",
    "            \n",
    "            for m in total_reference:\n",
    "                temp = -1\n",
    "                for n in total_reference[m]:\n",
    "                    temp += 1\n",
    "                    for o in n['reference']:                        \n",
    "                        if j == o:\n",
    "                            num_same_ref[s][count][m][temp] += 1\n",
    "                            break\n",
    "                            \n",
    "                           \n",
    "        count += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 引用网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:49:51.440231Z",
     "start_time": "2020-01-20T11:49:49.879423Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5157\n"
     ]
    }
   ],
   "source": [
    "node_list = []\n",
    "count = 0\n",
    "total_year = {}\n",
    "for s in total_reference:\n",
    "    for i in total_reference[s]:\n",
    "        #print (i)\n",
    "        total_year[count] = s\n",
    "        for j in i['reference']:    \n",
    "            \n",
    "            for m in total_reference:\n",
    "                temp = -1\n",
    "                for n in total_reference[m]:\n",
    "                    temp += 1\n",
    "                    for o in n['reference']:                        \n",
    "                        if j == o:\n",
    "                            node_list.append(j)\n",
    "                            break\n",
    "                            \n",
    "                           \n",
    "        count += 1\n",
    "        \n",
    "node_list = list(set(node_list))\n",
    "print (len(node_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:52:35.463897Z",
     "start_time": "2020-01-21T01:52:34.097286Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2016\n",
      "2015\n",
      "2014\n",
      "2013\n",
      "2012\n",
      "2011\n",
      "2008\n",
      "2006\n",
      "2010\n",
      "2004\n",
      "2009\n",
      "2000\n",
      "2018\n",
      "2005\n",
      "2001\n",
      "2007\n",
      "1998\n",
      "1997\n"
     ]
    }
   ],
   "source": [
    "count_id = {}\n",
    "total = 0\n",
    "for s in total_reference:\n",
    "    #print (s)\n",
    "    #print (total_reference[s])\n",
    "    for i in total_reference[s]:\n",
    "        #print (i)\n",
    "        for j in i['reference']:\n",
    "            #print (i)\n",
    "            count = 200\n",
    "            for m in node_list:\n",
    "                if j == m:\n",
    "                    count_id.setdefault(count,[]).append(total)\n",
    "                    break\n",
    "                count += 1\n",
    "                \n",
    "        total += 1\n",
    "\n",
    "            \n",
    "for s in count_id:\n",
    "    count_id[s] = list(set(count_id[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for s in total_reference:\n",
    "    for i in range(len(total_reference[s])):\n",
    "        if total == \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:52:48.786480Z",
     "start_time": "2020-01-21T01:52:48.775328Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "core_citing = {}\n",
    "for s in count_id:\n",
    "    #print (s)\n",
    "    #print (count_id[s])\n",
    "    for i in count_id[s]:\n",
    "        core_citing.setdefault(i,[]).append(s)\n",
    "        \n",
    "print (len(core_citing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:53:06.997865Z",
     "start_time": "2020-01-21T01:52:54.501561Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(columns = ['Source','Target','id','Type','weight'])\n",
    "index = 0\n",
    "Type = 'Undirected'\n",
    "for s in count_id:\n",
    "    for i in count_id[s]:\n",
    "        temp = []\n",
    "        if i in count_id.keys() and s in count_id[i]:\n",
    "            print (s)\n",
    "            print (i)\n",
    "            continue\n",
    "        \n",
    "        #source = i\n",
    "        #target = s\n",
    "        \n",
    "        temp.append(i)\n",
    "        temp.append(s)\n",
    "        temp.append(index)\n",
    "        temp.append(Type)\n",
    "        temp.append(1)\n",
    "        \n",
    "        df.loc[index] = temp\n",
    "        \n",
    "        index += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:53:17.802385Z",
     "start_time": "2020-01-21T01:53:17.775053Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('edge_small.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:58:18.768829Z",
     "start_time": "2020-01-21T01:58:07.057567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_node = pd.DataFrame(columns = ['id','Label','size','age'])\n",
    "index = 0\n",
    "for s in count_id:    \n",
    "    temp = []\n",
    "    #source = i\n",
    "    #target = s\n",
    "    \n",
    "    weight = math.log(len(count_id[s]))\n",
    "    \n",
    "\n",
    "    temp.append(s)\n",
    "    temp.append('')\n",
    "    temp.append(weight)\n",
    "    temp.append(30)\n",
    "    \n",
    "   \n",
    "\n",
    "    df_node.loc[index] = temp\n",
    "\n",
    "    index += 1\n",
    "\n",
    "for s in core_citing:\n",
    "    if s not in count_id.keys():\n",
    "        temp = []\n",
    "        weight = math.log(len(core_citing[s]))\n",
    "        year = total_year[s]\n",
    "        \n",
    "        age = 2020 - int(year) + 1\n",
    "        #print (age)\n",
    "        \n",
    "        \n",
    "        temp.append(s)\n",
    "        \n",
    "        if int(s) in onlineLearning:\n",
    "            temp.append(\"Online Learning\" + str(s))\n",
    "        elif int(s) in tabletopInterface:\n",
    "            temp.append('Interface' + str(s))\n",
    "        elif int(s) in STEMedu:\n",
    "            temp.append('STEM' + str(s))\n",
    "        elif int(s) in stuAnalysis:\n",
    "            temp.append('analysis' + str(s))\n",
    "        else:\n",
    "            temp.append('')\n",
    "        \n",
    "        temp.append(weight)\n",
    "        temp.append(age)\n",
    "        #print (len(temp))\n",
    "        \n",
    "        df_node.loc[index] = temp\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:58:18.773707Z",
     "start_time": "2020-01-21T01:58:18.770266Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5321, 4)\n"
     ]
    }
   ],
   "source": [
    "print (df_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:57:47.237595Z",
     "start_time": "2020-01-21T01:57:46.973408Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "7\n",
      "3\n",
      "8\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "9\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "8\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "13\n",
      "16\n",
      "2\n",
      "10\n",
      "2\n",
      "2\n",
      "12\n",
      "13\n",
      "11\n",
      "12\n",
      "2\n",
      "7\n",
      "5\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "7\n",
      "19\n",
      "15\n",
      "23\n",
      "20\n",
      "20\n",
      "9\n",
      "7\n",
      "4\n",
      "13\n",
      "22\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "13\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "4\n",
      "16\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "14\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "15\n",
      "11\n",
      "8\n",
      "22\n",
      "16\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "11\n",
      "5\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "12\n",
      "7\n",
      "8\n",
      "6\n",
      "12\n",
      "9\n",
      "7\n",
      "8\n",
      "16\n",
      "14\n",
      "9\n",
      "7\n",
      "7\n",
      "9\n",
      "14\n",
      "16\n",
      "8\n",
      "8\n",
      "12\n",
      "9\n",
      "16\n",
      "10\n",
      "10\n",
      "10\n",
      "2\n",
      "2\n",
      "23\n",
      "13\n",
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for s in df_node['age']:\n",
    "    print (s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:58:21.259882Z",
     "start_time": "2020-01-21T01:58:21.232708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_node.to_csv('node_small.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:02:56.175911Z",
     "start_time": "2019-12-26T11:02:56.163003Z"
    }
   },
   "source": [
    "# 计算相似得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:52.069473Z",
     "start_time": "2020-01-21T06:07:52.006126Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#初始化列表\n",
    "sim_score = {}\n",
    "single = {}\n",
    "for s in author_data:\n",
    "    #print (len(author_data[s]))\n",
    "    single[s] = [0] * len(author_data[s])\n",
    "#print (single)\n",
    "\n",
    "for s in author_data:\n",
    "    for i in author_data[s]:\n",
    "        sim_score.setdefault(s,[]).append(copy.deepcopy(single))\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "d = 1\n",
    "\n",
    "for s in total_article:\n",
    "    for i in range(len(total_article[s]['title'])):\n",
    "        \n",
    "        for year in num_same_author[s][i]:\n",
    "            for j in range(len(num_same_author[s][i][year])):\n",
    "                same_ref = num_same_ref[s][i][year][j]\n",
    "                same_author = num_same_author[s][i][year][j]\n",
    "                same_index = num_same_index[s][i][year][j]\n",
    "                same_keyword = num_same_keyword[s][i][year][j]\n",
    "                \n",
    "                sim_score[s][i][year][j] = a*same_ref + d*same_keyword + c*same_index + b*same_author  \n",
    "                \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成力导向数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:53.166835Z",
     "start_time": "2020-01-21T06:07:52.948702Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(columns = np.arange(164))\n",
    "article_position = {}\n",
    "num = 0\n",
    "for s in sim_score:\n",
    "    #print (s)\n",
    "    count = 0\n",
    "    for i in sim_score[s]:\n",
    "        title = total_article[s]['title'][count]\n",
    "        article_position[title] = num\n",
    "        temp = []\n",
    "        for j in i:\n",
    "            temp.extend(i[j])\n",
    "        #print (temp)\n",
    "        df.loc[num] = temp\n",
    "        \n",
    "        count += 1\n",
    "        num += 1\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:07:59.215921Z",
     "start_time": "2020-01-21T06:07:58.537768Z"
    }
   },
   "outputs": [],
   "source": [
    "df_edge = pd.DataFrame(columns = ['Source','Target','id','Type','weight'])\n",
    "index = 0\n",
    "Type = 'Undirected'\n",
    "\n",
    "for s in df:\n",
    "    for i in df:\n",
    "        temp = []\n",
    "        if s != i and df[s][i] > 15 and i > s:\n",
    "            temp.append(i)\n",
    "            temp.append(s)\n",
    "            temp.append(index)\n",
    "            temp.append(Type)\n",
    "            temp.append(df[s][i])\n",
    "            \n",
    "            #print (temp)\n",
    "\n",
    "            df_edge.loc[index] = temp\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:08:02.780166Z",
     "start_time": "2020-01-21T06:08:02.774910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 5)\n"
     ]
    }
   ],
   "source": [
    "print (df_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:36:16.988290Z",
     "start_time": "2020-01-21T05:36:16.655109Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_node = pd.DataFrame(columns = ['id','Label','size','age'])\n",
    "index = 0\n",
    "\n",
    "for s in range(len(new_cite_list)):\n",
    "    temp = []\n",
    "    #print (new_cite_list[s])\n",
    "    temp.append(s)\n",
    "    \n",
    "    if int(s) in onlineLearning:\n",
    "        temp.append(\"Online Learning\" + str(s))\n",
    "    elif int(s) in tabletopInterface:\n",
    "        temp.append('Interface' + str(s))\n",
    "    elif int(s) in STEMedu:\n",
    "        temp.append('STEM' + str(s))\n",
    "    elif int(s) in stuAnalysis:\n",
    "        temp.append('analysis' + str(s))\n",
    "    else:\n",
    "        temp.append('')\n",
    "        \n",
    "    temp.append(new_cite_list[s])\n",
    "    \n",
    "    num = df1.loc[s]\n",
    "    age = 2020 - int(num['year']) + 1\n",
    "    temp.append(age)\n",
    "    \n",
    "    df_node.loc[index] = temp\n",
    "\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:23:10.589116Z",
     "start_time": "2020-01-21T05:23:10.584431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 4)\n"
     ]
    }
   ],
   "source": [
    "print (df_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T06:08:13.217836Z",
     "start_time": "2020-01-21T06:08:13.205848Z"
    }
   },
   "outputs": [],
   "source": [
    "df_edge.to_csv('edge_small_final.csv', sep=',', header=True, index=False)\n",
    "df_node.to_csv('node_samll.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T12:15:21.660240Z",
     "start_time": "2020-01-07T12:15:21.450229Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- 19 {weight: 0.9}\n",
      "2 -- 62 {weight: 0.8}\n",
      "3 -- 52 {weight: 0.85}\n",
      "3 -- 75 {weight: 1.0}\n",
      "5 -- 36 {weight: 1.1}\n",
      "6 -- 145 {weight: 0.9}\n",
      "6 -- 156 {weight: 0.85}\n",
      "9 -- 62 {weight: 1.0}\n",
      "15 -- 68 {weight: 0.95}\n",
      "16 -- 37 {weight: 0.8}\n",
      "18 -- 44 {weight: 1.0}\n",
      "21 -- 75 {weight: 0.85}\n",
      "22 -- 68 {weight: 3.0}\n",
      "22 -- 151 {weight: 3.0}\n",
      "22 -- 161 {weight: 2.0}\n",
      "23 -- 37 {weight: 0.95}\n",
      "23 -- 83 {weight: 0.85}\n",
      "23 -- 136 {weight: 1.05}\n",
      "27 -- 68 {weight: 3.0}\n",
      "27 -- 151 {weight: 3.0}\n",
      "27 -- 161 {weight: 2.0}\n",
      "31 -- 37 {weight: 0.8}\n",
      "32 -- 36 {weight: 0.9}\n",
      "39 -- 68 {weight: 0.9}\n",
      "39 -- 69 {weight: 1.2}\n",
      "44 -- 68 {weight: 3.0}\n",
      "44 -- 151 {weight: 3.0}\n",
      "44 -- 161 {weight: 2.0}\n",
      "45 -- 156 {weight: 1.0}\n",
      "46 -- 68 {weight: 3.0}\n",
      "46 -- 77 {weight: 0.8}\n",
      "46 -- 151 {weight: 3.1}\n",
      "46 -- 161 {weight: 2.0}\n",
      "47 -- 68 {weight: 3.9}\n",
      "47 -- 77 {weight: 0.95}\n",
      "47 -- 151 {weight: 3.0}\n",
      "47 -- 161 {weight: 2.0}\n",
      "49 -- 68 {weight: 0.95}\n",
      "50 -- 68 {weight: 1.05}\n",
      "56 -- 68 {weight: 3.0}\n",
      "56 -- 151 {weight: 3.0}\n",
      "56 -- 156 {weight: 1.0}\n",
      "56 -- 161 {weight: 2.0}\n",
      "61 -- 68 {weight: 3.2}\n",
      "61 -- 151 {weight: 3.15}\n",
      "61 -- 161 {weight: 2.0}\n",
      "68 -- 69 {weight: 0.9}\n",
      "68 -- 77 {weight: 0.85}\n",
      "68 -- 151 {weight: 3.0}\n",
      "68 -- 161 {weight: 2.0}\n",
      "69 -- 77 {weight: 0.85}\n",
      "70 -- 151 {weight: 3.0}\n",
      "70 -- 161 {weight: 2.0}\n",
      "72 -- 151 {weight: 3.0}\n",
      "72 -- 161 {weight: 2.1}\n",
      "77 -- 151 {weight: 3.0}\n",
      "77 -- 161 {weight: 2.0}\n",
      "78 -- 163 {weight: 0.85}\n",
      "80 -- 131 {weight: 0.8}\n",
      "83 -- 136 {weight: 1.05}\n",
      "88 -- 147 {weight: 0.8}\n",
      "90 -- 151 {weight: 3.0}\n",
      "90 -- 161 {weight: 2.0}\n",
      "98 -- 129 {weight: 0.8}\n",
      "105 -- 151 {weight: 3.0}\n",
      "105 -- 161 {weight: 2.0}\n",
      "108 -- 151 {weight: 3.0}\n",
      "108 -- 161 {weight: 2.0}\n",
      "113 -- 156 {weight: 0.85}\n",
      "114 -- 151 {weight: 3.0}\n",
      "114 -- 161 {weight: 2.0}\n",
      "116 -- 151 {weight: 3.0}\n",
      "116 -- 161 {weight: 2.0}\n",
      "123 -- 151 {weight: 3.0}\n",
      "123 -- 161 {weight: 2.0}\n",
      "128 -- 151 {weight: 3.0}\n",
      "128 -- 161 {weight: 2.1}\n",
      "130 -- 151 {weight: 3.0}\n",
      "130 -- 161 {weight: 2.0}\n",
      "131 -- 155 {weight: 1.1}\n",
      "132 -- 151 {weight: 3.0}\n",
      "132 -- 161 {weight: 2.0}\n",
      "133 -- 151 {weight: 3.0}\n",
      "133 -- 161 {weight: 2.0}\n",
      "137 -- 151 {weight: 3.0}\n",
      "137 -- 161 {weight: 2.0}\n",
      "139 -- 151 {weight: 3.0}\n",
      "139 -- 161 {weight: 2.0}\n",
      "141 -- 156 {weight: 1.3}\n",
      "148 -- 163 {weight: 0.85}\n",
      "151 -- 161 {weight: 2.0}\n",
      "157 -- 161 {weight: 2.0}\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "for s in df:\n",
    "    #if s > 100:\n",
    "        #break\n",
    "    for i in df:\n",
    "        #if i > 100:\n",
    "            #break\n",
    "        if s != i and df[s][i] > 15 and i > s:\n",
    "            print (str(s) + ' -- ' + str(i) + \" {weight: \" + str(df[s][i]/20) + \"}\")\n",
    "            t.append(s)\n",
    "            t.append(i)\n",
    "s2 = list(set(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T11:34:25.312686Z",
     "start_time": "2020-01-07T11:34:25.308276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "\"\"\"for s in range(164):\n",
    "    if s not in s2:\n",
    "        print (s)\"\"\"\n",
    "print (len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T07:51:02.697866Z",
     "start_time": "2019-12-30T07:51:02.504133Z"
    }
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "node_temp = {}\n",
    "edges_temp = []\n",
    "count = 0\n",
    "for s in df:\n",
    "    #if s > 100:\n",
    "        #break\n",
    "    for i in df:\n",
    "        #if i > 100:\n",
    "            #break\n",
    "        if s != i and df[s][i] > 10:\n",
    "            if s not in node_temp.keys():\n",
    "                node_temp[s] = count\n",
    "                count += 1\n",
    "            if i not in node_temp.keys():\n",
    "                node_temp[i] = count\n",
    "                count += 1\n",
    "            edges_temp.append({\"source\": s, \"target\": i, \"weight\": df[s][i]/2})\n",
    "                \n",
    "s2 = list(set(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T07:52:57.661740Z",
     "start_time": "2019-12-30T07:52:57.652117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name:': 11}, {'name:': 143}, {'name:': 64}, {'name:': 76}, {'name:': 65}, {'name:': 84}, {'name:': 68}, {'name:': 77}, {'name:': 85}, {'name:': 113}, {'name:': 108}, {'name:': 116}, {'name:': 138}, {'name:': 139}]\n",
      "[{'source': 0, 'target': 1, 'weight': 7.0}, {'source': 2, 'target': 3, 'weight': 11.0}, {'source': 4, 'target': 5, 'weight': 7.0}, {'source': 6, 'target': 7, 'weight': 12.0}, {'source': 3, 'target': 2, 'weight': 11.0}, {'source': 7, 'target': 6, 'weight': 12.0}, {'source': 5, 'target': 4, 'weight': 7.0}, {'source': 8, 'target': 9, 'weight': 6.0}, {'source': 10, 'target': 11, 'weight': 12.0}, {'source': 9, 'target': 8, 'weight': 6.0}, {'source': 11, 'target': 10, 'weight': 12.0}, {'source': 12, 'target': 13, 'weight': 6.0}, {'source': 13, 'target': 12, 'weight': 6.0}, {'source': 1, 'target': 0, 'weight': 7.0}]\n"
     ]
    }
   ],
   "source": [
    "node = []\n",
    "edge = []\n",
    "for s in node_temp:\n",
    "    node.append({\"name:\": s})\n",
    "    \n",
    "print (node)\n",
    "for s in edges_temp:\n",
    "    source = s[\"source\"]\n",
    "    target = s['target']\n",
    "    edge.append({\"source\": node_temp[source], \"target\": node_temp[target], \"weight\": s['weight']})\n",
    "    print (edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df[95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正引用数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:55:44.609228Z",
     "start_time": "2020-01-21T02:55:44.594797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "now = 2020\n",
    "index = 4\n",
    "high_cited = {}\n",
    "missing = {}\n",
    "new_cite_list = []\n",
    "year_list = []\n",
    "for s in total_bibliometrics:\n",
    "    year_list.append(s)\n",
    "    #print (total_bibliometrics[s])\n",
    "    count = 0\n",
    "    if s == \"2014/2015\":\n",
    "        year = 2014.0\n",
    "    else:\n",
    "        year = float(s)\n",
    "    for i in total_bibliometrics[s]:\n",
    "        #print (i)\n",
    "\n",
    "        new_cite = index / (now - year + 1) * (i + 1)\n",
    "        #print (new_cite)\n",
    "        new_cite_list.append(new_cite)\n",
    "        #if s == '2014':\n",
    "            #print (len(new_cite_list))\n",
    "print (len(new_cite_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:55:56.544699Z",
     "start_time": "2020-01-21T02:55:56.540167Z"
    }
   },
   "outputs": [],
   "source": [
    "color = ['#97CBFF','#2894FF','#005AB5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:55:56.955793Z",
     "start_time": "2020-01-21T02:55:56.938823Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2{color:#97CBFF}\n",
      "30{color:#97CBFF}\n",
      "39{color:#97CBFF}\n",
      "40{color:#97CBFF}\n",
      "52{color:#97CBFF}\n",
      "61{color:#97CBFF}\n",
      "65{color:#97CBFF}\n",
      "69{color:#005AB5}\n",
      "71{color:#97CBFF}\n",
      "72{color:#97CBFF}\n",
      "77{color:#97CBFF}\n",
      "81{color:#97CBFF}\n",
      "83{color:#97CBFF}\n",
      "84{color:#005AB5}\n",
      "85{color:#005AB5}\n",
      "88{color:#97CBFF}\n",
      "91{color:#97CBFF}\n",
      "92{color:#97CBFF}\n",
      "96{color:#2894FF}\n",
      "97{color:#97CBFF}\n",
      "103{color:#97CBFF}\n",
      "104{color:#2894FF}\n",
      "107{color:#97CBFF}\n",
      "131{color:#97CBFF}\n",
      "132{color:#97CBFF}\n",
      "137{color:#97CBFF}\n",
      "150{color:#2894FF}\n",
      "153{color:#97CBFF}\n",
      "155{color:#005AB5}\n",
      "159{color:#97CBFF}\n",
      "161{color:#2894FF}\n",
      "[69, 84, 85, 96, 104, 150, 155, 161]\n"
     ]
    }
   ],
   "source": [
    "high_cited = []\n",
    "\n",
    "for s in range(len(new_cite_list)):\n",
    "    if new_cite_list[s] > 40:\n",
    "        print (str(s) + \"{color:\" + color[2] + \"}\")\n",
    "        high_cited.append(s)\n",
    "        continue\n",
    "    if new_cite_list[s] > 30:\n",
    "        print (str(s) + \"{color:\" + color[1] + \"}\")\n",
    "        high_cited.append(s)\n",
    "        continue\n",
    "    if new_cite_list[s] > 20:\n",
    "        print (str(s) + \"{color:\" + color[0] + \"}\")\n",
    "        \n",
    "        continue\n",
    "print (high_cited)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出文章信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:59:31.997374Z",
     "start_time": "2020-01-20T09:59:31.983882Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df1 = pd.DataFrame(columns = ['index','title','abstract','author','citation','conference','year','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:59:33.730003Z",
     "start_time": "2020-01-20T09:59:33.331040Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                                              title  \\\n",
      "142   142  Blocks4All: Overcoming Accessibility Barriers ...   \n",
      "143   143  “Bursting the Assistance Bubble”: Designing In...   \n",
      "144   144  Bots & (Main)Frames: Exploring the Impact of T...   \n",
      "145   145  Science Everywhere: Designing Public, Tangible...   \n",
      "146   146  ConceptScape: Collaborative Concept Mapping fo...   \n",
      "147   147  Collaborative Live Media Curation: Shared Cont...   \n",
      "148   148  Co-designing online privacy-related games and ...   \n",
      "149   149  EmotiW 2018: Audio-Video, Student Engagement a...   \n",
      "0       0  Learning to Code in Localized Programming Lang...   \n",
      "1       1  Enabling Real-Time Adaptivity in MOOCs with a ...   \n",
      "2       2  Writing Reusable Code Feedback at Scale with M...   \n",
      "3       3  Intelligent tutors as teachers' aides: explori...   \n",
      "4       4  Trends and issues in student-facing learning a...   \n",
      "5       5  Follow the successful crowd: raising MOOC comp...   \n",
      "6       6  Enabling Collaboration in Learning Computer Pr...   \n",
      "7       7  : The Effects of Curriculum-Aligned Making on ...   \n",
      "8       8  Why Tangibility Matters: A Design Case Study o...   \n",
      "9       9  A Social Media Based Index of Mental Well-Bein...   \n",
      "10     10       Teaching Programming with Gamified Semantics   \n",
      "11     11  Sidestepping the Elephant in the Classroom: Us...   \n",
      "12     12  Wearable Immersive Virtual Reality for Childre...   \n",
      "13     13  \"They basically like destroyed the school one ...   \n",
      "14     14  Language learning on-the-go: opportune moments...   \n",
      "15     15  Effects of In-Video Quizzes on MOOC Lecture Vi...   \n",
      "16     16          Expert Evaluation of 300 Projects per Day   \n",
      "17     17  AXIS: Generating Explanations at Scale with Le...   \n",
      "18     18  Combining click-stream data with NLP tools to ...   \n",
      "19     19  Privacy and analytics: it's a DELICATE issue a...   \n",
      "20     20  Introduction of learning visualisations and me...   \n",
      "21     21  A conceptual framework linking learning design...   \n",
      "..    ...                                                ...   \n",
      "129   129  Digital mysteries: designing for learning at t...   \n",
      "130   130  Building and evaluating an intelligent pedagog...   \n",
      "131   131  Off-task behavior in the cognitive tutor class...   \n",
      "132   132  Ambient wood: designing new forms of digital a...   \n",
      "133   133                 Visualizing programs with Jeliot 3   \n",
      "134   134  Lessons learned from eClass: Assessing automat...   \n",
      "135   135  The introduction of a shared interactive surfa...   \n",
      "118   118  Designing e-learning games for rural children ...   \n",
      "119   119  Playful toothbrush: ubicomp technology for tea...   \n",
      "120   120  Explore! possibilities and challenges of mobil...   \n",
      "121   121  CareLog: a selective archiving tool for behavi...   \n",
      "122   122  Playing with the sound maker: do embodied meta...   \n",
      "160   160  Designing for or designing with? Informant des...   \n",
      "161   161  The persona effect: affective impact of animat...   \n",
      "162   162  KidPad: a design collaboration between childre...   \n",
      "163   163  The Effect of Turn-Taking Protocols on Childre...   \n",
      "150   150  Extending tangible interfaces for education: d...   \n",
      "151   151  Livenotes: a system for cooperative and augmen...   \n",
      "152   152  Locus of feedback control in computer-based tu...   \n",
      "136   136  Two peers are better than one: aggregating pee...   \n",
      "137   137  Comparing the use of tangible and graphical pr...   \n",
      "138   138  Tabletop displays for small group study: affor...   \n",
      "139   139  Children designing together on a multi-touch t...   \n",
      "153   153  The life and death of online gaming communitie...   \n",
      "154   154  Implicit coordination in firefighting practice...   \n",
      "155   155  Storytelling alice motivates middle school gir...   \n",
      "156   156  Modeling and understanding students' off-task ...   \n",
      "157   157  Multiple mice for retention tasks in disadvant...   \n",
      "158   158  Investigating the capture, integration and acc...   \n",
      "159   159      Digital manipulatives: new toys to think with   \n",
      "\n",
      "                                              abstract  \\\n",
      "142  Blocks-based programming environments are a po...   \n",
      "143  Children living with visual impairments (VIs) ...   \n",
      "144  While recent work has begun to evaluate the ef...   \n",
      "145  A major challenge in education is understandin...   \n",
      "146  While video has become a widely adopted medium...   \n",
      "147  In recent years, online education's reach and ...   \n",
      "148  Children ages 8--12 spend nearly six hours per...   \n",
      "149  This paper details the sixth Emotion Recogniti...   \n",
      "0    Education research suggests that learning in o...   \n",
      "1    In this paper, we demonstrate a first-of-its-k...   \n",
      "2    In large introductory programming classes, tea...   \n",
      "3    Intelligent tutoring systems (ITSs) are common...   \n",
      "4    We conducted a literature review on systems th...   \n",
      "5    Social comparison theory asserts that we estab...   \n",
      "6    We investigate how technology can support coll...   \n",
      "7    Prior research investigating the effects of in...   \n",
      "8    Tangibles may be effective for reading applica...   \n",
      "9    Psychological distress in the form of depressi...   \n",
      "10   Dominant approaches to programming education e...   \n",
      "11   Cultural taboos can restrict student learning ...   \n",
      "12   Our research explores the potential of Wearabl...   \n",
      "13   This exploratory work studies the effects of e...   \n",
      "14   Learning a foreign language is a daunting and ...   \n",
      "15   Online courses on sites such as Coursera use q...   \n",
      "16   In October 2014, one-time MOOC developer Udaci...   \n",
      "17   While explanations may help people learn by pr...   \n",
      "18   Completion rates for massive open online class...   \n",
      "19   The widespread adoption of Learning Analytics ...   \n",
      "20   This paper describes open learner models as vi...   \n",
      "21   In this paper we present a learning analytics ...   \n",
      "..                                                 ...   \n",
      "129  We present the iterative design, implementatio...   \n",
      "130  Electronic educational games can be highly ent...   \n",
      "131  We investigate the prevalence and learning imp...   \n",
      "132  Ubiquitous and mobile technologies provide opp...   \n",
      "133  We present a program visualization tool called...   \n",
      "134  This article presents results from a study of ...   \n",
      "135  We describe a user study of a large multi-user...   \n",
      "118  Poor literacy remains a barrier to economic em...   \n",
      "119  This case study in UbiComp technology and desi...   \n",
      "120  This paper reports the experimental studies we...   \n",
      "121  Identifying the function of problem behavior c...   \n",
      "122  In this paper we present the results of a comp...   \n",
      "160                      An abstract is not available.   \n",
      "161                      An abstract is not available.   \n",
      "162                      An abstract is not available.   \n",
      "163  This study compared the influence of turn-taki...   \n",
      "150  This paper introduces a new framework for thin...   \n",
      "151  We describe Livenotes, a shared whiteboard sys...   \n",
      "152  The advent of second-generation intelligent co...   \n",
      "136  Scientific peer review, open source software d...   \n",
      "137  Much of the work done in the field of tangible...   \n",
      "138  In this paper we compare the affordances of pr...   \n",
      "139  Applications running on multi-touch tabletops ...   \n",
      "153  Massively multiplayer online games (MMOGs) can...   \n",
      "154  Fire emergency response requires rapidly proce...   \n",
      "155  We describe Storytelling Alice, a programming ...   \n",
      "156  We present a machine-learned model that can au...   \n",
      "157  This study evaluates single-mouse and multiple...   \n",
      "158                      An abstract is not available.   \n",
      "159                      An abstract is not available.   \n",
      "\n",
      "                                                author citation conference  \\\n",
      "142  [{'name': 'Lauren R. Milne', 'institutions': '...        6        CHI   \n",
      "143  [{'name': 'Oussama Metatla', 'institutions': '...       10        CHI   \n",
      "144  [{'name': 'Edward F. Melcer', 'institutions': ...        6        CHI   \n",
      "145  [{'name': 'June Ahn', 'institutions': 'New Yor...        6        CHI   \n",
      "146  [{'name': 'Ching Liu', 'institutions': 'Nation...        7        CHI   \n",
      "147  [{'name': 'William A. Hamilton', 'institutions...        6        CHI   \n",
      "148  [{'name': 'Priya Kumar', 'institutions': 'Univ...        6        IDC   \n",
      "149  [{'name': 'Abhinav Dhall', 'institutions': 'In...       12       ICMI   \n",
      "0    [{'name': 'Sayamindu Dasgupta', 'institutions'...        8         LS   \n",
      "1    [{'name': 'Zachary A. Pardos', 'institutions':...       13         LS   \n",
      "2    [{'name': 'Andrew Head', 'institutions': 'Univ...       21         LS   \n",
      "3    [{'name': 'Kenneth Holstein', 'institutions': ...        9        LAK   \n",
      "4    [{'name': 'Robert Bodily', 'institutions': 'Br...        8        LAK   \n",
      "5    [{'name': 'Dan Davis', 'institutions': 'Delft ...        8        LAK   \n",
      "6    [{'name': 'Anja Thieme', 'institutions': 'Micr...       15        DIS   \n",
      "7    [{'name': 'Sharon Lynn Chu', 'institutions': '...        8        CHI   \n",
      "8    [{'name': 'Min Fan', 'institutions': 'Simon Fr...        9        CHI   \n",
      "9    [{'name': 'Shrey Bagroy', 'institutions': 'III...        9        CHI   \n",
      "10   [{'name': 'Ian Arawjo', 'institutions': 'Corne...        8        CHI   \n",
      "11   [{'name': 'Piya Sorcar', 'institutions': 'Stan...        8        CHI   \n",
      "12   [{'name': 'Franca Garzotto', 'institutions': '...        9        IDC   \n",
      "13   [{'name': 'Vivek K. Singh', 'institutions': 'R...        8       CSCW   \n",
      "14   [{'name': 'Tilman Dingler', 'institutions': 'U...        8  MOBILECHI   \n",
      "15   [{'name': 'Geza Kovacs', 'institutions': 'Stan...       14         LS   \n",
      "16   [{'name': 'David A. Joyner', 'institutions': '...        0         LS   \n",
      "17   [{'name': 'Joseph Jay Williams', 'institutions...       19         LS   \n",
      "18   [{'name': 'Scott Crossley', 'institutions': 'G...       12        LAK   \n",
      "19   [{'name': 'Hendrik Drachsler', 'institutions':...       17        LAK   \n",
      "20   [{'name': 'Susan Bull', 'institutions': 'Unive...       12        LAK   \n",
      "21   [{'name': 'Aneesha Bakharia', 'institutions': ...       11        LAK   \n",
      "..                                                 ...      ...        ...   \n",
      "129  [{'name': 'Ahmed Kharrufa', 'institutions': 'N...       35        ITS   \n",
      "130  [{'name': 'Cristina Conati', 'institutions': '...       41        IUI   \n",
      "131  [{'name': 'Ryan Shaun Baker', 'institutions': ...       98        CHI   \n",
      "132  [{'name': 'Y. Rogers', 'institutions': 'Indian...       95        IDC   \n",
      "133  [{'name': 'Andrés Moreno', 'institutions': 'Un...       82        AVI   \n",
      "134  [{'name': 'Jason A. Brotherton', 'institutions...       68      TOCHI   \n",
      "135  [{'name': 'Harry Brignull', 'institutions': 'U...       52       CSCW   \n",
      "118  [{'name': 'Matthew Kam', 'institutions': 'Univ...       34        DIS   \n",
      "119  [{'name': 'Yu-Chen Chang', 'institutions': 'Na...       31        CHI   \n",
      "120  [{'name': 'Maria F. Costabile', 'institutions'...       36        CHI   \n",
      "121  [{'name': 'Gillian R. Hayes', 'institutions': ...       36        CHI   \n",
      "122  [{'name': 'Alissa N. Antle', 'institutions': '...       38        IDC   \n",
      "160  [{'name': 'Michael Scaife', 'institutions': 'S...      112        CHI   \n",
      "161  [{'name': 'James C. Lester', 'institutions': '...      204        CHI   \n",
      "162  [{'name': 'Allison Druin', 'institutions': 'Co...       79        CHI   \n",
      "163  [{'name': 'Kori Inkpen', 'institutions': ['Uni...       85         GI   \n",
      "150  [{'name': 'Oren Zuckerman', 'institutions': 'M...      133        CHI   \n",
      "151  [{'name': 'Matthew Kam', 'institutions': 'Univ...       60        CHI   \n",
      "152  [{'name': 'Albert T. Corbett', 'institutions':...       49        CHI   \n",
      "136  [{'name': 'Ken Reily', 'institutions': 'Univer...       28      GROUP   \n",
      "137  [{'name': 'Michael S. Horn', 'institutions': '...       68        CHI   \n",
      "138  [{'name': 'Anne Marie Piper', 'institutions': ...       52        CHI   \n",
      "139  [{'name': 'Jochen Rick', 'institutions': 'Open...       54        IDC   \n",
      "153  [{'name': 'Nicolas Ducheneaut', 'institutions'...       78        CHI   \n",
      "154  [{'name': 'Zachary O. Toups', 'institutions': ...       37        CHI   \n",
      "155  [{'name': 'Caitlin Kelleher', 'institutions': ...      147        CHI   \n",
      "156  [{'name': 'Ryan S.J.d. Baker', 'institutions':...       39        CHI   \n",
      "157  [{'name': 'Udai Singh Pawar', 'institutions': ...       45        CHI   \n",
      "158  [{'name': 'Gregory D. Abowd', 'institutions': ...       62        CHI   \n",
      "159  [{'name': 'Mitchel Resnick', 'institutions': '...      137        CHI   \n",
      "\n",
      "     year     id  \n",
      "142  2018   7973  \n",
      "143  2018   8249  \n",
      "144  2018   8169  \n",
      "145  2018   8181  \n",
      "146  2018   8290  \n",
      "147  2018   8457  \n",
      "148  2018  15031  \n",
      "149  2018  21556  \n",
      "0    2017     68  \n",
      "1    2017     67  \n",
      "2    2017     74  \n",
      "3    2017    439  \n",
      "4    2017    445  \n",
      "5    2017    464  \n",
      "6    2017   1732  \n",
      "7    2017   9904  \n",
      "8    2017  10049  \n",
      "9    2017  10035  \n",
      "10   2017  10308  \n",
      "11   2017  10134  \n",
      "12   2017  15411  \n",
      "13   2017  18584  \n",
      "14   2017  20230  \n",
      "15   2016    134  \n",
      "16   2016    149  \n",
      "17   2016    212  \n",
      "18   2016    816  \n",
      "19   2016    826  \n",
      "20   2016    819  \n",
      "21   2016    856  \n",
      "..    ...    ...  \n",
      "129  2010  22752  \n",
      "130  2004   4183  \n",
      "131  2004   9013  \n",
      "132  2004  15208  \n",
      "133  2004  16394  \n",
      "134  2004  17153  \n",
      "135  2004  18295  \n",
      "118  2008   1796  \n",
      "119  2008  10818  \n",
      "120  2008  10790  \n",
      "121  2008  10855  \n",
      "122  2008  15590  \n",
      "160  1997  12687  \n",
      "161  1997  12689  \n",
      "162  1997  12702  \n",
      "163  1997  14752  \n",
      "150  2005   8958  \n",
      "151  2005   8925  \n",
      "152  2001   9157  \n",
      "136  2009   5413  \n",
      "137  2009  10606  \n",
      "138  2009  10632  \n",
      "139  2009  15478  \n",
      "153  2007  11083  \n",
      "154  2007  11071  \n",
      "155  2007  11155  \n",
      "156  2007  11110  \n",
      "157  2007  11170  \n",
      "158  1998  11228  \n",
      "159  1998  11208  \n",
      "\n",
      "[164 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "for s in total_article:\n",
    "    for i in range(len(total_article[s]['title'])):\n",
    "        temp = []\n",
    "        title = total_article[s]['title'][i]\n",
    "        abstract = total_article[s]['abstract'][i]\n",
    "        author = author_data[s][i]\n",
    "        index = total_id[s][i]\n",
    "        conf = total_conf[s][i]\n",
    "        citation = total_bibliometrics[s][i]\n",
    "        num = article_position[title]\n",
    "        \n",
    "        temp.append(num)\n",
    "        temp.append(title)\n",
    "        temp.append(abstract)\n",
    "        temp.append(author)\n",
    "        temp.append(citation)\n",
    "        temp.append(conf)\n",
    "        temp.append(s)\n",
    "        temp.append(index)\n",
    "        \n",
    "        \n",
    "        df1.loc[num] = temp\n",
    "        \n",
    "        num += 1\n",
    "        \n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T01:55:15.403194Z",
     "start_time": "2020-01-21T01:55:15.394389Z"
    }
   },
   "outputs": [],
   "source": [
    "onlineLearning = [69,87,96,37,68,88,36,39,54,55,59,60,63,71,82,89,91,74]\n",
    "stuAnalysis = [84,65,104,102,103,111,131,149,85,113,56,57]\n",
    "STEMedu = [156,52,59,2,24,34,133,14,51,6,81,145]\n",
    "tabletopInterface = [151,161,77,105,132,137,159,98,108,116,117,129,138,139,135,157,163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:07:59.695849Z",
     "start_time": "2020-01-20T11:07:59.674548Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['352', '600', '16891', '283', '392', '612', '287', '285', '16979', '16980', '18011', '17885', '17966', '350', '18977', '5917', '5744', '544']\n",
      "['8925', '12689', '3241', '11999', '15208', '10606', '11208', '22393', '11908', '12489', '23147', '22752', '10632', '15478', '18295', '11170', '14752']\n",
      "['11110', '14959', '18011', '74', '6570', '17747', '16394', '20230', '7252', '1732', '13840', '8181']\n",
      "['24154', '23470', '685', '661', '681', '999', '9013', '21556', '610', '1003', '16992', '17907']\n"
     ]
    }
   ],
   "source": [
    "def print_id(onlineLearning):\n",
    "    temp = []\n",
    "    for s in onlineLearning:\n",
    "        #print (s)\n",
    "        num = df1.loc[s]\n",
    "        #print (num['id'])\n",
    "        #print (df['index'][num])\n",
    "        temp.append(num['id'])\n",
    "\n",
    "    print (temp)\n",
    "    \n",
    "print_id(onlineLearning)\n",
    "print_id(tabletopInterface)\n",
    "print_id(STEMedu)\n",
    "print_id(stuAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T10:02:36.060112Z",
     "start_time": "2020-01-20T10:02:36.043733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018': {'title': ['Blocks4All: Overcoming Accessibility Barriers to Blocks Programming for Children with Visual Impairments', '“Bursting the Assistance Bubble”: Designing Inclusive Technology with Children with Mixed Visual Abilities', 'Bots & (Main)Frames: Exploring the Impact of Tangible Blocks and Collaborative Play in an Educational Programming Game', 'Science Everywhere: Designing Public, Tangible Displays to Connect Youth Learning Across Settings', 'ConceptScape: Collaborative Concept Mapping for Video Learning', 'Collaborative Live Media Curation: Shared Context for Participation in Online Learning', 'Co-designing online privacy-related games and stories with children', 'EmotiW 2018: Audio-Video, Student Engagement and Group-Level Affect Prediction'], 'abstract': ['Blocks-based programming environments are a popular tool to teach children to program, but they rely heavily on visual metaphors and are therefore not fully accessible for children with visual impairments. We evaluated existing blocks-based environments and identified five major accessibility barriers for visually impaired users. We explored techniques to overcome these barriers in an interview with a teacher of the visually impaired and formative studies on a touchscreen blocks-based environment with five children with visual impairments. We distill our findings on usable touchscreen interactions into guidelines for designers of blocks-based environments.', 'Children living with visual impairments (VIs) are increasingly educated in mainstream rather than special schools. But knowledge about the challenges they face in inclusive schooling environments and how to design technology to overcome them remains scarce. We report findings from a field study involving interviews and observations of educators and children with/without VIs in mainstream schools, in which we identified the \"teaching assistant bubble\" as a potential barrier to group learning, social play and independent mobility. We present co-design activities blending elements of future workshops, multisensory crafting, fictional inquiry and bodystorming, demonstrating that children with and without VIs can jointly lead design processes and explore design spaces reflective of mixed visual abilities and shared experiences. We extend previous research by characterising challenges and opportunities for improving inclusive education of children with VIs in mainstream schools, in terms of balancing assistance and independence, and reflect on the process and outcomes of co-designing with mixed-ability groups in this context.', 'While recent work has begun to evaluate the efficacy of educational programming games, many common design decisions in these games (e.g., single player gameplay using touchpad or mouse) have not been explored for learning outcomes. For instance, alternative design approaches such as collaborative play and embodied interaction with tangibles may also provide important benefits to learners. To better understand how these design decisions impact learning and related factors, we created an educational programming game that allows for systematically varying input method and mode of play. In this paper, we describe design rationale for mouse and tangible versions of our game, and report a 2x2 factorial experiment comparing efficacy of mouse and tangible input methods with individual and collaborative modes of play. Results indicate tangibles have a greater positive impact on learning, situational interest, enjoyment, and programming self-beliefs. We also found collaborative play helps further reduce programming anxiety over individual play.', \"A major challenge in education is understanding how to connect learning experiences across settings (e.g., school, afterschool, and home) for youth. In this paper, we introduce and describe the participatory design process we undertook to develop Science Everywhere (SE), which is a sociotechnical system where children share their everyday science learning via social media. Public displays installed throughout the neighborhood invite parents, adults, peers, and community members to interact with children's ideas to better develop connections for learning across settings. Our case study of community interactions with the public displays illuminate how these technologies encouraged behaviors such as the noticing of children's ideas, recognition of people in the neighborhood, and bridging to new learning opportunities for youth.\", 'While video has become a widely adopted medium for online learning, existing video players provide limited support for navigation and learning. It is difficult to locate parts of the video that are linked to specific concepts. Also, most video players afford passive watching, thus making it difficult for learners with limited metacognitive skills to deeply engage with the content and reflect on their understanding. To support concept-driven navigation and comprehension of lecture videos, we present ConceptScape, a system that generates and presents a concept map for lecture videos. ConceptScape engages crowd workers to collaboratively generate a concept map by prompting them to externalize reflections on the video. We present two studies to show that (1) interactive concept maps can be useful tools for concept-based video navigation and comprehension, and (2) with ConceptScape, novice crowd workers can collaboratively generate complex concept maps that match the quality of those by experts.', \"In recent years, online education's reach and scale have increased through new platforms for large and small online courses. However, these platforms often rely on impoverished modalities, which provide limited support for participation in social learning experiences. We present Collaborative Live Media Curation (CLMC), a new medium for sharing context and participation in online learning. CLMC involves collaborative, synchronous collection, creation, and assemblage of web media, including images, text, video, and sketch. CLMC integrates live media including streaming video, screenshares, audio, and text chat. We deploy and study LiveMâché, a CLMC technology probe, in four situated online learning contexts. We discovered student and instructor strategies for sharing context and participating including creating curations in advance, sketching to illustrate and gesture, real-time transformations, sharing perspective, and assembling live streams. We develop implications through live experience patterns, which describe how spatial and computing structures support social activities.\", 'Children ages 8--12 spend nearly six hours per day with digital content, but they receive little formal instruction related to managing privacy online. In this study, we explore how games and storytelling can inform the development of resources to help children learn about privacy online. We present results from three co-design sessions with a university-based intergenerational design team that included eight children ages 8--11. During these sessions, we reviewed existing privacy resources with children and elicited design ideas for new resources. Our findings yield several recommendations for designers. Specifically, online privacy-focused educational resources should: (1) include relatable elements such as familiar characters and easily understandable storylines, (2) go beyond instructing children through \"dos and don\\'ts\" and equip children to make privacy-related decisions, and (3) expose children to a range of privacy consequences, highlighting the positive and negative outcomes that can result from disclosing and managing information online.', \"This paper details the sixth Emotion Recognition in the Wild (EmotiW) challenge. EmotiW 2018 is a grand challenge in the ACM International Conference on Multimodal Interaction 2018, Colarado, USA. The challenge aims at providing a common platform to researchers working in the affective computing community to benchmark their algorithms on 'in the wild' data. This year EmotiW contains three sub-challenges: a) Audio-video based emotion recognition; b) Student engagement prediction; and c) Group-level emotion recognition. The databases, protocols and baselines are discussed in detail.\"]}, '2017': {'title': ['Learning to Code in Localized Programming Languages', 'Enabling Real-Time Adaptivity in MOOCs with a Personalized Next-Step Recommendation Framework', 'Writing Reusable Code Feedback at Scale with Mixed-Initiative Program Synthesis', \"Intelligent tutors as teachers' aides: exploring teacher needs for real-time analytics in blended classrooms\", 'Trends and issues in student-facing learning analytics reporting systems research', 'Follow the successful crowd: raising MOOC completion rates through social comparison at scale', 'Enabling Collaboration in Learning Computer Programing Inclusive of Children with Vision Impairments', \": The Effects of Curriculum-Aligned Making on Children's Self-Identity\", 'Why Tangibility Matters: A Design Case Study of At-Risk Children Learning to Read and Spell', 'A Social Media Based Index of Mental Well-Being in College Campuses', 'Teaching Programming with Gamified Semantics', 'Sidestepping the Elephant in the Classroom: Using Culturally Localized Technology To Teach Around Taboos', 'Wearable Immersive Virtual Reality for Children with Disability: a Case Study', '\"They basically like destroyed the school one day\": On Newer App Features and Cyberbullying in Schools', 'Language learning on-the-go: opportune moments and design of mobile microlearning sessions'], 'abstract': [\"Education research suggests that learning in one's local language can have a positive impact on learning outcomes. We offer a quantitative test of the association between local language use and the rate at which youth learn to program. Using longitudinal data drawn from five countries and over 15,000 users of Scratch, a large informal learning community, we find that novice users who code with their programming language keywords and environment localized into their home countries' primary language demonstrate new programming concepts at a faster rate than users from the same countries whose interface is in English. We conclude with a discussion of the implications of our findings for designers of online learning systems.\", \"In this paper, we demonstrate a first-of-its-kind adaptive intervention in a MOOC utilizing real-time clickstream data and a novel machine learned model of behavior. We detail how we augmented the edX platform with the capabilities necessary to support this type of intervention which required both tracking learners' behaviors in real-time and dynamically adapting content based on each learner's individual clickstream history. Our chosen pilot intervention was in the category of adaptive pathways and courseware and took the form of a navigational suggestion appearing at the bottom of every non-forum content page in the course. We designed our pilot intervention to help students more efficiently navigate their way through a MOOC by predicting the next page they were likely to spend significant time on and allowing them to jump directly to that page. While interventions which attempt to optimize for learner achievement are candidates for this adaptive framework, behavior prediction has the benefit of not requiring causal assumptions to be made in its suggestions. We present a novel extension of a behavioral model that takes into account students' time spent on pages and forecasts the same. Several approaches to representing time using Recurrent Neural Networks are evaluated and compared to baselines without time, including a basic n-gram model. Finally, we discuss design considerations and handling of edge cases for real-time deployment, including considerations for training a machine learned model on a previous offering of a course for use in a subsequent offering where courseware may have changed. This work opens the door to broad experimentation with adaptivity and serves as a first example of delivering a data-driven personalized learning experience in a MOOC.\", 'In large introductory programming classes, teacher feedback on individual incorrect student submissions is often infeasible. Program synthesis techniques are capable of fixing student bugs and generating hints automatically, but they lack the deep domain knowledge of a teacher and can generate functionally correct but stylistically poor fixes. We introduce a mixed-initiative approach which combines teacher expertise with data-driven program synthesis techniques. We demonstrate our novel approach in two systems that use different interaction mechanisms. Our systems use program synthesis to learn bug-fixing code transformations and then cluster incorrect submissions by the transformations that correct them. The MistakeBrowser system learns transformations from examples of students fixing bugs in their own submissions. The FixPropagator system learns transformations from teachers fixing bugs in incorrect student submissions. Teachers can write feedback about a single submission or a cluster of submissions and propagate the feedback to all other submissions that can be fixed by the same transformation. Two studies suggest this approach helps teachers better understand student bugs and write reusable feedback that scales to a massive introductory programming classroom.', 'Intelligent tutoring systems (ITSs) are commonly designed to enhance student learning. However, they are not typically designed to meet the needs of teachers who use them in their classrooms. ITSs generate a wealth of analytics about student learning and behavior, opening a rich design space for real-time teacher support tools such as dashboards. Whereas real-time dashboards for teachers have become popular with many learning technologies, we are not aware of projects that have designed dashboards for ITSs based on a broad investigation of teachers\\' needs. We conducted design interviews with ten middle school math teachers to explore their needs for on-the-spot support during blended class sessions, as a first step in a user-centered design process of a real-time dashboard. Based on multi-methods analyses of this interview data, we identify several opportunities for ITSs to better support teachers\\' needs, noting that the analytics commonly generated by existing teacher support tools do not strongly align with the analytics teachers expect to be most useful. We highlight key tensions and tradeoffs in the design of such real-time supports for teachers, as revealed by \"Speed Dating\" possible futures with teachers. This paper has implications for our ongoing co-design of a real-time dashboard for ITSs, as well as broader implications for the design of ITSs that can effectively collaborate with teachers in classroom settings.', 'We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current student-facing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work.', \"Social comparison theory asserts that we establish our social and personal worth by comparing ourselves to others. In in-person learning environments, social comparison offers students critical feedback on how to behave and be successful. By contrast, online learning environments afford fewer social cues to facilitate social comparison. Can increased availability of such cues promote effective self-regulatory behavior and achievement in Massive Open Online Courses (MOOCs)? We developed a personalized feedback system that facilitates social comparison with previously successful learners based on an interactive visualization of multiple behavioral indicators. Across four randomized controlled trials in MOOCs (overall N = 33, 726), we find: (1) the availability of social comparison cues significantly increases completion rates, (2) this type of feedback benefits highly educated learners, and (3) learners' cultural context plays a significant role in their course engagement and achievement.\", \"We investigate how technology can support collaborative learning by children with mixed-visual abilities. Responding to a growing need for tools inclusive of children with vision impairments (VI) for the teaching of computer programing to novice learners, we explore Torino -- a physical programing language for teaching programing constructs and computational thinking to children age 7-11. We draw insights from 12 learning sessions with Torino that involved five pairs of children with vision ranging from blindness to full-sight. Our findings show how sense-making of the technology, collaboration, and learning were enabled through an interplay of system design, programing tasks and social interactions, and how this differed between the pairs. The paper contributes insights on the role of touch, audio and visual representations in designs inclusive of people with VI, and discusses the importance and opportunities provided through the 'social' in negotiations of accessibility, for learning, and for self-perceptions of ability and self-esteem.\", 'Prior research investigating the effects of incorporating Making into educational contexts has been limited to snapshot studies. These studies however do not allow for the investigation of aspects that require longer-term development and nurture. We present a longitudinal study that investigates the effects of Making on children\\'s degree of science self-efficacy, identity formation as possible scientists and engineers, and academic performance in science. Designed interactions with Making technology were integrated into the science curriculum of elementary school classrooms in a public school with a high proportion of students from minority populations for a year. Results showed significant differences between the \"Making classrooms\" and the control classrooms, and from pre- to post-test on the students\\' inclination towards science. The results support the promise and potential of incorporating Making into formal schooling on the growth and long-term attitudes of children towards science and STEM in general.', 'Tangibles may be effective for reading applications. Letters can be represented as 3D physical objects. Words are spatially organized collections of letters. We explore how tangibility impacts reading and spelling acquisition for young Anglophone children who have dyslexia. We describe our theory-based design rationale and present a mixed-methods case study of eight children using our PhonoBlocks system. All children made significant gains in reading and spelling on trained and untrained (new) words, and could apply all spelling rules a month later. We discuss the design features of our system that contributed to effective learning processes, resulting in successful learning outcomes: dynamic colour cues embedded in 3D letters, which can draw attention to how letter(s) position changes their sounds; and the form of 3D tangible letters, which can enforce correct letter orientation and enable epistemic strategies in letter organization that simplify spelling tasks. We conclude with design guidelines for tangible reading systems.', 'Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multi-campus data on mental well-being presents significant challenges to intervention and mitigation efforts in college campuses. We examine the potential of social media as a new \"barometer\" for quantifying the mental well-being of college populations. Utilizing student-contributed data in Reddit communities of over 100 universities, we first build and evaluate a transfer learning based classification approach that can detect mental health expressions with 97% accuracy. Thereafter, we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI is able to reveal meaningful temporal patterns of mental well-being in campuses, and to assess how their expressions relate to university attributes like size, academic prestige, and student demographics. We discuss the implications of our work for improving counselor efforts, and in the design of tools that can enable better assessment of the mental health climate of college campuses.', 'Dominant approaches to programming education emphasize program construction over language comprehension. We present Reduct, an educational game embodying a new, comprehension-first approach to teaching novices core programming concepts which include functions, Booleans, equality, conditionals, and mapping functions over sets. In this novel teaching strategy, the player executes code using reduction-based operational semantics. During gameplay, code representations fade from concrete, block-based graphics to the actual syntax of JavaScript ES2015. We describe our design rationale and report on the results of a study evaluating the efficacy of our approach on young adults (18+) without prior coding experience. In a short timeframe, novices demonstrated promising learning of core concepts expressed in actual JavaScript. We also present results from an online deployment. Finally, we discuss ramifications for the design of future computational thinking games.', 'Cultural taboos can restrict student learning on topics of critical importance. In India, such taboos have led multiple states to ban materials intended to educate youth about HIV, putting millions at risk. We present the design of TeachAIDS, a software application that leverages cultural insights, learning science, and affordances of technology to provide comprehensive HIV education while circumventing taboos. Using a mixed-methods evaluation, we demonstrate that this software leaves students with significantly increased knowledge about HIV and reduced stigma toward individuals infected with the virus. Validating the effectiveness of TeachAIDS in circumventing taboos, students report comfort in learning from the software, and it has since been deployed in tens of thousands of schools throughout India. The methodology presented here has broader implications for the design and implementation of interactive technologies for providing education on sensitive topics in health and other areas.', 'Our research explores the potential of Wearable Immersive Virtual Reality (WIVR) as learning tool for children with disability, particularly Neurodevelopmental Disorder (NDDs). NDD is characterized by severe and often co-existing deficits in the cognitive, emotional, and motor areas. The paper discusses the learning potential of WIVR and presents the design and preliminary evaluation of Wildcard, a novel WIVR system designed in cooperation with NDD specialists. Virtual environments are displayed on a smartphone placed inside a commercial low cost VR viewer while children interact with the virtual world through gaze focus and direction. An exploratory study performed at a care center sheds a light on the behavior of children with NDDs in wearable immersive virtual reality environments and highlights the learning potential as well as the possible difficulties of using this technology with this target group.', 'This exploratory work studies the effects of emerging app features on the cyberbullying practices in high school settings. These include the increasing prevalence of image/video content, perceived ephemerality, anonymity, and hyperlocal communication. Based on qualitative analysis of focus groups and follow-up individual interviews with high school students, these features were found to influence the practice of cyberbullying, as well as creating negative socio-psychological effects. For example, visual data was found to be used in cyberbullying settings as evidence of contentious events, a repeated reminder, and caused a graphic impact on recipients. Similarly, perceived ephemerality of content was found to be associated with \"broken expectations\" with respect to the apps and severe bullying outcomes for those affected. Results shed light on an important technology-mediated social phenomenon of cyberbullying, improve understanding of app use (and abuse) by the teenage user population, and pave the way for future research on countering appcentric cyberbullying.', 'Learning a foreign language is a daunting and time-consuming task. People often lack the time or motivation to sit down and engage with learning content on a regular basis. We present an investigation of microlearning sessions on mobile phones, in which we focus on session triggers, presentation methods, and user context. Therefore, we built an Android app that prompts users to review foreign language vocabulary directly through notifications or through app usage across the day. We present results from a controlled and an in-the-wild study, in which we explore engagement and user context. In-app sessions lasted longer, but notifications added a significant number of \"quick\" learning sessions. 37.6% of sessions were completed in transit, hence learning-on-the-go was well received. Neither the use of boredom as trigger nor the presentation (flashcard and multiple-choice) had a significant effect. We conclude with implications for the design of mobile microlearning applications with context-awareness.']}, '2016': {'title': ['Effects of In-Video Quizzes on MOOC Lecture Viewing', 'Expert Evaluation of 300 Projects per Day', 'AXIS: Generating Explanations at Scale with Learnersourcing and Machine Learning', 'Combining click-stream data with NLP tools to better understand MOOC completion', \"Privacy and analytics: it's a DELICATE issue a checklist for trusted learning analytics\", 'Introduction of learning visualisations and metacognitive support in a persuadable open learner model', 'A conceptual framework linking learning design with learning analytics', 'An Intelligent Interface for Learning Content: Combining an Open Learner Model and Social Comparison to Support Self-Regulated Learning and Engagement', 'Facilitator, Functionary, Friend or Foe?: Studying the Role of iPads within Learning Activities Across a School Year', 'Framing Feedback: Choosing Review Environment Features that Support High Quality Peer Assessment', 'Programming, Problem Solving, and Self-Awareness: Effects of Explicit Guidance', \"'Don't Waste My Time': Use of Time Information Improves Focus\", 'Learn Piano with BACh: An Adaptive Learning Interface that Adjusts Task Difficulty Based on Brain State', 'Improving Real-Time Captioning Experiences for Deaf and Hard of Hearing Students', 'Legitimate Participation in the Classroom Context: Adding Learning Goals to Participatory Design', \"Future's Butterflies: Co-Designing ICT Wayfaring Technology with Refugee Syrian Youth\", \"Identity Work on Social Media Sites: Disadvantaged Students' College Transition Processes\", 'Remixing as a Pathway to Computational Thinking', 'Learnersourcing Personalized Hints', 'RichReview++: Deployment of a Collaborative Multi-modal Annotation System for Instructor Feedback and Peer Discussion', 'Do Massive Open Online Course Platforms Support Employability?'], 'abstract': [\"Online courses on sites such as Coursera use quizzes embedded inside lecture videos (in-video quizzes) to help learners test their understanding of the video. This paper analyzes how users interact with in-video quizzes, and how in-video quizzes influence users' lecture viewing behavior. We analyze the viewing logs of users who took the Machine Learning course on Coursera. Users engage heavily with in-video quizzes -- 74% of viewers who start watching a video will attempt its corresponding in-video quiz. We observe spikes in seek activity surrounding in-video quizzes, particularly seeks from the in-video quiz to the preceding section. We show that this is likely due to users reviewing the preceding section to help them answer the quiz, as the majority of users who seek backwards from in-video quizzes have not yet submitted a correct answer, but will later attempt the quiz. Some users appear to use quiz-oriented navigation strategies, such as seeking directly from the start of the video to in-video quizzes, or skipping from one quiz to the next. We discuss implications of our findings on the design of lecture-viewing platforms.\", 'In October 2014, one-time MOOC developer Udacity completed its transition from primarily producing massive, open online courses to producing job-focused, project-based microcredentials called \"Nanodegree\" programs. With this transition came a challenge: whereas MOOCs focus on automated assessment and peer-to-peer grading, project-based microcredentials would only be feasible with expert evaluation. With dreams of enrolling tens of thousands of students at a time, the major obstacle became project evaluation. To address this, Udacity developed a system for hiring external experts as project reviewers. A year later, this system has supported project evaluation on a massive scale: 61,000 projects have been evaluated in 12 months, with 50% evaluated within 2.5 hours (and 88% within 24 hours) of submission. More importantly, students rate the feedback they receive very highly at 4.8/5.0. In this paper, we discuss the structure of the project review system, including the nature of the projects, the structure of the feedback, and the data described above.', \"While explanations may help people learn by providing information about why an answer is correct, many problems on online platforms lack high-quality explanations. This paper presents AXIS (Adaptive eXplanation Improvement System), a system for obtaining explanations. AXIS asks learners to generate, revise, and evaluate explanations as they solve a problem, and then uses machine learning to dynamically determine which explanation to present to a future learner, based on previous learners' collective input. Results from a case study deployment and a randomized experiment demonstrate that AXIS elicits and identifies explanations that learners find helpful. Providing explanations from AXIS also objectively enhanced learning, when compared to the default practice where learners solved problems and received answers without explanations. The rated quality and learning benefit of AXIS explanations did not differ from explanations generated by an experienced instructor.\", \"Completion rates for massive open online classes (MOOCs) are notoriously low. Identifying student patterns related to course completion may help to develop interventions that can improve retention and learning outcomes in MOOCs. Previous research predicting MOOC completion has focused on click-stream data, student demographics, and natural language processing (NLP) analyses. However, most of these analyses have not taken full advantage of the multiple types of data available. This study combines click-stream data and NLP approaches to examine if students' on-line activity and the language they produce in the online discussion forum is predictive of successful class completion. We study this analysis in the context of a subsample of 320 students who completed at least one graded assignment and produced at least 50 words in discussion forums, in a MOOC on educational data mining. The findings indicate that a mix of click-stream data and NLP indices can predict with substantial accuracy (78%) whether students complete the MOOC. This predictive power suggests that student interaction data and language data within a MOOC can help us both to understand student retention in MOOCs and to develop automated signals of student success.\", \"The widespread adoption of Learning Analytics (LA) and Educational Data Mining (EDM) has somewhat stagnated recently, and in some prominent cases even been reversed following concerns by governments, stakeholders and civil rights groups about privacy and ethics applied to the handling of personal data. In this ongoing discussion, fears and realities are often indistinguishably mixed up, leading to an atmosphere of uncertainty among potential beneficiaries of Learning Analytics, as well as hesitations among institutional managers who aim to innovate their institution's learning support by implementing data and analytics with a view on improving student success. In this paper, we try to get to the heart of the matter, by analysing the most common views and the propositions made by the LA community to solve them. We conclude the paper with an eight-point checklist named DELICATE that can be applied by researchers, policy makers and institutional managers to facilitate a trusted implementation of Learning Analytics.\", \"This paper describes open learner models as visualisations of learning for learners, with a particular focus on how information about their learning can be used to help them reflect on their skills, identify gaps in their skills, and plan their future learning. We offer an approach that, in addition to providing visualisations of their learning, allows learners to propose changes to their learner model. This aims to help improve the accuracy of the learner model by taking into account student viewpoints on their learning, while also promoting learner reflection on their learning as part of a discussion of the content of their learner model. This aligns well with recent calls for learning analytics for learners. Building on previous research showing that learners will use open learner models, we here investigate their initial reactions to open learner model features to identify the likelihood of uptake in contexts where an open learner model is offered on an optional basis. We focus on university students' perceptions of a range of visualisations and their stated preferences for a facility to view evidence for the learner model data and to propose changes to the values.\", 'In this paper we present a learning analytics conceptual framework that supports enquiry-based evaluation of learning designs. The dimensions of the proposed framework emerged from a review of existing analytics tools, the analysis of interviews with teachers, and user scenarios to understand what types of analytics would be useful in evaluating a learning activity in relation to pedagogical intent. The proposed framework incorporates various types of analytics, with the teacher playing a key role in bringing context to the analysis and making decisions on the feedback provided to students as well as the scaffolding and adaptation of the learning design. The framework consists of five dimensions: temporal analytics, tool-specific analytics, cohort dynamics, comparative analytics and contingency. Specific metrics and visualisations are defined for each dimension of the conceptual framework. Finally the development of a tool that partially implements the conceptual framework is discussed.', 'We present the Mastery Grids system, an intelligent interface for online learning content that combines open learner modeling (OLM) and social comparison features. We grounded the design of Mastery Grids in self-regulated learning and learning motivation theories, as well as in our past work in social comparison, OLM, and adaptive navigation support. The force behind the interface is the combination of adaptive navigation functionality with the mastery-oriented aspects of OLM and the performance-oriented aspects of social comparison. We examined different configurations of Mastery Grids in two classroom studies and report the results of analysis of log data and survey responses. The results show how Mastery Grids interacts with different factors, like gender and achievement-goal orientation, and ultimately, its impact on student engagement, performance, and motivation.', 'We present the findings from a longitudinal study of iPad use in a Primary school classroom. While tablet devices have found their way into classroom environments, we still lack in-depth and long-term studies of how they integrate into everyday classroom activities. Our findings illustrate in-classroom tablet use and the broad range of learning activities in subjects such as maths, languages, social sciences, and even physical education. Our observations expand current models on teaching and learning supported by tablet technology. Our findings are child-centred, focusing on three different roles that tablets can play as part of learning activities: Friend, Functionary, and Facilitator. This new perspective on in-classroom tablet use can facilitate critical discussions around the integration and impact of these devices in the educational context, from a design and educational point of view.', \"Peer assessment is rapidly growing in online learning, as it presents a method to address scalability challenges. However, research suggests that the benefits of peer review are obtained inconsistently. This paper explores why, introducing three ways that framing task goals significantly changes reviews. Three experiments manipulated features in the review environment. First, adding a numeric scale to open text reviews was found to elicit more explanatory, but lower quality reviews. Second, structuring a review task into short, chunked stages elicited more diverse feedback. Finally, showing reviewers a draft along with finished work elicited reviews that focused more on the work's goals than aesthetic details. These findings demonstrate the importance of carefully structuring online learning environments to ensure high quality peer reviews.\", 'More people are learning to code than ever, but most learning opportunities do not explicitly teach the problem solving skills necessary to succeed at open-ended programming problems. In this paper, we present a new approach to impart these skills, consisting of: 1) explicit instruction on programming problem solving, which frames coding as a process of translating mental representations of problems and solutions into source code, 2) a method of visualizing and monitoring progression through six problem solving stages, 3) explicit, on-demand prompts for learners to reflect on their strategies when seeking help from instructors, and 4) context-sensitive help embedded in a code editor that reinforces the problem solving instruction. We experimentally evaluated the effects of our intervention across two 2-week web development summer camps with 48 high school students, finding that the intervention increased productivity, independence, programming self-efficacy, metacognitive awareness, and growth mindset. We discuss the implications of these results on learning technologies and classroom instruction.', \"Maintaining work focus when on a computer is a major challenge, and people often feel that they use their time ineffectively. To improve focus we designed meTime, a real-time awareness application that shows users how they allocate their time across applications. In two real-world deployments involving 118 participants, we examined whether greater awareness of time use improves focus. In our first deployment, we provided awareness information using meTime, to both office workers and students. Exposure to meTime reduced use of social media, email, browsing and total time online. However increased awareness didn't affect time spent in productivity applications. A second educational deployment largely replicated these results and showed that meTime also reduced users' perceptions of their ability to focus effectively. Changed perceptions were associated with higher class grades. We discuss practical and theoretical implications as well as design principles for use of time applications.\", \"We present Brain Automated Chorales (BACh), an adaptive brain-computer system that dynamically increases the levels of difficulty in a musical learning task based on pianists' cognitive workload measured by functional near-infrared spectroscopy. As users' cognitive workload fell below a certain threshold, suggesting that they had mastered the material and could handle more cognitive information, BACh automatically increased the difficulty of the learning task. We found that learners played with significantly increased accuracy and speed in the brain-based adaptive task compared to our control condition. Participant feedback indicated that they felt they learned better with BACh and they liked the timings of the level changes. The underlying premise of BACh can be applied to learning situations where a task can be broken down into increasing levels of difficulty.\", \"We take a qualitative approach to understanding deaf and hard of hearing (DHH) students' experiences with real-time captioning as an access technology in mainstream university classrooms. We consider both existing human-based captioning as well as new machine-based solutions that use automatic speech recognition (ASR). We employed a variety of qualitative research methods to gather data about students' captioning experiences including in-class observations, interviews, diary studies, and usability evaluations. We also conducted a co-design workshop with 8 stakeholders after our initial research findings. Our results show that accuracy and reliability of the technology are still the most important issues across captioning solutions. However, we additionally found that current captioning solutions tend to limit students' autonomy in the classroom and present a variety of user experience shortcomings, such as complex setups, poor feedback and limited control over caption presentation. Based on these findings, we propose design requirements and recommend features for real-time captioning in mainstream classrooms.\", 'In this paper we examine the challenges of introducing learning goals in Participatory Design (PD) activities in a school context. In order to increase the transparency of mutual learning in accordance with traditional PD values, we argue that learning through design approaches can inspire us to actively formulate learning goals, stage activities and include reflection as an integral part in the PD activity in order to meet those learning goals. We tested this approach in several master student projects, where the students were required to involve children in schools in the design of a technology. Our data analysis is based on their written reports as well as a specific exam question. We found that defining good learning goals was hard, but useful, especially when designing and discussing informed consent forms with teachers. Staging activities in order to meet the learning goals was possible, although learning goals were sometimes derived from the activities. Finally, incorporating moments of reflection for children was still difficult for our students because they felt pressed for time. We present some of the advantages and problems so that practitioners can consider the added value of this approach.', \"We conducted participatory design workshops at the UNHCR Za'atari refugee camp in Jordan to learn how Syrian youth help others using information and technology. We asked 144 young people to create paper prototypes of visionary devices for helping their community and analyzed the designs for themes using qualitative techniques. The 61 drawings helped provide additional context for the community's challenges, including information problems and limited access to education. Findings also showed that Syrian refugee youth play important roles in helping others. We developed and tested a youth-focused co-design approach and contributed to a greater understanding of the experiences of Syrian refugee youth. As millions of Syrians continue to be displaced, our work may have implications for helping identify the refugees' needs and inform humanitarian response.\", 'Prior research suggests that some social media practices can play a role in shaping studentsâÂ€Â™ adjustment to college; however, the specific mechanisms by which social media can support the identity work associated with successful transitions to college are not well understood. This paper investigates how social media experiences and interactions can support college-focused identity construction for low-income, first-generation college students. Drawing on in-depth, semi-structured interviews with 31 emergent adults from disadvantaged backgrounds in the United States, we identify social media affordances that support the process of identity work during a critical transition period. Findings indicate that social media platforms support provisional identity work, but disadvantaged college students lack access to mentor-like figures that could be accessible through social media. We also find barriers to sharing information online that may extend to other life transitions in multiple life contexts and review the design implications of our findings.', 'Theorists and advocates of “remixing” have suggested that appropriation can act as a pathway for learning. We test this theory quantitatively using data from more than 2.4 million multimedia programming projects shared by more than 1 million users in the Scratch online community. First, we show that users who remix more often have larger repertoires of programming commands even after controlling for the numbers of projects and amount of code shared. Second, we show that exposure to computational thinking concepts through remixing is associated with increased likelihood of using those concepts. Our results support theories that young people learn through remixing, and have important implications for designers of social computing systems.', 'Personalized support for students is a gold standard in education, but it scales poorly with the number of students. Prior work on learnersourcing presented an approach for learners to engage in human computation tasks while trying to learn a new skill. Our key insight is that students, through their own experience struggling with a particular problem, can become experts on the particular optimizations they implement or bugs they resolve. These students can then generate hints for fellow students based on their new expertise. We present workflows that harvest and organize studentsâ?? collective knowledge and advice for helping fellow novices through design problems in engineering. Systems embodying each workflow were evaluated in the context of a college-level computer architecture class with an enrollment of more than two hundred students each semester. We show that, given our design choices, students can create helpful hints for their peers that augment or even replace teachersâ?? personalized assistance, when that assistance is not available.', 'New multi-modal annotation tools hold the promise of bringing the benefits of face-to-face contact to remote, asynchronous interactions. One such system, RichReview++, incorporates new techniques to improve access to the embedded multimedia commentary and allows users to annotate with new modalities, like deictic gestures. We conducted a series of field deployments of RichReview++ to characterize how these features benefit students using them for activities in the university classroom. Our first deployment investigated the use of multi-modal annotations as a way for instructors to provide feedback on student term papers. Our second deployment used annotations to support peer discussion about assigned readings in a graduate-level course. We found that presenting voice comments as interactive waveforms seems to facilitate studentsâ?? consumption of the instructorâ??s voice comments. We also found that gestural annotations clarify voice and give annotators a quick and lightweight way to alter the scope of their voice comments. Based on these results, we suggest ways to best leverage multi-modal annotation tools in education environments.', 'Past research suggests that many individuals take Massive Open Online Courses (MOOCs) for employment-related reasons. It is unclear, however, how learners leverage MOOCs for employment and how effectively these platforms support employability. To explore this further, we surveyed 441 learners and interviewed 22 learners motivated to take MOOCs for reasons related to financial limitations and/or reasons related to employment. Using the three dimensions of employability as a frameworkâ??human and social capital, career identity, and personal adaptabilityâ??we find that while most of our participants were optimistic about the potential for MOOCs to improve their employability, there was very limited tangible evidence of employment mobility from taking MOOCs. Though MOOCs support human capital, there are opportunities to further support social capital, career identity, and personal adaptability. We contribute a deeper understanding of learners who use MOOCs for employment and provide concrete design implications for MOOC platforms to better support employability in the future. We found very few low SES learners using MOOCs for reasons of employment and identify opportunities for MOOCs to reach and support these learners.']}, '2019': {'title': [], 'abstract': []}, '2015': {'title': ['A Playful Game Changer: Fostering Student Retention in Online Education with Social Gamification', 'Attrition and Achievement Gaps in Online Learning', 'Uncovering Trajectories of Informal Learning in Large Online Communities of Creators', 'PeerStudio: Rapid Peer Feedback Emphasizes Revision and Improves Performance', 'Learning is Not a Spectator Sport: Doing is Better than Watching for Learning from a MOOC', 'Autonomously Generating Hints by Inferring Problem Solving Policies', 'Learning analytics beyond the LMS: the connected learning analytics toolkit', 'Examining engagement: analysing learner subpopulations in massive open online courses (MOOCs)', 'Unsupervised modeling for understanding MOOC discussion forums: a learning analytics approach', 'Codeopticon: Real-Time, One-To-Many Human Tutoring for Computer Programming', 'Automatic Detection of Learning-Centered Affective States in the Wild', 'Mudslide: A Spatially Anchored Census of Student Confusion for Online Lecture Videos', 'Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos', ': Haptic Feedback to Enhance Early Reading', 'Wait-Learning: Leveraging Wait Time for Second Language Education', 'RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos', \"To block or not to block, that is the question: students' perceptions of blocks-based programming\", 'Pencil code: block code for a text world', 'Motivation as a Lens to Understand Online Learners: Toward Data-Driven Design with the OLEI Scale', 'OverCode: Visualizing Variation in Student Solutions to Programming Problems at Scale', 'Teaching and Developing Social and Emotional Skills with Technology', 'Learnersourcing Subgoal Labels for How-to Videos', 'Structuring Interactions for Large-Scale Synchronous Peer Learning', 'A Classroom Study of Using Crowd Feedback in the Iterative Design Process', 'MoodLight: Exploring Personal and Social Implications of Ambient Display of Biosensor Data', 'Understanding Student Motivation, Behaviors and Perceptions in MOOCs', 'Piloting TrACE: Exploring Spatiotemporal Anchored Collaboration in Asynchronous Learning', 'Talkabout: Making Distance Matter with Small Groups in Massive Classes', 'From computational thinking to computational making', 'SmartGPA: how smartphones can assess and predict academic performance of college students'], 'abstract': ['Many MOOCs report high drop off rates for their students. Among the factors reportedly contributing to this picture are lack of motivation, feelings of isolation, and lack of interactivity in MOOCs. This paper investigates the potential of gamification with social game elements for increasing retention and learning success. Students in our experiment showed a significant increase of 25% in retention period (videos watched) and 23% higher average scores when the course interface was gamified. Social game elements amplify this effect significantly -- students in this condition showed an increase of 50% in retention period and 40% higher average test scores.', 'Attrition in online learning is generally higher than in traditional settings, especially in large-scale online learning environments. A systematic analysis of individual differences in attrition and performance in 20 massive open online courses (N > 67,000) revealed a geographic achievement gap and a gender achievement gap. Online learners in Africa, Asia, and Latin America scored substantially lower grades and were only half as likely to persist than those in Europe, Oceania, and Northern America. Women also exhibited lower persistence and performance than men. Yet more persistent learners were only marginally more satisfied with their achievement. The primary obstacle for most learners was finding time for the course, which was partly related to low levels of volitional control. Self-ascribed successful learners reported higher levels of goal striving, growth mindset, and feelings of social belonging than unsuccessful ones. Insights into why learners leave online courses inform models of attrition and targeted interventions to support learners achieve their goals.', 'We analyzed informal learning in Scratch Online -- an online community with over 4.3 million users and 6.7 million user-generated content. Users develop projects, which are graphical interfaces involving manipulation of programming blocks. We investigated two fundamental questions: how can we model informal learning, and what patterns of informal learning emerge. We proceeded in two phases. First, we modeled learning as a trajectory of cumulative programming block usage by long-term users who created at least 50 projects. Second, we applied K-means++ clustering to uncover patterns of learning and corresponding subpopulations. We found four groups of users manifesting four different patterns of learning, ranging from the smallest to the largest improvement. At one end of the spectrum, users learned more and in a faster manner. At the opposite end, users did not show much learning, even after creating dozens of projects. The modeling and clustering of trajectory patterns that enabled us to quantitatively analyze informal learning may be applicable to other similar communities. The results can also support administrators of online communities in implementing customized interventions for specific subpopulations.', \"Rapid feedback is a core component of mastery learning, but feedback on open-ended work requires days or weeks in most classes today. This paper introduces PeerStudio, an assessment platform that leverages the large number of students' peers in online classes to enable rapid feedback on in-progress work. Students submit their draft, give rubric-based feedback on two peers' drafts, and then receive peer feedback. Students can integrate the feedback and repeat this process as often as they desire. In MOOC deployments, the median student received feedback in just twenty minutes. Rapid feedback on in-progress work improves course outcomes: in a controlled experiment, students' final grades improved when feedback was delivered quickly, but not if delayed by 24 hours. More than 3,600 students have used PeerStudio in eight classes, both massive and in-person. This research demonstrates how large classes can leverage their scale to encourage mastery through rapid feedback and revision.\", \"The printing press long ago and the computer today have made widespread access to information possible. Learning theorists have suggested, however, that mere information is a poor way to learn. Instead, more effective learning comes through doing. While the most popularized element of today's MOOCs are the video lectures, many MOOCs also include interactive activities that can afford learning by doing. This paper explores the learning benefits of the use of informational assets (e.g., videos and text) in MOOCs, versus the learning by doing opportunities that interactive activities provide. We find that students doing more activities learn more than students watching more videos or reading more pages. We estimate the learning benefit from extra doing (1 SD increase) to be more than six times that of extra watching or reading. Our data, from a psychology MOOC, is correlational in character, however we employ causal inference mechanisms to lend support for the claim that the associations we find are causal.\", \"Exploring the whole sequence of steps a student takes to produce work, and the patterns that emerge from thousands of such sequences is fertile ground for a richer understanding of learning. In this paper we autonomously generate hints for the Code.org `Hour of Code,' (which is to the best of our knowledge the largest online course to date) using historical student data. We first develop a family of algorithms that can predict the way an expert teacher would encourage a student to make forward progress. Such predictions can form the basis for effective hint generation systems. The algorithms are more accurate than current state-of-the-art methods at recreating expert suggestions, are easy to implement and scale well. We then show that the same framework which motivated the hint generating algorithms suggests a sequence-based statistic that can be measured for each learner. We discover that this statistic is highly predictive of a student's future success.\", 'We present a Connected Learning Analytics (CLA) toolkit, which enables data to be extracted from social media and imported into a Learning Record Store (LRS), as defined by the new xAPI standard. A number of implementation issues are discussed, and a mapping that will enable the consistent storage and then analysis of xAPI verb/object/activity statements across different social media and online environments is introduced. A set of example learning activities are proposed, each facilitated by the Learning Analytics beyond the LMS that the toolkit enables.', 'Massive open online courses (MOOCs) are now being used across the world to provide millions of learners with access to education. Many learners complete these courses successfully, or to their own satisfaction, but the high numbers who do not finish remain a subject of concern for platform providers and educators. In 2013, a team from Stanford University analysed engagement patterns on three MOOCs run on the Coursera platform. They found four distinct patterns of engagement that emerged from MOOCs based on videos and assessments. However, not all platforms take this approach to learning design. Courses on the FutureLearn platform are underpinned by a social-constructivist pedagogy, which includes discussion as an important element. In this paper, we analyse engagement patterns on four FutureLearn MOOCs and find that only two clusters identified previously apply in this case. Instead, we see seven distinct patterns of engagement: Samplers, Strong Starters, Returners, Mid-way Dropouts, Nearly There, Late Completers and Keen Completers. This suggests that patterns of engagement in these massive learning environments are influenced by decisions about pedagogy. We also make some observations about approaches to clustering in this context.', \"Massively Open Online Courses (MOOCs) have gained attention recently because of their great potential to reach learners. Substantial empirical study has focused on student persistence and their interactions with the course materials. However, most MOOCs include a rich textual dialogue forum, and these textual interactions are largely unexplored. Automatically understanding the nature of discussion forum posts holds great promise for providing adaptive support to individual students and to collaborative groups. This paper presents a study that applies unsupervised student understanding models originally developed for synchronous tutorial dialogue to MOOC forums. We use a clustering approach to group similar posts, compare the clusters with manual annotations by MOOC researchers, and further investigate clusters qualitatively. This paper constitutes a step toward applying unsupervised models to asynchronous communication, which can enable massive-scale automated discourse analysis and mining to better support students' learning.\", '\" One-on-one tutoring from a human expert is an effective way for novices to overcome learning barriers in complex domains such as computer programming. But there are usually far fewer experts than learners. To enable a single expert to help more learners at once, we built Codeopticon, an interface that enables a programming tutor to monitor and chat with dozens of learners in real time. Each learner codes in a workspace that consists of an editor, compiler, and visual debugger. The tutor sees a real-time view of each learner\\'s actions on a dashboard, with each learner\\'s workspace summarized in a tile. At a glance, the tutor can see how learners are editing and debugging their code, and what errors they are encountering. The dashboard automatically reshuffles tiles so that the most active learners are always in the tutor\\'s main field of view. When the tutor sees that a particular learner needs help, they can open an embedded chat window to start a one-on-one conversation. A user study showed that 8 first-time Codeopticon users successfully tutored anonymous learners from 54 countries in a naturalistic online setting. On average, in a 30-minute session, each tutor monitored 226 learners, started 12 conversations, exchanged 47 chats, and helped 2.4 learners.', \"Affect detection is a key component in developing intelligent educational interfaces that are capable of responding to the affective needs of students. In this paper, computer vision and machine learning techniques were used to detect students' affect as they used an educational game designed to teach fundamental principles of Newtonian physics. Data were collected in the real-world environment of a school computer lab, which provides unique challenges for detection of affect from facial expressions (primary channel) and gross body movements (secondary channel) - up to thirty students at a time participated in the class, moving around, gesturing, and talking to each other. Results were cross validated at the student level to ensure generalization to new students. Classification was successful at levels above chance for off-task behavior (area under receiver operating characteristic curve or (AUC = .816) and each affective state including boredom (AUC =.610), confusion (.649), delight (.867), engagement (.679), and frustration (.631) as well as a five-way overall classification of affect (.655), despite the noisy nature of the data. Implications and prospects for affect-sensitive interfaces for educational software in classroom environments are discussed.\", 'Educators have developed an effective technique to get feedback after in-person lectures, called \"muddy cards.\" Students are given time to reflect and write the \"muddiest\" (least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students\\' muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers\\' and students\\' experiences with our prototype.', \"Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity. Moreover, the content of comments would further affect learners' intention of commenting. Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education.\", \"Engaging children with traditional approaches in education, especially reading, grows ever more difficult in the face of their attachment to tablets and computer games. We explore the possibility of making the story reading experience more interesting and memorable for children using haptic augmentation. In this paper, we present FeelSleeve, an interface that allows children to feel story events in their hands while they are reading on a mobile device. FeelSleeve uses transducers and audio output from the tablet within a gloved attachment to create vibratory effects that are meaningfully related to story content. We describe a study investigating whether embedding such haptic feedback into stories enhances reading for six to nine year olds. Our results indicate that story events accompanied by haptic feedback are better comprehended and appear to be more salient in memory. These results provide evidence that haptic effects have the potential to improve children's reading experience and make it more memorable.\", \"Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. In this paper, we explore wait-learning: leveraging brief moments of waiting during a person's existing conversations for second language vocabulary practice, even if the conversation happens in the native language. We present an augmented version of instant messaging, WaitChatter, that supports the notion of wait-learning by displaying contextually relevant foreign language vocabulary and micro-quizzes just-in-time while the user awaits a response from her conversant. Through a two week field study of WaitChatter with 20 people, we found that users were able to learn 57 new words on average during casual instant messaging. Furthermore, we found that users were most receptive to learning opportunities immediately after sending a chat message, and that this timing may be critical given user tendency to multi-task during waiting periods.\", \"Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners' responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural knowledge. Teachers found the exercises useful for capturing students' thought processes, identifying misconceptions, and engaging students with content.\", 'Blocks-based programming tools are becoming increasingly common in high-school introductory computer science classes. Such contexts are quite different than the younger audience and informal settings where these tools are more often used. This paper reports findings from a study looking at how high school students view blocks-based programming tools, what they identify as contributing to the perceived ease-of-use of such tools, and what they see as the most salient differences between blocks-based and text-based programming. Students report that numerous factors contribute to making blocks-based programming easy, including the natural language description of blocks, the drag-and-drop composition interaction, and the ease of browsing the language. Students also identify drawbacks to blocks-based programming compared to the conventional text-based approach, including a perceived lack of authenticity and being less powerful. These findings, along with the identified differences between blocks-based and text-based programming, contribute to our understanding of the suitability of using such tools in formal high school settings and can be used to inform the design of new, and revision of existing, introductory programming tools.', 'Pencil Code is a block-based coding tool that helps beginners work with text-based web programming languages. It has been used to allow help first-time programmers of all ages create programs in JavaScript and CoffeeScript. Pencil Code allows students to toggle between text code and blocks freely. This approach allows students to transition smoothly from blocks to text as they become familiar with syntax. It also allows educators to create block vocabularies for specific lessons without working with an entirely new programming language.', \"Open online learning environments attract an audience with diverse motivations who interact with structured courses in several ways. To systematically describe the motivations of these learners, we developed the Online Learning Enrollment Intentions (OLEI) scale, a 13-item questionnaire derived from open-ended responses to capture learners' authentic perspectives. Although motivations varied across courses, we found that each motivation predicted key behavioral outcomes for learners (N = 71, 475 across 14 courses). From learners' motivational and behavioral patterns, we infer a variety of needs that they seek to gratify by engaging with the courses, such as meeting new people and learning English. To meet these needs, we propose multiple design directions, including virtual social spaces outside any particular course, improved support for local groups of learners, and modularization to promote accessibility and organization of course content. Motivations thus provide a lens for understanding online learners and designing online courses to better support their needs.\", \"In MOOCs, a single programming exercise may produce thousands of solutions from learners. Understanding solution variation is important for providing appropriate feedback to students at scale. The wide variation among these solutions can be a source of pedagogically valuable examples and can be used to refine the autograder for the exercise by exposing corner cases. We present OverCode, a system for visualizing and exploring thousands of programming solutions. OverCode uses both static and dynamic analysis to cluster similar solutions, and lets teachers further filter and cluster solutions based on different criteria. We evaluated OverCode against a nonclustering baseline in a within-subjects study with 24 teaching assistants and found that the OverCode interface allows teachers to more quickly develop a high-level view of students' understanding and misconceptions, and to provide feedback that is relevant to more students' solutions.\", 'Supporting social interactions is a long-term focus for Human Computer Interaction (HCI) and Computer Supported Cooperative Work (CSCW). However, understanding how social and emotional skills are learned, and how this process can be supported by technology, is an important but underresearched area in HCI so far. To address this gap, we review existing approaches to social and emotions skills learning (SEL) in other fields, with a specific focus on SEL in education, in which a large number of evidence-based programs is widely deployed. In doing so, the primary aim of this article is to provide a foundation and set an agenda for future research on the design of technology that would support, and help teach, social and emotional skills. We identify the key challenges to successful learning shared by SEL programs in education—such as embedding skills learned in class also into everyday situations, promoting reflection, and providing additional opportunities for practice—and outline how these could be addressed by digital technology. Overall, our key argument is that much existing HCI work could be used in support of social and emotional skills learning in education, and possibly other domains, but that the topic has not been explored so far. We also highlight how the focus on supporting SEL would bring novel opportunities and challenges for HCI, as well as provide a basis for a strong HCI research agenda in this space.', 'Websites like YouTube host millions of how-to videos, but their interfaces are not optimized for learning. Previous research suggests that people learn more from how-to videos when the videos are accompanied by outlines showing individual steps and labels for groups of steps (subgoals). We envision an alternative video player where the steps and subgoals are displayed alongside the video. To generate this information for existing videos, we introduce learnersourcing, an approach in which intrinsically motivated learners contribute to a human computation workflow as they naturally go about learning from the videos. To demonstrate this method, we deployed a live website with a workflow for constructing subgoal labels implemented on a set of introductory web programming videos. For the four videos with the highest participation, we found that a majority of learner-generated subgoals were comparable in quality to expert-generated ones. Learners commented that the system helped them grasp the material, suggesting that our workflow did not detract from the learning experience.', 'This research investigates how to introduce synchronous interactive peer learning into an online setting appropriate both for crowdworkers (learning new tasks) and students in massive online courses (learning course material). We present an interaction framework in which groups of learners are formed on demand and then proceed through a sequence of activities that include synchronous group discussion about learner-generated responses. Via controlled experiments with crowdworkers, we show that discussing challenging problems leads to better outcomes than working individually, and incentivizing people to help one another yields still better results. We then show that providing a mini-lesson in which workers consider the principles underlying the tested concept and justify their answers leads to further improvements. Combining the mini-lesson with the discussion of the multiple-choice question leads to significant improvements on that question. We also find positive subjective responses to the peer interactions, suggesting that discussions can improve morale in remote work or learning settings.', 'Crowd feedback systems offer designers an emerging approach for improving their designs, but there is little empirical evidence of the benefit of these systems. This paper reports the results of a study of using a crowd feedback system to iterate on visual designs. Users in an introductory visual design course created initial designs satisfying a design brief and received crowd feedback on the designs. Users revised the designs and the system was used to generate feedback again. This format enabled us to detect the changes between the initial and revised designs and how the feedback related to those changes. Further, we analyzed the value of crowd feedback by comparing it with expert evaluation and feedback generated via free-form prompts. Results showed that the crowd feedback system prompted deep and cosmetic changes and led to improved designs, the crowd recognized the design improvements, and structured workflows generated more interpretative, diverse and critical feedback than free-form prompts.', \"MoodLight is an interactive ambient lighting system that responds to biosensor input related to an individual's current level of arousal. Changes in levels of arousal correspond to fluctuations in the color of light provided by the system, altering the immediate environment in ways intimately related to the user's private internal state. We use this intervention to explore personal and social implications of the ambient display of biosensor data. A design probe study conducted with university students provided the opportunity to observe MoodLight being used by individuals and dyads. Discussion of findings highlights key tensions associated with the dialectics of technology-mediated self-awareness and automated disclosure of personal information, addressing issues of agency, skepticism and uncertainty. This study provides greater understanding of the ways in which the representations of personal informatics, with a focus on ambient feedback, influence our perceptions of ourselves and those around us.\", \"Massive Open Online Courses (MOOCs) have recently experienced rapid development and garnered significant attention from various populations. Despite the wide recognition of MOOCs as an important opportunity within educational practices, there are still many questions as to how we might satisfy students' needs, as evidenced by very high dropout rates. Researchers lack a solid understanding of what student needs are being addressed by MOOCs, and how well MOOCs now address (or fail to address) these needs. To help in building such an understanding, we conducted in-depth interviews probing student motivations, learning perceptions and experiences towards MOOCs, paying special attention to the MOOC affordances and experiences that might lead to high drop rates. Our study identified learning motivations, learning patterns, and a number of factors that appear to influence student retention. We proposed that the issue of retention should be addressed from two perspectives: retention as a problem but also retention as an opportunity.\", \"The use of multimedia content such as video is becoming more prevalent in educational environments. However, current platforms for hosting these media provide few collaborative tools to foster social learning between students or request help from instructors. In this paper, we explore the potential of spatiotemporal anchored collaboration, and we present a prototype media-playback environment called TrACE that exemplifies the approach. We examine a first design-based research (DBR) pilot deployment of TrACE in two post-secondary courses. Results indicate that students do take advantage of the system's affordances to interact in meaningful ways, though overall student annotation authoring was limited. Using the pilot data, we propose socio-technical modifications for the next iteration in the DBR cycle. Specifically we focus on tools to support instructors' use of the system and for promoting collaboration between students.\", \"Massive online classes are global and diverse. How can we harness this diversity to improve engagement and learning? Currently, though enrollments are high, students' interactions with each other are minimal: most are alone together. This isolation is particularly disappointing given that a global community is a major draw of online classes. This paper illustrates the potential of leveraging geographic diversity in massive online classes. We connect students from around the world through small-group video discussions. Our peer discussion system, Talkabout, has connected over 5,000 students in fourteen online classes. Three studies with 2,670 students from two classes found that globally diverse discussions boost student performance and engagement: the more geographically diverse the discussion group, the better the students performed on later quizzes. Through this work, we challenge the view that online classes are useful only when in-person classes are unavailable. Instead, we demonstrate how diverse online classrooms can create benefits that are largely unavailable in a traditional classroom.\", \"Computational thinking is considered best practice for teaching computing and more broadly to solve problems and design systems, however as computing extends beyond the desktop (for instance increased integration of ubicomp technologies) so too must our educational methods. Exposure to ubicomp technologies is most accessible through the maker movement. With this in mind we argue we must move from computational thinking to computational making as an educational framework. Here we present a case study of children's making to support our vision for a broader conception of computational making.\", \"Many cognitive, behavioral, and environmental factors impact student learning during college. The SmartGPA study uses passive sensing data and self-reports from students' smartphones to understand individual behavioral differences between high and low performers during a single 10-week term. We propose new methods for better understanding study (e.g., study duration) and social (e.g., partying) behavior of a group of undergraduates. We show that there are a number of important behavioral factors automatically inferred from smartphones that significantly correlate with term and cumulative GPA, including time series analysis of activity, conversational interaction, mobility, class attendance, studying, and partying. We propose a simple model based on linear regression with lasso regularization that can accurately predict cumulative GPA. The predicted GPA strongly correlates with the ground truth from students' transcripts (r = 0:81 and p < 0:001) and predicts GPA within ±0:179 of the reported grades. Our results open the way for novel interventions to improve academic performance.\"]}, '2014': {'title': ['Student skill and goal achievement in the mapping with google MOOC', 'Superposter behavior in MOOC forums', 'Social factors that contribute to attrition in MOOCs', 'How video production affects student engagement: an empirical study of MOOC videos', 'Divide and correct: using clusters to grade short answers at scale', 'Demographic differences in how students navigate through MOOCs', 'Understanding in-video dropouts and interaction peaks inonline lecture videos', 'Chatrooms in MOOCs: all talk and no action', 'Visualizing patterns of student engagement and performance in MOOCs', 'Designing pedagogical interventions to support student use of learning analytics', 'Sewing interest in E-textiles: analyzing making from a gendered perspective', 'Data-driven interaction techniques for improving navigation of educational videos', 'StepStream: a school-based pervasive social fitness system for everyday adolescent health', 'Brain points: a growth mindset incentive structure boosts persistence in an educational game', 'Involving children in content control: a collaborative and education-oriented content filtering approach', 'ABC and 3D: opportunities and obstacles to 3D printing in special education environments', 'Reviewing versus doing: learning and performance in crowd assessment', 'Should your MOOC forum use a reputation system?', 'StudentLife: assessing mental health, academic performance and behavioral trends of college students using smartphones'], 'abstract': [\"Students who registered for the Mapping with Google massive open online course (MOOC) were asked several questions during the registration process to identify prior experience with eleven skills as well as their goals for registering for the course. Students selected goals from a list; they were periodically reminded of these goals during the MOOC. At the end of the course, we compared students' self reports of goal achievement on a post-course survey with behavioral click-stream analysis. In addition, we assessed how well prior skill in a subject predicts a student's course completion and found no correlation. Our research shows that students who completed course activities were more likely to earn certificates of completion than peers who did not.\", 'Discussion forums, employed by MOOC providers as the primary mode of interaction among instructors and students, have emerged as one of the important components of online courses. We empirically study contribution behavior in these online collaborative learning forums using data from 44 MOOCs hosted on Coursera, focusing primarily on the highest-volume contributors---\"superposters\"---in a forum. We explore who these superposters are and study their engagement patterns across the MOOC platform, with a focus on the following question---to what extent is superposting a positive phenomenon for the forum? Specifically, while superposters clearly contribute heavily to the forum in terms of quantity, how do these contributions rate in terms of quality, and does this prolific posting behavior negatively impact contribution from the large remainder of students in the class? We analyze these questions across the courses in our dataset, and find that superposters display above-average engagement across Coursera, enrolling in more courses and obtaining better grades than the average forum participant; additionally, students who are superposters in one course are significantly more likely to be superposters in other courses they take. In terms of utility, our analysis indicates that while being neither the fastest nor the most upvoted, superposters\\' responses are speedier and receive more upvotes than the average forum user\\'s posts; a manual assessment of quality on a subset of this content supports this conclusion that a large fraction of superposter contributions indeed constitute useful content. Finally, we find that superposters\\' prolific contribution behavior does not `drown out the silent majority\\'---high superposter activity correlates positively and significantly with higher overall activity and forum health, as measured by total contribution volume, higher average perceived utility in terms of received votes, and a smaller fraction of orphaned threads.', 'In this paper, we explore student dropout behavior in a Massively Open Online Course (MOOC). We use a survival model to measure the impact of three social factors that make predictions about attrition along the way for students who have participated in the course discussion forum.', 'Videos are a widely-used kind of resource for online learning. This paper presents an empirical study of how video production decisions affect student engagement in online educational videos. To our knowledge, ours is the largest-scale study of video engagement to date, using data from 6.9 million video watching sessions across four courses on the edX MOOC platform. We measure engagement by how long students are watching each video, and whether they attempt to answer post-video assessment problems. Our main findings are that shorter videos are much more engaging, that informal talking-head videos are more engaging, that Khan-style tablet drawings are more engaging, that even high-quality pre-recorded classroom lectures might not make for engaging online videos, and that students engage differently with lecture and tutorial videos. Based upon these quantitative findings and qualitative insights from interviews with edX staff, we developed a set of recommendations to help instructors and video producers take better advantage of the online video format. Finally, to enable researchers to reproduce and build upon our findings, we have made our anonymized video watching data set and analysis scripts public. To our knowledge, ours is one of the first public data sets on MOOC resource usage.', \"In comparison to multiple choice or other recognition-oriented forms of assessment, short answer questions have been shown to offer greater value for both students and teachers; for students they can improve retention of knowledge, while for teachers they provide more insight into student understanding. Unfortunately, the same open-ended nature which makes them so valuable also makes them more difficult to grade at scale. To address this, we propose a cluster-based interface that allows teachers to read, grade, and provide feedback on large groups of answers at once. We evaluated this interface against an unclustered baseline in a within-subjects study with 25 teachers, and found that the clustered interface allows teachers to grade substantially faster, to give more feedback to students, and to develop a high-level view of students' understanding and misconceptions.\", 'The current generation of Massive Open Online Courses (MOOCs) attract a diverse student audience from all age groups and over 196 countries around the world. Researchers, educators, and the general public have recently become interested in how the learning experience in MOOCs differs from that in traditional courses. A major component of the learning experience is how students navigate through course content. This paper presents an empirical study of how students navigate through MOOCs, and is, to our knowledge, the first to investigate how navigation strategies differ by demographics such as age and country of origin. We performed data analysis on the activities of 140,546 students in four edX MOOCs and found that certificate earners skip on average 22% of the course content, that they frequently employ non-linear navigation by jumping backward to earlier lecture sequences, and that older students and those from countries with lower student-teacher ratios are more comprehensive and non-linear when navigating through the course. From these findings, we suggest design recommendations such as for MOOC platforms to develop more detailed forms of certification that incentivize students to deeply engage with the content rather than just doing the minimum necessary to earn a passing grade. Finally, to enable other researchers to reproduce and build upon our findings, we have made our data set and analysis scripts publicly available.', 'With thousands of learners watching the same online lecture videos, analyzing video watching patterns provides a unique opportunity to understand how students learn with videos. This paper reports a large-scale analysis of in-video dropout and peaks in viewership and student activity, using second-by-second user interaction data from 862 videos in four Massive Open Online Courses (MOOCs) on edX. We find higher dropout rates in longer videos, re-watching sessions (vs first-time), and tutorials (vs lectures). Peaks in re-watching sessions and play events indicate points of interest and confusion. Results show that tutorials (vs lectures) and re-watching sessions (vs first-time) lead to more frequent and sharper peaks. In attempting to reason why peaks occur by sampling 80 videos, we observe that 61% of the peaks accompany visual transitions in the video, e.g., a slide view to a classroom view. Based on this observation, we identify five student activity patterns that can explain peaks: starting from the beginning of a new material, returning to missed content, following a tutorial step, replaying a brief segment, and repeating a non-visual explanation. Our analysis has design implications for video authoring, editing, and interface design, providing a richer understanding of video learning on MOOCs.', \"We study effects of introducing a real-time chatroom into a massive open online course with several thousand students, supplementing an existing forum. The chatroom was supported by teaching assistants, and generated thousands of lines of discussion by 28\\\\% of 681 consenting chat condition participants, mostly on-topic. Despite this, chat activity remained low ($\\\\mu=8.2$ messages per hour) and we could find no significant effect of chat use on objective or subjective dependent variables such as grades, retention, forum participation, or students' sense of community. Further investigation reveals that only 12\\\\% of chat participants have substantive interactions, while the remainder are either passive or have trivial interactions that are unlikely to result in learning. We also find that pervasive, highly visible chat interfaces are highly effective in encouraging both active and substantive participation in chat. When compared to chat interfaces that are restricted to a single webpage, the pervasive interface exhibits \\\\changes{2.8 times} as many users with substantive interactions.\", \"In the last five years, the world has seen a remarkable level of interest in Massive Open Online Courses, or MOOCs. A consistent message from universities participating in MOOC delivery is their eagerness to understand students' online learning processes. This paper reports on an exploratory investigation of students' learning processes in two MOOCs which have different curriculum and assessment designs. When viewed through the lens of common MOOC learning analytics, the high level of initial student interest and, ultimately, the high level of attrition, makes these two courses appear very similar to each other, and to MOOCs in general. With the goal of developing a greater understanding of students' patterns of learning behavior in these courses, we investigated alternative learning analytic approaches and visual representations of the output of these analyses. Using these approaches we were able to meaningfully classify student types and visualize patterns of student engagement which were previously unclear. The findings from this research contribute to the educational community's understanding of students' engagement and performance in MOOCs, and also provide the broader learning analytics community with suggestions of new ways to approach learning analytic data analysis and visualization.\", 'This article addresses a relatively unexplored area in the emerging field of learning analytics, the design of learning analytics interventions. A learning analytics intervention is defined as the surrounding frame of activity through which analytic tools, data, and reports are taken up and used. It is a soft technology that involves the orchestration of the human process of engaging with the analytics as part of the larger teaching and learning activity. This paper first makes the case for the overall importance of intervention design, situating it within the larger landscape of the learning analytics field, and then considers the specific issues of intervention design for student use of learning analytics. Four principles of pedagogical learning analytics intervention design that can be used by teachers and course developers to support the productive use of learning analytics by students are introduced: Integration, Agency, Reference Frame and Dialogue. In addition three core processes in which to engage students are described: Grounding, Goal-Setting and Reflection. These principles and processes are united in a preliminary model of pedagogical learning analytics intervention design for students, presented as a starting point for further inquiry.', \"In this paper we explore the appropriateness of e-textiles for teaching programming to mixed gender groups ages 8-12, allowing children to construct maker identities around technology. Our findings demonstrate the potential of e-textiles to promote girls' and boys' computational literacy, and the required craft and programming skills for making that can disrupt binary gender roles. We argue it allows both girls and boys to demonstrate technical mastery as well as to explore and construct a spectrum of gendered sociotechnical identities that might otherwise be obscured by conventional masculinist attitudes towards technology.\", 'With an unprecedented scale of learners watching educational videos on online platforms such as MOOCs and YouTube, there is an opportunity to incorporate data generated from their interactions into the design of novel video interaction techniques. Interaction data has the potential to help not only instructors to improve their videos, but also to enrich the learning experience of educational video watchers. This paper explores the design space of data-driven interaction techniques for educational video navigation. We introduce a set of techniques that augment existing video interface widgets, including: a 2D video timeline with an embedded visualization of collective navigation traces; dynamic and non-linear timeline scrubbing; data-enhanced transcript search and keyword summary; automatic display of relevant still frames next to the video; and a visual summary representing points with high learner activity. To evaluate the feasibility of the techniques, we ran a laboratory user study with simulated learning tasks. Participants rated watching lecture videos with interaction data to be efficient and useful in completing the tasks. However, no significant differences were found in task performance, suggesting that interaction data may not always align with moment-by-moment information needs during the tasks.', \"Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.\", 'There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children\\'s learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present \"brain points,\" a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the \"brain points\" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.', \"We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.\", 'Consumer-grade digital fabrication such as 3D printing is on the rise, and we believe it can be leveraged to great benefit in the arena of special education. Although 3D printing is beginning to infiltrate mainstream education, little to no research has explored 3D printing in the context of students with special support needs. We present a formative study exploring the use of 3D printing at three locations serving populations with varying ability, including individuals with cognitive, motor, and visual impairments. We found that 3D design and printing performs three functions in special education: developing 3D design and printing skills encourages STEM engagement; 3D printing can support the creation of educational aids for providing accessible curriculum content; and 3D printing can be used to create custom adaptive devices. In addition to providing opportunities to students, faculty, and caregivers in their efforts to integrate 3D printing in special education settings, our investigation also revealed several concerns and challenges. We present our investigation at three diverse sites as a case study of 3D printing in the realm of special education, discuss obstacles to efficient 3D printing in this context, and offer suggestions for designers and technologists.', \"In modern crowdsourcing markets, requesters face the challenge of training and managing large transient workforces. Requesters can hire peer workers to review others' work, but the value may be marginal, especially if the reviewers lack requisite knowledge. Our research explores if and how workers learn and improve their performance in a task domain by serving as peer reviewers. Further, we investigate whether peer reviewing may be more effective in teams where the reviewers can reach consensus through discussion. An online between-subjects experiment compares the trade-offs of reviewing versus producing work using three different organization strategies: working individually, working as an interactive team, and aggregating individuals into nominal groups. The results show that workers who review others' work perform better on subsequent tasks than workers who just produce. We also find that interactive reviewer teams outperform individual reviewers on all quality measures. However, aggregating individual reviewers into nominal groups produces better quality assessments than interactive teams, except in task domains where discussion helps overcome individual misconceptions.\", \"Massive open online courses (MOOCs) rely primarily on discussion forums for interaction among students. We investigate how forum design affects student activity and learning outcomes through a field experiment with 1101 participants on the edX platform. We introduce a reputation system, which gives students points for making useful posts. We show that, as in other settings, use of forums in MOOCs is correlated with better grades and higher retention. Reputation systems additionally produce faster response times and larger numbers of responses per post, as well as differences in how students ask questions. However, reputation systems have no significant impact on grades, retention, or the students' subjective sense of community. This suggests that forums are essential for MOOCs, and reputation systems can improve the forum experience, but other techniques are needed to improve student outcomes and community formation. We also contribute a set of guidelines for running field experiments on MOOCs.\", 'Much of the stress and strain of student life remains hidden. The StudentLife continuous sensing app assesses the day-to-day and week-by-week impact of workload on stress, sleep, activity, mood, sociability, mental well-being and academic performance of a single class of 48 students across a 10 week term at Dartmouth College using Android phones. Results from the StudentLife study show a number of significant correlations between the automatic objective sensor data from smartphones and mental health and educational outcomes of the student body. We also identify a Dartmouth term lifecycle in the data that shows students start the term with high positive affect and conversation levels, low stress, and healthy sleep and daily activity patterns. As the term progresses and the workload increases, stress appreciably rises while positive affect, sleep, conversation and activity drops off. The StudentLife dataset is publicly available on the web.']}, '2013': {'title': ['Deconstructing disengagement: analyzing learner subpopulations in massive open online courses', 'Affective states and state tests: investigating how affect throughout the school year predicts end of year learning outcomes', 'Multimodal learning analytics', 'MOOCs and the funnel of participation', 'Designing with traces', 'A pilot study of using crowds in the classroom', 'Optimizing challenge in an educational game using large-scale design experiments', 'The effect of virtual achievements on student engagement', 'A trace-based framework for analyzing and synthesizing educational progressions', \"The makers' movement and FabLabs in education: experiences, technologies, and research\", 'Sharing Stories “in the Wild”: A Mobile Storytelling Case Study Using StoryKit', 'Peer and self assessment in massive online classes', 'Managing mobile multitasking: the culture of iPhones on stanford campus', 'Extending tabletop application design to the classroom', 'Arpège: learning multitouch chord gestures vocabularies'], 'abstract': ['As MOOCs grow in popularity, the relatively low completion rates of learners has been a central criticism. This focus on completion rates, however, reflects a monolithic view of disengagement that does not allow MOOC designers to target interventions or develop adaptive course features for particular subpopulations of learners. To address this, we present a simple, scalable, and informative classification method that identifies a small number of longitudinal engagement trajectories in MOOCs. Learners are classified based on their patterns of interaction with video lectures and assessments, the primary features of most MOOCs to date. In an analysis of three computer science MOOCs, the classifier consistently identifies four prototypical trajectories of engagement. The most notable of these is the learners who stay engaged through the course without taking assessments. These trajectories are also a useful framework for the comparison of learner engagement between different course structures or instructional approaches. We compare learners in each trajectory and course across demographics, forum participation, video access, and reports of overall experience. These results inform a discussion of future interventions, research, and design directions for MOOCs. Potential improvements to the classification mechanism are also discussed, including the introduction of more fine-grained analytics.', 'In this paper, we investigate the correspondence between student affect in a web-based tutoring platform throughout the school year and learning outcomes at the end of the year, on a high-stakes mathematics exam. The relationships between affect and learning outcomes have been previously studied, but not in a manner that is both longitudinal and finer-grained. Affect detectors are used to estimate student affective states based on post-hoc analysis of tutor log-data. For every student action in the tutor the detectors give us an estimated probability that the student is in a state of boredom, engaged concentration, confusion, and frustration, and estimates of the probability that they are exhibiting off-task or gaming behaviors. We ran the detectors on two years of log-data from 8th grade student use of the ASSISTments math tutoring system and collected corresponding end of year, high stakes, state math test scores for the 1,393 students in our cohort. By correlating these data sources, we find that boredom during problem solving is negatively correlated with performance, as expected; however, boredom is positively correlated with performance when exhibited during scaffolded tutoring. A similar pattern is unexpectedly seen for confusion. Engaged concentration and frustration are both associated with positive learning outcomes, surprisingly in the case of frustration.', \"New high-frequency data collection technologies and machine learning analysis techniques could offer new insights into learning, especially in tasks in which students have ample space to generate unique, personalized artifacts, such as a computer program, a robot, or a solution to an engineering challenge. To date most of the work on learning analytics and educational data mining has focused on online courses or cognitive tutors, in which the tasks are more structured and the entirety of interaction happens in front of a computer. In this paper, I argue that multimodal learning analytics could offer new insights into students' learning trajectories, and present several examples of this work and its educational application.\", \"Massive Online Open Courses (MOOCs) are growing substantially in numbers, and also in interest from the educational community. MOOCs offer particular challenges for what is becoming accepted as mainstream practice in learning analytics. Partly for this reason, and partly because of the relative newness of MOOCs as a widespread phenomenon, there is not yet a substantial body of literature on the learning analytics of MOOCs. However, one clear finding is that drop-out/non-completion rates are substantially higher than in more traditional education. This paper explores these issues, and introduces the metaphor of a 'funnel of participation' to reconceptualise the steep drop-off in activity, and the pattern of steeply unequal participation, which appear to be characteristic of MOOCs and similar learning environments. Empirical data to support this funnel of participation are presented from three online learning sites: iSpot (observations of nature), Cloudworks ('a place to share, find and discuss learning and teaching ideas and experiences'), and openED 2.0, a MOOC on business and management that ran between 2010--2012. Implications of the funnel for MOOCs, formal education, and learning analytics practice are discussed.\", 'This paper draws on new materialist perspectives to introduce the analytic category of \"material traces\" to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.', 'Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.', \"Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the \\\\'1cInverted-U Hypothesis\\\\'1d, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge.\", \"Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts. Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains. With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation. In this paper, we report on a large-scale (n > 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool. We discover a highly significant positive effect on the quantity of students' contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.\", 'A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.', 'In this paper, we introduce the origins and applications of digital fabrication and \"making\" in education, and discuss how they can be implemented, researched, and developed in schools. Our discussion is based on several papers and posters that we summarize into three categories: research, technology development, and experiences in formal and informal education.', 'Today’s mobile devices are equipped with a variety of tools that enable users to capture and share their daily experiences. However, designing authoring tools that effectively integrate the discrete media-capture components of mobile devices to enable rich expression---especially by children---remains a challenge. Evaluating such tools authentically, as they are being used in-situ, can be even more challenging. We detail a long-term, multimethod study on the use of StoryKit, a mobile storytelling application. By taking advantage of a public distribution channel, we were able to evaluate StoryKit’s use on a scale beyond that usually found in lab settings or limited field trials. Our results show that StoryKit’s simple but well-integrated interface attracted a high number of dedicated users in education contexts at all levels, including children with special learning needs. We include a discussion of the challenges and opportunities that similar “in the wild” studies hold for HCI research.', 'Peer and self-assessment offer an opportunity to scale both assessment and learning to global classrooms. This article reports our experiences with two iterations of the first large online class to use peer and self-assessment. In this class, peer grades correlated highly with staff-assigned grades. The second iteration had 42.9&percnt; of students’ grades within 5&percnt; of the staff grade, and 65.5&percnt; within 10&percnt;. On average, students assessed their work 7&percnt; higher than staff did. Students also rated peers’ work from their own country 3.6&percnt; higher than those from elsewhere. We performed three experiments to improve grading accuracy. We found that giving students feedback about their grading bias increased subsequent accuracy. We introduce short, customizable feedback snippets that cover common issues with assignments, providing students more qualitative peer feedback. Finally, we introduce a data-driven approach that highlights high-variance items for improvement. We find that rubrics that use a parallel sentence structure, unambiguous wording, and well-specified dimensions have lower variance. After revising rubrics, median grading error decreased from 12.4&percnt; to 9.9&percnt;.', 'This paper discusses three concepts that govern technosocial practices among university students with iPhones. First is the social expectation of constant connection that requires multitasking to achieve. Second is the resulting technosocial pecking order of who gets interrupted or ignored for whom. Third is the way that many students push back against these demands with techno-resistance, deliberately curtailing constant connection to reduce the negative effects of multitasking, in spite of the risk of social censure. These concepts are developed from interviews with 57 students, 30 hours of field observations, and a survey of 177 students on Stanford campus, which in particular explored iPhone use. This research concludes that so-called \"digital natives\" must still navigate familiar social dynamics and personal desires, both online and off. Providing a detailed description of how students from across campus make sense of iPhones in their everyday technosocial assemblages, this research suggests opportunities for more socially and cognitively sensitive design of smartphone features.', 'While a number of guidelines exist for the design of learning applications that target a single group working around an interactive tabletop, the same cannot be said for the design of applications intended for use in multi-tabletops deployments in the classroom. Accordingly, a number of these guidelines for single-tabletop settings need to be extended to take account of both the distinctive qualities of the classroom and the particular challenges of having various groups using the same application on multiple tables simultaneously. This paper presents an empirical analysis of the effectiveness of designs for small-group multi-tabletop collaborative learning activities in the wild. We use distributed cognition as a framework to analyze the small number of authentic multi-tabletop deployments and help characterize the technological and educational ecology of these classroom settings. Based on previous research on single-tabletop collaboration, the concept of orchestration, and both first-hand experience and second-hand accounts of the few existing multiple-tabletop deployments to date, we develop a three-dimensional framework of design recommendations for multi-tabletop learning settings.', 'This paper presents Arpège, a progressive multitouch input technique for learning chords, as well as a robust recognizer and guidelines for building large chord vocabularies. Experiment one validated our design guidelines and suggests implications for designing vocabularies, i.e. users prefer relaxed to tense chords, chords with fewer fingers and chords with fewer tense fingers. Experiment two demonstrated that users can learn and remember a large chord vocabulary with both Arpège and cheat sheets, and Arpège encourages the creation of effective mmnemonics.']}, '2012': {'title': ['Learning analytics: envisioning a research discipline and a domain of practice', 'Social learning analytics: five approaches', 'The learning analytics cycle: closing the loop effectively', 'Learning analytics and educational data mining: towards communication and collaboration', 'Course signals at Purdue: using learning analytics to increase student success', 'Successful classroom deployment of a social document annotation system', \"Phylo-Genie: engaging students in collaborative 'tree-thinking' through tabletop techniques\", 'Pay attention!: designing adaptive agents that monitor and improve user engagement', 'Omnipedia: bridging the wikipedia language gap', 'An investigation into the use of tactile instructions in snowboarding', 'Mood meter: counting smiles in the wild'], 'abstract': ['Learning analytics are rapidly being implemented in different educational settings, often without the guidance of a research base. Vendors incorporate analytics practices, models, and algorithms from datamining, business intelligence, and the emerging \"big data\" fields. Researchers, in contrast, have built up a substantial base of techniques for analyzing discourse, social networks, sentiments, predictive models, and in semantic content (i.e., \"intelligent\" curriculum). In spite of the currently limited knowledge exchange and dialogue between researchers, vendors, and practitioners, existing learning analytics implementations indicate significant potential for generating novel insight into learning and vital educational practices. This paper presents an integrated and holistic vision for advancing learning analytics as a research discipline and a domain of practices. Potential areas of collaboration and overlap are presented with the intent of increasing the impact of analytics on teaching, learning, and the education system.', \"This paper proposes that Social Learning Analytics (SLA) can be usefully thought of as a subset of learning analytics approaches. SLA focuses on how learners build knowledge together in their cultural and social settings. In the context of online social learning, it takes into account both formal and informal educational environments, including networks and communities. The paper introduces the broad rationale for SLA by reviewing some of the key drivers that make social learning so important today. Five forms of SLA are identified, including those which are inherently social, and others which have social dimensions. The paper goes on to describe early work towards implementing these analytics on SocialLearn, an online learning space in use at the UK's Open University, and the challenges that this is raising. This work takes an iterative approach to analytics, encouraging learners to respond to and help to shape not only the analytics but also their associated recommendations.\", \"This paper develops Campbell and Oblinger's [4] five-step model of learning analytics (Capture, Report, Predict, Act, Refine) and other theorisations of the field, and draws on broader educational theory (including Kolb and Schön) to articulate an incrementally more developed, explicit and theoretically-grounded Learning Analytics Cycle. This cycle conceptualises successful learning analytics work as four linked steps: learners (1) generating data (2) that is used to produce metrics, analytics or visualisations (3). The key step is 'closing the loop' by feeding back this product to learners through one or more interventions (4). This paper seeks to begin to place learning analytics practice on a base of established learning theory, and draws several implications from this theory for the improvement of learning analytics projects. These include speeding up or shortening the cycle so feedback happens more quickly, and widening the audience for feedback (in particular, considering learners and teachers as audiences for analytics) so that it can have a larger impact.\", 'Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.', \"In this paper, an early intervention solution for collegiate faculty called Course Signals is discussed. Course Signals was developed to allow instructors the opportunity to employ the power of learner analytics to provide real-time feedback to a student. Course Signals relies not only on grades to predict students' performance, but also demographic characteristics, past academic history, and students' effort as measured by interaction with Blackboard Vista, Purdue's learning management system. The outcome is delivered to the students via a personalized email from the faculty member to each student, as well as a specific color on a stoplight -- traffic signal -- to indicate how each student is doing. The system itself is explained in detail, along with retention and performance outcomes realized since its implementation. In addition, faculty and student perceptions will be shared.\", \"NB is an in-place collaborative document annotation website targeting students reading lecture notes and draft textbooks. Serving as a discussion forum in the document margins, NB lets users ask and answer questions about their reading material as they are reading. NB users can read and annotate documents using their web browsers, without any special plug-ins. We describe the NB system and its evaluation in real class environment, where students used it to submit their reading assignments, ask questions and get or provide feedback. We show that this tool can be and has been successfully incorporated into a number of different classes at different institutions. To understand how and why, we focus on a particularly successful class deployment where the instructor adapted his teaching style to take students' comment into account. We analyze the annotation practices that were observed - including the way geographic locality was exploited in ways unavailable in traditional forums - and discuss general design implications for online annotation tools in academia.\", \"Phylogenetic trees are representations of evolutionary relationships amongst species. Interviews of instructors and students have revealed that novice biologists have difficulty understanding phylogenetics. Moreover, misinterpretations of phylogenetics are common among college-level students. In this paper we present Phylo-Genie, a tabletop interface for fostering collaborative learning of phylogenetics. We conducted an experimental study with 56 participants, comparing students' conceptual learning and engagement using Phylo-Genie as: 1) a multi-touch tabletop interface and 2) a pen and paper activity. Our findings show that the tabletop implementation fosters collaborative learning by engaging users in the activity. We also shed light on the way in which our design principles facilitated engagement and collaborative learning in a tabletop environment.\", 'Embodied agents hold great promise as educational assistants, exercise coaches, and team members in collaborative work. These roles require agents to closely monitor the behavioral, emotional, and mental states of their users and provide appropriate, effective responses. Educational agents, for example, will have to monitor student attention and seek to improve it when student engagement decreases. In this paper, we draw on techniques from brain-computer interfaces (BCI) and knowledge from educational psychology to design adaptive agents that monitor student attention in real time using measurements from electroencephalography (EEG) and recapture diminishing attention levels using verbal and nonverbal cues. An experimental evaluation of our approach showed that an adaptive robotic agent employing behavioral techniques to regain attention during drops in engagement improved student recall abilities 43% over the baseline regardless of student gender and significantly improved female motivation and rapport. Our findings offer guidelines for developing effective adaptive agents, particularly for educational settings.', 'We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.', \"In many sports, athletes are spatially separated from their coach while practicing an exercise. This spatial separation makes learning new skills arduous because the coach cannot give instructions or feedback on performance. We present the findings of an in the wild study that demonstrate the potential for teaching sport skills with realtime tactile instructions. We focused on snowboard training. Ten amateurs learned a riding technique with a wearable system that automatically provided tactile instructions during descents. These instructions were in sync with the movements of the snowboard and signaled how to move the body. We found that tactile instructions could help snowboarders to improve their skills. We report insights into the snowboarders' opinion and give recommendations for teaching sport skills with tactile instructions. Our findings help to identify the conditions under which tactile instructions can support athletes in sports training.\", \"In this study, we created and evaluated a computer vision based system that automatically encouraged, recognized and counted smiles on a college campus. During a ten-week installation, passersby were able to interact with the system at four public locations. The aggregated data was displayed in real time in various intuitive and interactive formats on a public website. We found privacy to be one of the main design constraints, and transparency to be the best strategy to gain participants' acceptance. In a survey (with 300 responses), participants reported that the system made them smile more than they expected, and it made them and others around them feel momentarily better. Quantitative analysis of the interactions revealed periodic patterns (e.g., more smiles during the weekends) and strong correlation with campus events (e.g., fewer smiles during exams, most smiles the day after graduation), reflecting the emotional responses of a large community.\"]}, '2011': {'title': ['Attention please!: learning analytics for visualization and recommendation', \"Using learning analytics to assess students' behavior in open-ended programming tasks\", 'Dataset-driven research for improving recommender systems for learning', 'SideBySide: ad-hoc multi-user interaction with handheld projectors', 'Practical, appropriate, empirically-validated guidelines for designing educational games', 'Enhancing genomic learning through tabletop interaction', 'Who did what? Who said that?: Collaid: an environment for capturing traces of collaborative learning at the tabletop'], 'abstract': ['This paper will present the general goal of and inspiration for our work on learning analytics, that relies on attention metadata for visualization and recommendation. Through information visualization techniques, we can provide a dashboard for learners and teachers, so that they no longer need to \"drive blind\". Moreover, recommendation can help to deal with the \"paradox of choice\" and turn abundance from a problem into an asset for learning.', \"There is great interest in assessing student learning in unscripted, open-ended environments, but students' work can evolve in ways that are too subtle or too complex to be detected by the human eye. In this paper, I describe an automated technique to assess, analyze and visualize students learning computer programming. I logged hundreds of snapshots of students' code during a programming assignment, and I employ different quantitative techniques to extract students' behaviors and categorize them in terms of programming experience. First I review the literature on educational data mining, learning analytics, computer vision applied to assessment, and emotion detection, discuss the relevance of the work, and describe one case study with a group undergraduate engineering students\", 'In the world of recommender systems, it is a common practice to use public available datasets from different application environments (e.g. MovieLens, Book-Crossing, or Each-Movie) in order to evaluate recommendation algorithms. These datasets are used as benchmarks to develop new recommendation algorithms and to compare them to other algorithms in given settings. In this paper, we explore datasets that capture learner interactions with tools and resources. We use the datasets to evaluate and compare the performance of different recommendation algorithms for learning. We present an experimental comparison of the accuracy of several collaborative filtering algorithms applied to these TEL datasets and elaborate on implicit relevance data, such as downloads and tags, that can be used to improve the performance of recommendation algorithms.', 'We introduce SideBySide, a system designed for ad-hoc multi-user interaction with handheld projectors. SideBySide uses device-mounted cameras and hybrid visible/infrared light projectors to track multiple independent projected images in relation to one another. This is accomplished by projecting invisible fiducial markers in the near-infrared spectrum. Our system is completely self-contained and can be deployed as a handheld device without instrumentation of the environment. We present the design and implementation of our system including a hybrid handheld projector to project visible and infrared light, and techniques for tracking projected fiducial markers that move and overlap. We introduce a range of example applications that demonstrate the applicability of our system to real-world scenarios such as mobile content exchange, gaming, and education.', 'There has recently been a great deal of interest in the potential of computer games to function as innovative educational tools. However, there is very little evidence of games fulfilling that potential. Indeed, the process of merging the disparate goals of education and games design appears problematic, and there are currently no practical guidelines for how to do so in a coherent manner. In this paper, we describe the successful, empirically validated teaching methods developed by behavioural psychologists and point out how they are uniquely suited to take advantage of the benefits that games offer to education. We conclude by proposing some practical steps for designing educational games, based on the techniques of Applied Behaviour Analysis. It is intended that this paper can both focus educational games designers on the features of games that are genuinely useful for education, and also introduce a successful form of teaching that this audience may not yet be familiar with.', \"We present G-nome Surfer 2.0, a tabletop interface for fostering inquiry-based learning of genomics. We conducted an experimental study with 48 participants that compared students' learning of genomic concepts using existing bioinformatics tools and using two alternative implementations of G-nome Surfer: a collaborative multi-mouse GUI and a tabletop interface. Our findings indicate that G-nome Surfer improves students' performance, reduces workload, and increases enjoyment. The comparison of tabletop and multi-mouse implementations further shows that the tabletop condition results in four educational benefits: 1) increasing physical participation, 2) encouraging reflection, 3) fostering effective collaboration, and 4) facilitating more intuitive interaction.\", 'Tabletops have the potential to provide new ways to support collaborative learning generally and, more specifically, to aid people in learning to collaborate more effectively. To achieve this potential, we need to gain understanding of how to design tabletop environments so that they capture relevant information about collaboration processes so that we can make it available in a form that is useful for learners, their teachers and facilitators. This paper draws upon research in computer supported collaborative learning to establish a set of principles for the design of a tabletop learning system. We then show how these have been used to design our Collaid (Collaborative Learning Aid) environment. Key features of this system are: capture of multi-modal data about collaboration in a tabletop activity using a microphone array and a depth sensor; integration of these data with other parts of the learning system; transforming the data into visualisations depicting the processes that occurred during the collaboration at the table; and sequence mining of the interaction logs. The main contributions of this paper are: our design guidelines to build the Collaid environment and the demonstration of its use in a collaborative concept mapping learning tool applying data mining and visualisations of collaboration.']}, '2006': {'title': ['Quiet interfaces that help students think', 'On the design of Camelot, an outdoor game for children', 'roBlocks: a robotic construction kit for mathematics and science education'], 'abstract': [\"As technical as we have become, modern computing has not permeated many important areas of our lives, including mathematics education which still involves pencil and paper. In the present study, twenty high school geometry students varying in ability from low to high participated in a comparative assessment of math problem solving using existing pencil and paper work practice (PP), and three different interfaces: an Anoto-based digital stylus and paper interface (DP), pen tablet interface (PT), and graphical tablet interface (GT). Cognitive Load Theory correctly predicted that as interfaces departed more from familiar work practice (GT > PT > DP), students would experience greater cognitive load such that performance would deteriorate in speed, attentional focus, meta-cognitive control, correctness of problem solutions, and memory. In addition, low-performing students experienced elevated cognitive load, with the more challenging interfaces (GT, PT) disrupting their performance disproportionately more than higher performers. The present results indicate that Cognitive Load Theory provides a coherent and powerful basis for predicting the rank ordering of users' performance by type of interface. In the future, new interfaces for areas like education and mobile computing could benefit from designs that minimize users' load so performance is more adequately supported.\", 'This paper describes the design of Camelot, a mobile outdoor game for small groups of children aged 7-10. Camelot was designed with the aim to encourage social interaction between the players and to encourage physical activity. The paper extends the research literature on design methodology for children, by recording and reflecting upon the lessons learnt by applying a range of techniques for involving children in the design of interactive systems.', 'We describe work in progress on roBlocks, a computational construction kit that encourages users to experiment and play with a collection of sensor, logic and actuator blocks, exposing them to a variety of advanced concepts including kinematics, feedback and distributed control. Its interface presents novice users with a simple, tangible set of robotic blocks, whereas advanced users work with software tools to analyze and rewrite the programs embedded in each block. Early results suggest that roBlocks may be an effective vehicle to expose young people to complex ideas in science, technology, engineering and mathematics.']}, '2000': {'title': ['Alice: lessons learned from building a 3D system for novices', ': designing a new class of computational toys'], 'abstract': ['We present lessons learned from developing Alice, a 3D graphics programming environment designed for undergraduates with no 3D graphics or programming experience. Alice is a Windows 95/NT tool for describing the time-based and interactive behavior of 3D objects, not a CAD tool for creating object geometry. Our observations and conclusions come from formal and informal observations of hundreds of users. Primary results include the use of LOGO-style egocentric coordinate systems, the use of arbitrary objects as lightweight coordinate systems, the launching of implicit threads of execution, extensive function overloading for a small set of commands, the careful choice of command names, and the ubiquitous use of animation and undo.', 'We introduce an educational toy, called curlybot, as the basis for a new class of toys aimed at children in their early stages of development — ages four and up. curlybot is an autonomous two-wheeled vehicle with embedded electronics that can record how it has been moved on any flat surface and then play back that motion accurately and repeatedly. Children can use curlybot to develop intuitions for advanced mathematical and computational concepts, like differential geometry, through play away from a traditional computer.In our preliminary studies, we found that children learn to use curlybot quickly. They readily establish an affective and body syntonic connection with curlybot, because of its ability to remember all of the intricacies of their original gesture; every pause, acceleration, and even the shaking in their hand is recorded. Programming by example in this context makes the educational ideas implicit in the design of curlybot accessible to young children.']}, '2002': {'title': [], 'abstract': []}, '2010': {'title': ['Hands-on math: a page-based multi-touch and pen desktop for technical work and problem solving', 'An exploratory study of unsupervised mobile learning in rural India', 'Expressive robots in education: varying the degree of social supportive behavior of a robotic tutor', 'Digital mysteries: designing for learning at the tabletop'], 'abstract': ['Students, scientists and engineers have to choose between the flexible, free-form input of pencil and paper and the computational power of Computer Algebra Systems (CAS) when solving mathematical problems. Hands-On Math is a multi-touch and pen-based system which attempts to unify these approaches by providing virtual paper that is enhanced to recognize mathematical notations as a means of providing in situ access to CAS functionality. Pages can be created and organized on a large pannable desktop, and mathematical expressions can be computed, graphed and manipulated using a set of uni- and bi-manual interactions which facilitate rapid exploration by eliminating tedious and error prone transcription tasks. Analysis of a qualitative pilot evaluation indicates the potential of our approach and highlights usability issues with the novel techniques used.', 'Cellphones have the potential to improve education for the millions of underprivileged users in the developing world. However, mobile learning in developing countries remains under-studied. In this paper, we argue that cellphones are a perfect vehicle for making educational opportunities accessible to rural children in places and times that are more convenient than formal schooling. We carried out participant observations to identify the opportunities in their everyday lives for mobile learning. We next conducted a 26-week study to investigate the extent to which rural children will voluntarily make use of cellphones to access educational content. Our results show a reasonable level of academic learning and motivation. We also report on the social context around these results. Our goal is to examine the feasibility of mobile learning in out-of-school settings in rural, underdeveloped areas, and to help more researchers learn how to undertake similarly difficult studies around mobile computing in the developing world.', 'Teaching is inherently a social interaction between teacher and student. Despite this knowledge, many educational tools, such as vocabulary training programs, still model the interaction in a tutoring scenario as unidirectional knowledge transfer rather than a social dialog. Therefore, ongoing research aims to develop virtual agents as more appropriate media in education. Virtual agents can induce the perception of a life-like social interaction partner that communicates through natural modalities such as speech, gestures and emotional expressions. This effect can be additionally enhanced with a physical robotic embodiment. This paper presents the development of social supportive behaviors for a robotic tutor to be used in a language learning application. The effect of these behaviors on the learning performance of students was evaluated. The results support that employing social supportive behavior increases learning efficiency of students.', \"We present the iterative design, implementation, and validation of a collaborative learning application for school children designed for a digital tabletop. Digital mysteries, is based on the mysteries paper-based learning technique. Our work is distinctive in that the design process, the design choices, and the implementation framework are all grounded in theories of both collaborative interaction and learning. Our hypothesis was that, if well utilized, the digital tabletop's unique affordances would allow for the creation of collaborative learning tools that were better than traditional paper-or computer-based tools. The two main design goals for the digital version are supporting externalization of thinking and higher-level thinking skills. The evaluation of the final version provided evidence that use of the application increases the probability that effective learning mechanisms will occur and encourages higher-level thinking through reflection. We conclude the paper with design guidelines for tabletop collaborative learning applications.\"]}, '2004': {'title': ['Building and evaluating an intelligent pedagogical agent to improve the effectiveness of an educational game', 'Off-task behavior in the cognitive tutor classroom: when students \"game the system\"', 'Ambient wood: designing new forms of digital augmentation for learning outdoors', 'Visualizing programs with Jeliot 3', 'Lessons learned from eClass: Assessing automated capture and access in the classroom', 'The introduction of a shared interactive surface into a communal space'], 'abstract': [\"Electronic educational games can be highly entertaining, but studies have shown that they do not always trigger learning. To enhance the effectiveness of educational games, we propose intelligent pedagogical agents that can provide individualized instruction integrated with the entertaining nature of the games. In this paper, we describe one such agent, that we have developed for Prime Climb, an educational game on number factorization. The Prime Climb agent relies on a probabilistic student model to generate tailored interventions aimed at helping students learn number factorization through the game. After describing the functioning of the agent and the underlying student model, we report the results of an empirical study that we performed to test the agent's effectiveness.\", 'We investigate the prevalence and learning impact of different types of off-task behavior in classrooms where students are using intelligent tutoring software. We find that within the classrooms studied, no other type of off-task behavior is associated nearly so strongly with reduced learning as \"gaming the system\": behavior aimed at obtaining correct answers and advancing within the tutoring curriculum by systematically taking advantage of regularities in the software\\'s feedback and help. A student\\'s frequency of gaming the system correlates as strongly to post-test score as the student\\'s prior domain knowledge and general academic achievement. Controlling for prior domain knowledge, students who frequently game the system score substantially lower on a post-test than students who never game the system. Analysis of students who choose to game the system suggests that learned helplessness or performance orientation might be better accounts for why students choose this behavior than lack of interest in the material. This analysis will inform the future re-design of tutors to respond appropriately when students game the system.', 'Ubiquitous and mobile technologies provide opportunities for designing novel learning experiences that move out of the classroom. Information can be presented and interacted with in a variety of ways while exploring a physical environment. A key issue this raises is when, where, what and how much? Our research is concerned with the design, delivery and interaction of digital information when learning about ecology outdoors. We present a framework of the different forms of digital augmentation and the different processes by which they can be accessed. Using the framework, we designed an outdoors learning experience, aimed at encouraging students to carry out contextualized scientific enquiry and to reflect on their interactions. Pairs of 11-12 year olds explored a woodland and were presented at certain times with different forms of digital augmentation. Our study showed that this kind of exploration promoted interpretation and reflection at a number of levels of abstraction.', 'We present a program visualization tool called Jeliot 3 that is designed to aid novice students to learn procedural and object oriented programming. The key feature of Jeliot is the fully or semi-automatic visualization of the data and control flows. The development process of Jeliot has been research-oriented, meaning that all the different versions have had their own research agenda rising from the design of the previous version and their empirical evaluations. In this process, the user interface and visualization has evolved to better suit the targeted audience, which in the case of Jeliot 3, is novice programmers. In this paper we explain the model for the system and introduce the features of the user interface and visualization engine. Moreover, we have developed an intermediate language that is used to decouple the interpretation of the program from its visualization. This has led to a modular design that permits both internal and external extensibility.', 'This article presents results from a study of an automated capture and access system, eClass, which was designed to capture the materials presented in college lectures for later review by students. In this article, we highlight the lessons learned from our three-year study focusing on the effect of capture and access on grades, attendance, and use of the captured notes and media. We then present suggestions for building future systems discussing improvements from our system in the capture, integration, and access of college lectures.', 'We describe a user study of a large multi-user interactive surface deployed for an initial period within a real world setting. The surface was designed to enable the sharing and exchange of a wide variety of digital media. The setting for the study was the common room of a high school where students come together to mix, socialize, and collaborate throughout the day. We report on how the students use the new technology within their own established communal space. Findings show that the system was used extensively by the students in a variety of ways, including sharing of photos, video clips, and websites, and for facilitating social interaction. We discuss how the interactive shared surface was appropriated by the students and introduced into their everyday lives in ways that both mirrored and extended their existing practices within the communal space.']}, '2008': {'title': ['Designing e-learning games for rural children in India: a format for balancing learning with fun', 'Playful toothbrush: ubicomp technology for teaching tooth brushing to kindergarten children', 'Explore! possibilities and challenges of mobile learning', 'CareLog: a selective archiving tool for behavior management in schools', 'Playing with the sound maker: do embodied metaphors help children learn?'], 'abstract': ['Poor literacy remains a barrier to economic empowerment in the developing world. Of particular importance is fluency in a widely spoken \"world language\" such as English, which is typically a second language for these low-income learners. We make the case that mobile games on cellphones is an appropriate solution in the typical ecologies of developing regions. The challenge is to design e-learning games that are both educational and pleasurable for our target learners, who have limited familiarity with high technology. We propose the receptive-practice-activation cycle that could be used as the conceptual model for the designs. We then report how this format could be refined, based on our experiences in the field with three games that have collectively undergone nine rounds of iterations. In particular, it appears that maintaining a distinction between learning and fun to some extent is necessary for effective designs.', 'This case study in UbiComp technology and design presents a \"Playful Toothbrush\" system for assisting parents and teachers to motivate kindergarten children to learn proper and thorough brushing skills. The system includes a vision-based motion tracker that recognizes different tooth brushing strokes and a tooth brushing game in which the child cleans a virtual, mirror picture of his/her dirty teeth by physically brushing his/her own teeth. The user study results suggest that Playful Toothbrush enhances the effectiveness of kindergarten children in brushing their teeth, as measured by number of brushing strokes, duration of brushing and thoroughness of teeth cleaning.', 'This paper reports the experimental studies we have performed to evaluate Explore!, an m-learning system that supports middle school students during a visit to an archaeological park. It exploits a learning technique called excursion-game, whose aim is to help students to acquire historical notions while playing and to make archaeological visits more effective and exciting. In order to understand the potentials and limitations of Explore!, our studies compare the experience of playing the excursion-game with and without technological support. The design and evaluation of Explore! have provided knowledge on the advantages and pitfalls of m-learning that may be instrumental in informing the current debate on e-learning.', 'Identifying the function of problem behavior can lead to the development of more effective interventions. One way to identify the function is through functional behavior assessment (FBA). Teachers conduct FBA in schools. However, the task load of recording the data manually is high, and the challenge of accurately identifying antecedents and consequences is significant while interacting with students. These issues often result in imperfect information capture. CareLog allows teachers more easily to conduct FBAs and enhances the capture of relevant information. In this paper, we describe the design process that led to five design principles that governed the development of CareLog. We present results from a five-month, quasi-controlled study aimed at validating those design principles. We reflect on how various constraints imposed by special education settings impact the design and evaluation process for HCI practitioners and researchers.', 'In this paper we present the results of a comparative study that explores the potential benefits of using embodied interaction to help children, aged 7 to 10, learn abstract concepts related to musical sounds. Forty children learned to create musical sound sequences using an interactive sound making environment. Half the children used a version of the system that instantiated a body-based metaphor in the mapping layer connecting body movements to output sounds. The remaining children used a version of the same environment that did not instantiate a metaphor in the mapping layer. In general, children were able to more accurately demonstrate sound sequences in the embodied metaphor based system version. However, we observed that children often resorted to spatial rather than body-based metaphors and that the mapping must be easily discoverable as well as metaphorical to provide benefit.']}, '1997': {'title': ['Designing for or designing with? Informant design for interactive learning environments', 'The persona effect: affective impact of animated pedagogical agents', 'KidPad: a design collaboration between children, technologists, and educators', \"The Effect of Turn-Taking Protocols on Children's Learning in Mouse-Driven Collaborative Environments.\"], 'abstract': ['An abstract is not available.', 'An abstract is not available.', 'An abstract is not available.', 'This study compared the influence of turn-taking protocols on children’s behaviour and learning when they used either one shared mouse or two individual mice in a collaborative problem-solving environment. The two-mouse case was investigated for both a give protocol, in which the child with control of the game voluntarily relinquished control, and a take protocol, in which the child without control of the game preemptively acquired control. Children in the study took part in two sessions. In the first collaborative session, children played a problem solving puzzle game with a partner using one of the three protocols (onemouse shared, two-mouse give, or two-mouse take). This was followed by a second solo session in which each child played the game alone. The results of the study revealed that the choice of turn-taking protocol can have a significant affect on children’s learning and behaviour in a collaborative problem-solving environment. For boys, the protocol affected their access to the mouse, which in turn affected their learning: a significant correlation was found between the amount of time each boy had control of the mouse in the collaborative session and the number of puzzles that same boy could solve in a subsequent solo session. In the two-mouse take condition boys exhibited a more equal division of mouse control than did boys using either of the other two protocols.']}, '1995': {'title': [], 'abstract': []}, '1993': {'title': [], 'abstract': []}, '1990': {'title': [], 'abstract': []}, '2003': {'title': [], 'abstract': []}, '1992': {'title': [], 'abstract': []}, '1991': {'title': [], 'abstract': []}, '2005': {'title': ['Extending tangible interfaces for education: digital montessori-inspired manipulatives', 'Livenotes: a system for cooperative and augmented note-taking in lectures'], 'abstract': ['This paper introduces a new framework for thinking about tangible interfaces in education, with specific focus on abstract problem domains.Manipulatives are physical objects specifically designed to foster learning. We offer a new classification of Manipulatives: \"Froebel-inspired Manipulatives\" (FiMs) and \"Montessori-inspired Manipulatives\" (MiMs). We argue that FiMs are design materials, fostering modeling of real-world structures, while MiMs foster modeling of more abstract structures. We show that our classification extends to computationally enhanced versions of manipulatives.We present Digital MiMs - computationally enhanced building blocks. We describe two prototypical members of the Digital MiMs class: FlowBlocks and SystemBlocks, physical, modular interactive systems that serve as general-purpose modeling and simulation tools for dynamic behavior. We present findings from qualitative studies, and conclude that digital MiMs are accessible to young children, engaging, and encourage learning of abstract structures of dynamic behavior through an iterative process of hands-on modeling, simulating, and analogizing.', 'We describe Livenotes, a shared whiteboard system and educational practice that uses wireless communication and tablet computing to support real-time conversations within small groups of students during lectures, independent of class size. We present an interface design that enables group members to interact with one another by taking lecture notes cooperatively, as well as to augment student note-taking by providing instructor slides in the background to annotate over. Livenotes was designed to facilitate more efficient, stimulating modes of learning that other collaborative approaches do not. We report how the system impacts cooperative learning in an undergraduate class and how students interacted with background slides in the workspace. We conclude with directions for improving the system and learning practice.']}, '2001': {'title': ['Locus of feedback control in computer-based tutoring: impact on learning rate, achievement and attitudes'], 'abstract': ['The advent of second-generation intelligent computer tutors raises an important instructional design question: when should tutorial advice be presented in problem solving? This paper examines four feedback conditions in the ACT Programming Tutor. Three versions offer the student different levels of control over error feedback and correction: (a) immediate feedback and immediate error correction; (b) immediate error flagging and student control of error correction; (c) feedback on demand and student control of error correction. A fourth, No-tutor condition offers no stepby-step problem solving support. The immediate feedback group with greatest tutor control of problem solving yielded the most efficient learning. These students completed the tutor problems fastest, and the three tutor-supported groups performed equivalently on tests. Questionnaires revealed little student preference among the four conditions. These results suggest that students will need explicit guidance to benefit from learning opportunities that arise when they have greater control over tutorial assistance.']}, '1996': {'title': [], 'abstract': []}, '1988': {'title': [], 'abstract': []}, '2009': {'title': ['Two peers are better than one: aggregating peer reviews for computing assignments is surprisingly accurate', 'Comparing the use of tangible and graphical programming languages for informal science education', 'Tabletop displays for small group study: affordances of paper and digital materials', 'Children designing together on a multi-touch tabletop: an analysis of spatial orientation and user interactions'], 'abstract': [\"Scientific peer review, open source software development, wikis, and other domains use distributed review to improve quality of created content by providing feedback to the work's creator. Distributed review is used to assess or improve the quality of a work (e.g., an article). However, it can also provide learning benefits to the participants in the review process. We developed an online review system for beginning computer programming students; it gathers multiple anonymous peer reviews to give students feedback on their programming work. We deployed the system in an introductory programming class and evaluated it in a controlled study. We find that: peer reviews are accurate compared to an accepted evaluation standard, that students prefer reviews from other students with less experience than themselves, and that participating in a peer review process results in better learning outcomes.\", 'Much of the work done in the field of tangible interaction has focused on creating tools for learning; however, in many cases, little evidence has been provided that tangible interfaces offer educational benefits compared to more conventional interaction techniques. In this paper, we present a study comparing the use of a tangible and a graphical interface as part of an interactive computer programming and robotics exhibit that we designed for the Boston Museum of Science. In this study, we have collected observations of 260 museum visitors and conducted interviews with 13 family groups. Our results show that visitors found the tangible and the graphical systems equally easy to understand. However, with the tangible interface, visitors were significantly more likely to try the exhibit and significantly more likely to actively participate in groups. In turn, we show that regardless of the condition, involving multiple active participants leads to significantly longer interaction times. Finally, we examine the role of children and adults in each condition and present evidence that children are more actively involved in the tangible condition, an effect that seems to be especially strong for girls.', 'In this paper we compare the affordances of presenting educational material on a tabletop display with presenting the same material using traditional paper handouts. Ten pairs of undergraduate students used digital or paper materials to prepare for exams during four one-hour study sessions over the course of a term. Students studying with the tabletop display solved problems on their own before resorting to answer keys and repeated activities more often than students studying with paper documents. We summarize study activities and discuss the benefits and drawbacks of each medium.', \"Applications running on multi-touch tabletops are beginning to be developed to enable children to collaborate on a variety of activities, from photo sharing to playing games. However, little is know as to how children work together on such interactive surfaces. We present a study that investigated groups of children's use of a multitouch tabletop for a shared-space design task, requiring reasoning and compromise. The OurSpace application was designed to allow children to arrange the desks in their classroom and allocate students to seats around those desks. A number of findings are reported, including a comparison of single versus multiple touch, equity of participation, and an analysis of how a child's tabletop position affects where he or she touches. A main finding was that children used all of the tabletop surface, but took more responsibility for the parts of the design closer to their relative position.\"]}, '2007': {'title': ['The life and death of online gaming communities: a look at guilds in world of warcraft', 'Implicit coordination in firefighting practice: design implications for teaching fire emergency responders', 'Storytelling alice motivates middle school girls to learn computer programming', \"Modeling and understanding students' off-task behavior in intelligent tutoring systems\", 'Multiple mice for retention tasks in disadvantaged schools'], 'abstract': ['Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or \"guilds\" to coordinate their actions and accomplish the games\\' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.', 'Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.', \"We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.\", \"We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.\", 'This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.']}, '1998': {'title': ['Investigating the capture, integration and access problem of ubiquitous computing in an educational setting', 'Digital manipulatives: new toys to think with'], 'abstract': ['An abstract is not available.', 'An abstract is not available.']}, '1994': {'title': [], 'abstract': []}, '1999': {'title': [], 'abstract': []}, '1989': {'title': [], 'abstract': []}, '2014/2015': {'title': [], 'abstract': []}, '1986': {'title': [], 'abstract': []}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T10:01:25.293794Z",
     "start_time": "2020-01-20T10:01:25.212603Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/home/lr/Downloads/conference_data/education_high_cited/\"\n",
    "if not os.path.exists(path):\n",
    "     os.mkdir(path)\n",
    "#date_rand =time.strftime(\"%Y-%m-%d\",time.localtime())\n",
    "file_name = path+'artical_info.xlsx'\n",
    "writer = pd.ExcelWriter(file_name)\n",
    "\n",
    "df1.to_excel(writer, \"article_info\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:49:00.781674Z",
     "start_time": "2020-01-20T06:49:00.720056Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                              title  \\\n",
      "index                                                                  \n",
      "39             39          Quiet interfaces that help students think   \n",
      "40             40  On the design of Camelot, an outdoor game for ...   \n",
      "41             41  roBlocks: a robotic construction kit for mathe...   \n",
      "129           129      : designing a new class of computational toys   \n",
      "130           130  Alice: lessons learned from building a 3D syst...   \n",
      "83             83  An Intelligent Interface for Learning Content:...   \n",
      "84             84  Framing Feedback: Choosing Review Environment ...   \n",
      "85             85  Programming, Problem Solving, and Self-Awarene...   \n",
      "86             86  'Don't Waste My Time': Use of Time Information...   \n",
      "87             87  Facilitator, Functionary, Friend or Foe?: Stud...   \n",
      "88             88  Learn Piano with BACh: An Adaptive Learning In...   \n",
      "89             89  Improving Real-Time Captioning Experiences for...   \n",
      "90             90  Future's Butterflies: Co-Designing ICT Wayfari...   \n",
      "91             91  Legitimate Participation in the Classroom Cont...   \n",
      "92             92  RichReview++: Deployment of a Collaborative Mu...   \n",
      "93             93  Do Massive Open Online Course Platforms Suppor...   \n",
      "94             94  Identity Work on Social Media Sites: Disadvant...   \n",
      "95             95    Remixing as a Pathway to Computational Thinking   \n",
      "96             96                 Learnersourcing Personalized Hints   \n",
      "97             97  Effects of In-Video Quizzes on MOOC Lecture Vi...   \n",
      "98             98          Expert Evaluation of 300 Projects per Day   \n",
      "99             99  AXIS: Generating Explanations at Scale with Le...   \n",
      "100           100  Combining click-stream data with NLP tools to ...   \n",
      "101           101  Introduction of learning visualisations and me...   \n",
      "102           102  Privacy and analytics: it's a DELICATE issue a...   \n",
      "103           103  A conceptual framework linking learning design...   \n",
      "131           131  Blocks4All: Overcoming Accessibility Barriers ...   \n",
      "132           132  Bots & (Main)Frames: Exploring the Impact of T...   \n",
      "133           133  Science Everywhere: Designing Public, Tangible...   \n",
      "134           134  “Bursting the Assistance Bubble”: Designing In...   \n",
      "...           ...                                                ...   \n",
      "63             63  Attrition and Achievement Gaps in Online Learning   \n",
      "64             64  PeerStudio: Rapid Peer Feedback Emphasizes Rev...   \n",
      "65             65  A Playful Game Changer: Fostering Student Rete...   \n",
      "66             66  Learning is Not a Spectator Sport: Doing is Be...   \n",
      "67             67  Uncovering Trajectories of Informal Learning i...   \n",
      "68             68  Autonomously Generating Hints by Inferring Pro...   \n",
      "69             69  Learning analytics beyond the LMS: the connect...   \n",
      "70             70  Examining engagement: analysing learner subpop...   \n",
      "71             71  Unsupervised modeling for understanding MOOC d...   \n",
      "139           139  Livenotes: a system for cooperative and augmen...   \n",
      "140           140  Extending tangible interfaces for education: d...   \n",
      "141           141  Locus of feedback control in computer-based tu...   \n",
      "110           110  Two peers are better than one: aggregating pee...   \n",
      "111           111  Comparing the use of tangible and graphical pr...   \n",
      "112           112  Tabletop displays for small group study: affor...   \n",
      "113           113  Children designing together on a multi-touch t...   \n",
      "142           142  Implicit coordination in firefighting practice...   \n",
      "143           143  The life and death of online gaming communitie...   \n",
      "144           144  Modeling and understanding students' off-task ...   \n",
      "145           145  Storytelling alice motivates middle school gir...   \n",
      "146           146  Multiple mice for retention tasks in disadvant...   \n",
      "147           147      Digital manipulatives: new toys to think with   \n",
      "148           148  Investigating the capture, integration and acc...   \n",
      "76             76  SideBySide: ad-hoc multi-user interaction with...   \n",
      "77             77  Practical, appropriate, empirically-validated ...   \n",
      "78             78  Enhancing genomic learning through tabletop in...   \n",
      "79             79  Who did what? Who said that?: Collaid: an envi...   \n",
      "80             80  Attention please!: learning analytics for visu...   \n",
      "81             81  Dataset-driven research for improving recommen...   \n",
      "82             82  Using learning analytics to assess students' b...   \n",
      "\n",
      "                                                abstract  \\\n",
      "index                                                      \n",
      "39     As technical as we have become, modern computi...   \n",
      "40     This paper describes the design of Camelot, a ...   \n",
      "41     We describe work in progress on roBlocks, a co...   \n",
      "129    We introduce an educational toy, called curlyb...   \n",
      "130    We present lessons learned from developing Ali...   \n",
      "83     We present the Mastery Grids system, an intell...   \n",
      "84     Peer assessment is rapidly growing in online l...   \n",
      "85     More people are learning to code than ever, bu...   \n",
      "86     Maintaining work focus when on a computer is a...   \n",
      "87     We present the findings from a longitudinal st...   \n",
      "88     We present Brain Automated Chorales (BACh), an...   \n",
      "89     We take a qualitative approach to understandin...   \n",
      "90     We conducted participatory design workshops at...   \n",
      "91     In this paper we examine the challenges of int...   \n",
      "92     New multi-modal annotation tools hold the prom...   \n",
      "93     Past research suggests that many individuals t...   \n",
      "94     Prior research suggests that some social media...   \n",
      "95     Theorists and advocates of “remixing” have sug...   \n",
      "96     Personalized support for students is a gold st...   \n",
      "97     Online courses on sites such as Coursera use q...   \n",
      "98     In October 2014, one-time MOOC developer Udaci...   \n",
      "99     While explanations may help people learn by pr...   \n",
      "100    Completion rates for massive open online class...   \n",
      "101    This paper describes open learner models as vi...   \n",
      "102    The widespread adoption of Learning Analytics ...   \n",
      "103    In this paper we present a learning analytics ...   \n",
      "131    Blocks-based programming environments are a po...   \n",
      "132    While recent work has begun to evaluate the ef...   \n",
      "133    A major challenge in education is understandin...   \n",
      "134    Children living with visual impairments (VIs) ...   \n",
      "...                                                  ...   \n",
      "63     Attrition in online learning is generally high...   \n",
      "64     Rapid feedback is a core component of mastery ...   \n",
      "65     Many MOOCs report high drop off rates for thei...   \n",
      "66     The printing press long ago and the computer t...   \n",
      "67     We analyzed informal learning in Scratch Onlin...   \n",
      "68     Exploring the whole sequence of steps a studen...   \n",
      "69     We present a Connected Learning Analytics (CLA...   \n",
      "70     Massive open online courses (MOOCs) are now be...   \n",
      "71     Massively Open Online Courses (MOOCs) have gai...   \n",
      "139    We describe Livenotes, a shared whiteboard sys...   \n",
      "140    This paper introduces a new framework for thin...   \n",
      "141    The advent of second-generation intelligent co...   \n",
      "110    Scientific peer review, open source software d...   \n",
      "111    Much of the work done in the field of tangible...   \n",
      "112    In this paper we compare the affordances of pr...   \n",
      "113    Applications running on multi-touch tabletops ...   \n",
      "142    Fire emergency response requires rapidly proce...   \n",
      "143    Massively multiplayer online games (MMOGs) can...   \n",
      "144    We present a machine-learned model that can au...   \n",
      "145    We describe Storytelling Alice, a programming ...   \n",
      "146    This study evaluates single-mouse and multiple...   \n",
      "147                        An abstract is not available.   \n",
      "148                        An abstract is not available.   \n",
      "76     We introduce SideBySide, a system designed for...   \n",
      "77     There has recently been a great deal of intere...   \n",
      "78     We present G-nome Surfer 2.0, a tabletop inter...   \n",
      "79     Tabletops have the potential to provide new wa...   \n",
      "80     This paper will present the general goal of an...   \n",
      "81     In the world of recommender systems, it is a c...   \n",
      "82     There is great interest in assessing student l...   \n",
      "\n",
      "                                                  author  citation conference  \\\n",
      "index                                                                           \n",
      "39     [{'name': 'Sharon Oviatt', 'institutions': 'Or...        41       UIST   \n",
      "40     [{'name': 'Janneke Verhaegh', 'institutions': ...        38        IDC   \n",
      "41     [{'name': 'Eric Schweikardt', 'institutions': ...        42       ICMI   \n",
      "129    [{'name': 'Phil Frei', 'institutions': 'Tangib...        71        CHI   \n",
      "130    [{'name': 'Matthew Conway', 'institutions': 'U...        85        CHI   \n",
      "83     [{'name': 'Julio Guerra', 'institutions': 'Uni...        12        IUI   \n",
      "84     [{'name': 'Catherine M. Hicks', 'institutions'...        12        CHI   \n",
      "85     [{'name': 'Dastyni Loksa', 'institutions': 'Un...        24        CHI   \n",
      "86     [{'name': 'Steve Whittaker', 'institutions': '...        18        CHI   \n",
      "87     [{'name': 'Anne-Marie Mann', 'institutions': '...        13        CHI   \n",
      "88     [{'name': 'Beste F. Yuksel', 'institutions': '...        17        CHI   \n",
      "89     [{'name': 'Saba Kawas', 'institutions': 'Unive...        11     ASSETS   \n",
      "90     [{'name': 'Karen E. Fisher', 'institutions': '...        25        IDC   \n",
      "91     [{'name': 'Wolmet Barendregt', 'institutions':...        11        IDC   \n",
      "92     [{'name': 'Dongwook Yoon', 'institutions': 'Co...        11       CSCW   \n",
      "93     [{'name': 'Tawanna R. Dillahunt', 'institution...        12       CSCW   \n",
      "94     [{'name': 'Tsubasa Morioka', 'institutions': '...        15       CSCW   \n",
      "95     [{'name': 'Sayamindu Dasgupta', 'institutions'...        21       CSCW   \n",
      "96     [{'name': 'Elena L. Glassman', 'institutions':...        13       CSCW   \n",
      "97     [{'name': 'Geza Kovacs', 'institutions': 'Stan...        14         LS   \n",
      "98     [{'name': 'David A. Joyner', 'institutions': '...         0         LS   \n",
      "99     [{'name': 'Joseph Jay Williams', 'institutions...        19         LS   \n",
      "100    [{'name': 'Scott Crossley', 'institutions': 'G...        12        LAK   \n",
      "101    [{'name': 'Susan Bull', 'institutions': 'Unive...        12        LAK   \n",
      "102    [{'name': 'Hendrik Drachsler', 'institutions':...        17        LAK   \n",
      "103    [{'name': 'Aneesha Bakharia', 'institutions': ...        11        LAK   \n",
      "131    [{'name': 'Lauren R. Milne', 'institutions': '...         6        CHI   \n",
      "132    [{'name': 'Edward F. Melcer', 'institutions': ...         6        CHI   \n",
      "133    [{'name': 'June Ahn', 'institutions': 'New Yor...         6        CHI   \n",
      "134    [{'name': 'Oussama Metatla', 'institutions': '...        10        CHI   \n",
      "...                                                  ...       ...        ...   \n",
      "63     [{'name': 'René F. Kizilcec', 'institutions': ...        29         LS   \n",
      "64     [{'name': 'Chinmay E. Kulkarni', 'institutions...        44         LS   \n",
      "65     [{'name': 'Markus Krause', 'institutions': 'Le...        15         LS   \n",
      "66     [{'name': 'Kenneth R. Koedinger', 'institution...        32         LS   \n",
      "67     [{'name': 'Seungwon Yang', 'institutions': 'Ge...        18         LS   \n",
      "68     [{'name': 'Chris Piech', 'institutions': 'Stan...        21         LS   \n",
      "69     [{'name': 'Kirsty Kitto', 'institutions': 'Que...        13        LAK   \n",
      "70     [{'name': 'Rebecca Ferguson', 'institutions': ...        20        LAK   \n",
      "71     [{'name': 'Aysu Ezen-Can', 'institutions': 'No...        13        LAK   \n",
      "139    [{'name': 'Matthew Kam', 'institutions': 'Univ...        60        CHI   \n",
      "140    [{'name': 'Oren Zuckerman', 'institutions': 'M...       133        CHI   \n",
      "141    [{'name': 'Albert T. Corbett', 'institutions':...        49        CHI   \n",
      "110    [{'name': 'Ken Reily', 'institutions': 'Univer...        28      GROUP   \n",
      "111    [{'name': 'Michael S. Horn', 'institutions': '...        68        CHI   \n",
      "112    [{'name': 'Anne Marie Piper', 'institutions': ...        52        CHI   \n",
      "113    [{'name': 'Jochen Rick', 'institutions': 'Open...        54        IDC   \n",
      "142    [{'name': 'Zachary O. Toups', 'institutions': ...        37        CHI   \n",
      "143    [{'name': 'Nicolas Ducheneaut', 'institutions'...        78        CHI   \n",
      "144    [{'name': 'Ryan S.J.d. Baker', 'institutions':...        39        CHI   \n",
      "145    [{'name': 'Caitlin Kelleher', 'institutions': ...       147        CHI   \n",
      "146    [{'name': 'Udai Singh Pawar', 'institutions': ...        45        CHI   \n",
      "147    [{'name': 'Mitchel Resnick', 'institutions': '...       137        CHI   \n",
      "148    [{'name': 'Gregory D. Abowd', 'institutions': ...        62        CHI   \n",
      "76     [{'name': 'Karl D.D. Willis', 'institutions': ...        41       UIST   \n",
      "77     [{'name': 'Conor Linehan', 'institutions': 'Un...        36        CHI   \n",
      "78     [{'name': 'Orit Shaer', 'institutions': 'Welle...        36        CHI   \n",
      "79     [{'name': 'Roberto Martínez', 'institutions': ...        28        ITS   \n",
      "80     [{'name': 'Erik Duval', 'institutions': 'Katho...        48        LAK   \n",
      "81     [{'name': 'Katrien Verbert', 'institutions': '...        35        LAK   \n",
      "82     [{'name': 'Paulo Blikstein', 'institutions': '...        36        LAK   \n",
      "\n",
      "       year     id  \n",
      "index               \n",
      "39     2006   2225  \n",
      "40     2006  14781  \n",
      "41     2006  20971  \n",
      "129    2000   6293  \n",
      "130    2000   6338  \n",
      "83     2016   3731  \n",
      "84     2016   6570  \n",
      "85     2016   6658  \n",
      "86     2016   6682  \n",
      "87     2016   6693  \n",
      "88     2016   7014  \n",
      "89     2016  13019  \n",
      "90     2016  14814  \n",
      "91     2016  14827  \n",
      "92     2016  17747  \n",
      "93     2016  17750  \n",
      "94     2016  17798  \n",
      "95     2016  17844  \n",
      "96     2016  17860  \n",
      "97     2016    134  \n",
      "98     2016    149  \n",
      "99     2016    212  \n",
      "100    2016    816  \n",
      "101    2016    819  \n",
      "102    2016    826  \n",
      "103    2016    856  \n",
      "131    2018   7973  \n",
      "132    2018   8169  \n",
      "133    2018   8181  \n",
      "134    2018   8249  \n",
      "...     ...    ...  \n",
      "63     2015    283  \n",
      "64     2015    285  \n",
      "65     2015    287  \n",
      "66     2015    289  \n",
      "67     2015    291  \n",
      "68     2015    298  \n",
      "69     2015    914  \n",
      "70     2015    920  \n",
      "71     2015    934  \n",
      "139    2005   8925  \n",
      "140    2005   8958  \n",
      "141    2001   9157  \n",
      "110    2009   5413  \n",
      "111    2009  10606  \n",
      "112    2009  10632  \n",
      "113    2009  15478  \n",
      "142    2007  11071  \n",
      "143    2007  11083  \n",
      "144    2007  11110  \n",
      "145    2007  11155  \n",
      "146    2007  11170  \n",
      "147    1998  11208  \n",
      "148    1998  11228  \n",
      "76     2011   3366  \n",
      "77     2011  12383  \n",
      "78     2011  12489  \n",
      "79     2011  23147  \n",
      "80     2011    999  \n",
      "81     2011   1003  \n",
      "82     2011   1012  \n",
      "\n",
      "[164 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "path = \"/home/lr/Downloads/conference_data/education_high_cited/\"\n",
    "file_name = path+'artical_info.xlsx'\n",
    "\n",
    "\n",
    "df = pd.DataFrame(pd.read_excel(file_name))\n",
    "df=df.set_index(['index'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类分组+词云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T02:52:54.894366Z",
     "start_time": "2020-01-08T02:52:54.885943Z"
    }
   },
   "outputs": [],
   "source": [
    "#初步分类\n",
    "onlineLearning = [23,96,61,90,62,83,54,15,5,45,147,49,50,63,82,72,47,69,68,77,59,146,31,159,134]\n",
    "tabletopInterface = [117,98,108,129,116,139,138]\n",
    "STEMedu = [1,40,34,52,11,94,137,64,76,122,6,142,143,24,92,156,151,158,125,140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:25:02.521392Z",
     "start_time": "2020-01-14T10:25:02.507456Z"
    }
   },
   "outputs": [],
   "source": [
    "#最终分类\n",
    "onlineLearning = [94,87,69,88,91,54,36,60,63,39,67,71,82,146,147,42,33,40,25,17,5,49,50,43,32,0,16,18,66,74]\n",
    "tabletopInterface = [151,161,68,132,77,105,133,137,148,163,98,129,78,123,150,128,157,116,110,112,130,108,95,124,139,122,70,72,40,22,27,114,46,56,90]\n",
    "STEMedu = [156,52,24,2,55,59,34,6,145,9,62,53,142,1,152,85,45,76,140,125,141,113,143,11]\n",
    "stuAnalysis = [84,37,65,104,81,102,131,103,155,80,79,93,86,92,41,57,79,4,13,75,21,3,31,19,28,30,35,7,20,38,8,58,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T01:59:54.707706Z",
     "start_time": "2020-01-07T01:59:54.694797Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"def generateWC(group):\n",
    "    word_sum = []\n",
    "    for s in group:\n",
    "        position = findPosition(s)\n",
    "        year = position[0]\n",
    "        index = position[1]\n",
    "\n",
    "        title = total_article[year]['title'][index]\n",
    "        abstract = total_article[year]['title'][index]\n",
    "        text = title + ' ' + title + ' ' + abstract\n",
    "\n",
    "        sent = splitSentence(title) \n",
    "        word_list = []\n",
    "        for m in sent:\n",
    "            word = wordtokenizer(m)                  \n",
    "            word_list = word_list + word\n",
    "\n",
    "        word_standard = standardization(word_list)\n",
    "        word_ori = lemmatizer(word_standard)\n",
    "\n",
    "        word_sum.extend(word_ori)\n",
    "\n",
    "    #print (word_sum)\n",
    "    prep_list = '/'.join(word_sum)\n",
    "    #print (prep_list)\n",
    "    \n",
    "    from wordcloud import WordCloud\n",
    "    wc = WordCloud(width = 600, height = 300).generate(prep_list)\n",
    "    image = wc.to_image()\n",
    "    image.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T02:53:15.142756Z",
     "start_time": "2020-01-08T02:53:15.053608Z"
    }
   },
   "outputs": [],
   "source": [
    "def wordList(group):\n",
    "    word_sum = []\n",
    "    for s in group:\n",
    "        info = df1.loc[s]\n",
    "        title = info['title']\n",
    "        abstract = info['abstract']\n",
    "\n",
    "        text = title + ' ' + title + ' ' + abstract\n",
    "\n",
    "        sent = splitSentence(title) \n",
    "        word_list = []\n",
    "        for m in sent:\n",
    "            word = wordtokenizer(m)                  \n",
    "            word_list = word_list + word\n",
    "\n",
    "        word_standard = standardization(word_list)\n",
    "        word_ori = lemmatizer(word_standard)\n",
    "\n",
    "        word_sum.extend(word_ori)\n",
    "\n",
    "    prep_list = '/'.join(word_sum)\n",
    "    return prep_list\n",
    "\n",
    "ol_list = wordList(onlineLearning)\n",
    "ti_list = wordList(tabletopInterface)\n",
    "stem_list = wordList(STEMedu)\n",
    "sa_list = wordList(stuAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T02:54:33.632678Z",
     "start_time": "2020-01-08T02:54:33.628062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn/code/localized/programming/language/uncover/trajectory/informal/learning/large/online/community/creator/remixing/pathway/computational/thinking/block/block/question/student/perception/block/base/programming/teach/program/gamified/semantics/maker/movement/fablabs/education/experience/technology/research/compare/tangible/graphical/programming/language/informal/science/education/computational/thinking/computational/making/interest/textile/analyze/make/gendered/perspective/play/sound/maker/embody/metaphor/help/child/learn/enable/collaboration/learn/computer/program/inclusive/child/vision/impairment/blocks4all/overcoming/accessibility/barrier/block/program/child/visual/impairment/main/frame/explore/impact/tangible/block/collaborative/play/educational/programming/game/programming/problem/solving/self/awareness/effect/explicit/guidance/trace/base/framework/analyze/synthesize/educational/progression/storytelling/alice/motivates/middle/school/girl/learn/computer/program/extend/tangible/interface/education/digital/montessori/inspired/manipulatives/digital/manipulatives/think/roblocks/robotic/construction/mathematics/science/education/design/class/computational\n"
     ]
    }
   ],
   "source": [
    "print (stem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T02:45:52.693395Z",
     "start_time": "2020-01-07T02:45:49.556368Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateWC(prep_list,string):\n",
    "    from wordcloud import WordCloud\n",
    "    wc = WordCloud(width = 800, height = 600).generate(prep_list)\n",
    "    image = wc.to_image()\n",
    "    wc.to_file(string)\n",
    "    image.show()\n",
    "    \n",
    "generateWC(ol_list,'OnlingLearning.png')\n",
    "generateWC(ti_list,'tabletopInterface.png')\n",
    "generateWC(stem_list,'STEM.png')\n",
    "generateWC(sa_list,'StudentAnalysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T09:56:17.781715Z",
     "start_time": "2019-12-27T09:56:17.770946Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "24\n",
      "29\n",
      "34\n",
      "36\n",
      "39\n",
      "54\n",
      "55\n",
      "59\n",
      "60\n",
      "63\n",
      "71\n",
      "77\n",
      "81\n",
      "82\n",
      "89\n",
      "91\n",
      "97\n",
      "102\n",
      "103\n",
      "105\n",
      "111\n",
      "131\n",
      "132\n",
      "133\n",
      "137\n",
      "145\n",
      "149\n",
      "154\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "for s in range(len(new_cite_list)):\n",
    "    if new_cite_list[s] < 30 and new_cite_list[s] > 20:\n",
    "        print (s)\n",
    "        continue\n",
    "    \"\"\"if new_cite_list[s] > 30:\n",
    "        print (str(s) + \"{color:\" + color[1] + \"}\")\n",
    "        continue\n",
    "    if new_cite_list[s] > 20:\n",
    "        print (str(s) + \"{color:\" + color[0] + \"}\")\n",
    "        continue\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T03:04:09.189570Z",
     "start_time": "2020-01-07T03:04:09.180156Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "stem\n",
      "143\n",
      "stem\n",
      "145\n",
      "stem\n",
      "146\n",
      "OL\n",
      "147\n",
      "OL\n",
      "148\n",
      "Interface\n"
     ]
    }
   ],
   "source": [
    "for s in range(142,150):\n",
    "    if s in onlineLearning:\n",
    "        print (s)\n",
    "        print ('OL')\n",
    "    elif s in tabletopInterface:\n",
    "        print (s)\n",
    "        print ('Interface')\n",
    "    elif s in STEMedu:\n",
    "        print (s)\n",
    "        print ('stem')\n",
    "    elif s in stuAnalysis:\n",
    "        print (s)\n",
    "        print ('sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T09:06:14.117243Z",
     "start_time": "2020-01-07T09:06:14.104962Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2013': 4, '2014': 6, '2015': 10, '2018': 2, '2016': 6, '2017': 2}\n",
      "{'2005': 2, '1997': 2, '2014': 5, '2004': 3, '2012': 3, '2009': 2, '2018': 1, '2013': 3, '2010': 2, '2006': 2, '2007': 1, '2011': 3, '2008': 1, '2015': 3, '2016': 2}\n",
      "{'2007': 1, '2015': 6, '2016': 2, '2017': 5, '2018': 3, '2001': 1, '2013': 1, '2014': 1, '2000': 2, '2006': 1, '2011': 1}\n",
      "{'2014': 6, '2015': 6, '2012': 3, '2004': 1, '2007': 1, '2013': 3, '2017': 6, '2016': 7}\n"
     ]
    }
   ],
   "source": [
    "def annualCount(stuAnalysis):\n",
    "    year_data = {}\n",
    "    for s in stuAnalysis:\n",
    "        #print (s)\n",
    "        #print(df1['year'][s])\n",
    "        year = df1['year'][s]\n",
    "        if year not in year_data.keys():\n",
    "            year_data[year] = 1\n",
    "        else:\n",
    "            year_data[year] += 1\n",
    "    print(year_data)\n",
    "    \n",
    "    \n",
    "annualCount(onlineLearning)\n",
    "annualCount(tabletopInterface)\n",
    "annualCount(STEMedu)\n",
    "annualCount(stuAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "377.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
